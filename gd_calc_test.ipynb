{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOeHUZZc9C6wL6N+NZiW6dr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucker3900/machine_learning/blob/main/gd_calc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "QKJe8iwGU3Wz"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
      ],
      "metadata": {
        "id": "otaTTLNwU5Hl"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Relu函数\n",
        "def relu(a):\n",
        "  a= np.maximum(0,a)\n",
        "  return a"
      ],
      "metadata": {
        "id": "UQsi4DWYU7Xn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播,求输出\n",
        "def forward(W, X, V, B, b3):\n",
        "  H = np.dot(W,X) + B\n",
        "\n",
        "  print(f\"隐藏层h1,h2节点:{H}\\n\")\n",
        "  y_pred = np.dot(V,H) + b3\n",
        "  print(f\"y输出值:{y_pred}\\n\")\n",
        "  H = np.reshape(H, (2,1))\n",
        "\n",
        "  return H, y_pred"
      ],
      "metadata": {
        "id": "p3hjIxW1U9In"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算loss值\n",
        "def computer_loss(y_pred, y_true):\n",
        "  loss = pow((y_pred - y_true),2) / 2\n",
        "  print(f\"loss的值{loss}\\n\")\n",
        "  return loss"
      ],
      "metadata": {
        "id": "nrZa1x32U-gT"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算v1,v2,b3,w1,w2,b1,b2的梯度\n",
        "def computer_gradian(y_pred, y_true, H, V, W, X):\n",
        "  W_grad = []\n",
        "  y_diff = y_pred - y_true\n",
        "  B_grad = np.dot(W,X)\n",
        "\n",
        "  W_grad.append((y_pred - y_true) * np.reshape(V, (2,1)) * 1* X)\n",
        "\n",
        "  Wg = np.reshape(W_grad, (2,3))\n",
        "\n",
        "  return Wg, y_diff * relu(H), B_grad, y_diff"
      ],
      "metadata": {
        "id": "co7KCgqrVBWI"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#反向传导,更新weight, bias\n",
        "def backward(lr, W, B, b3, W_grad, B_grad, b3_grad):\n",
        "  W -= lr * W_grad\n",
        "  B -= lr * B_grad\n",
        "  b3 -= lr * b3_grad\n",
        "  return W, B, b3"
      ],
      "metadata": {
        "id": "tHweahgRVDO4"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYSq1lSUUsAf",
        "outputId": "6695bca2-0339-4c6d-e9dc-1d601d33c639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "隐藏层h1,h2节点:[ 3.95 -1.8 ]\n",
            "\n",
            "y输出值:1.735\n",
            "\n",
            "loss的值0.027612500000000022\n",
            "\n",
            "w偏导数([[ 0.329   -0.24675  0.4935 ]\n",
            " [ 0.282   -0.2115   0.423  ]]), v偏导数([[0.92825]\n",
            " [0.     ]]), 隐藏层b偏导数[ 3.85 -1.6 ], 输出层b3偏导数0.2350000000000001\n",
            "\n",
            "更新后w的值([[ 0.49671   -0.2975325  0.795065 ]\n",
            " [-0.20282    0.402115  -0.20423  ]]), 更新后隐藏节点b的值[ 0.0615 -0.184 ], 更新后b3的值0.047650000000000005\n",
            "隐藏层h1,h2节点:[ 3.88641375 -1.8055025 ]\n",
            "\n",
            "y输出值:1.684838125\n",
            "\n",
            "loss的值0.017082566226757807\n",
            "\n",
            "w偏导数([[ 0.25877337 -0.19408003  0.38816006]\n",
            " [ 0.22180575 -0.16635431  0.33270862]]), v偏导数([[0.71835743]\n",
            " [0.        ]]), 隐藏层b偏导数[ 3.82491375 -1.6215025 ], 输出层b3偏导数0.18483812499999996\n",
            "\n",
            "更新后w的值([[ 0.49412227 -0.2955917   0.7911834 ]\n",
            " [-0.20503806  0.40377854 -0.20755709]]), 更新后隐藏节点b的值[ 0.02325086 -0.16778498], 更新后b3的值0.04580161875\n",
            "隐藏层h1,h2节点:[ 3.82843314 -1.80620016]\n",
            "\n",
            "y输出值:1.641984720546875\n",
            "\n",
            "loss的值0.010079830434387085\n",
            "\n",
            "w偏导数([[ 0.19877861 -0.14908396  0.29816791]\n",
            " [ 0.17038166 -0.12778625  0.2555725 ]]), v偏导数([[0.54357901]\n",
            " [0.        ]]), 隐藏层b偏导数[ 3.80518228 -1.63841519], 输出层b3偏导数0.14198472054687494\n",
            "\n",
            "更新后w的值([[ 0.49213448 -0.29410086  0.78820172]\n",
            " [-0.20674187  0.40505641 -0.21011281]]), 更新后隐藏节点b的值[-0.01480096 -0.15140082], 更新后b3的值0.044381771544531254\n",
            "隐藏层h1,h2节点:[ 3.77522445 -1.80280761]\n",
            "\n",
            "y输出值:1.605354319110049\n",
            "\n",
            "loss的值0.005549766277571018\n",
            "\n",
            "w偏导数([[ 0.14749605 -0.11062204  0.22124407]\n",
            " [ 0.12642518 -0.09481889  0.18963777]]), v偏导数([[0.3977362]\n",
            " [0.       ]]), 隐藏层b偏导数[ 3.79002541 -1.65140679], 输出层b3偏导数0.105354319110049\n",
            "\n",
            "更新后w的值([[ 0.49065952 -0.29299464  0.78598928]\n",
            " [-0.20800613  0.40600459 -0.21200919]]), 更新后隐藏节点b的值[-0.05270121 -0.13488676], 更新后b3的值0.04332822835343077\n",
            "隐藏层h1,h2节点:[ 3.72607762 -1.79593347]\n",
            "\n",
            "y输出值:1.5740224851678484\n",
            "\n",
            "loss的值0.002739664155212166\n",
            "\n",
            "w偏导数([[ 0.10363148 -0.07772361  0.15544722]\n",
            " [ 0.08882698 -0.06662024  0.13324047]]), v偏导数([[0.27581353]\n",
            " [0.        ]]), 隐藏层b偏导数[ 3.77877884 -1.66104671], 输出层b3偏导数0.07402248516784837\n",
            "\n",
            "更新后w的值([[ 0.4896232  -0.2922174   0.78443481]\n",
            " [-0.2088944   0.4066708  -0.21334159]]), 更新后隐藏节点b的值[-0.090489   -0.11827629], 更新后b3的值0.042588003501752285\n",
            "隐藏层h1,h2节点:[ 3.68038793 -1.78609606]\n",
            "\n",
            "y输出值:1.5472019240759742\n",
            "\n",
            "loss的值0.001114010818237018\n",
            "\n",
            "w偏导数([[ 0.06608269 -0.04956202  0.09912404]\n",
            " [ 0.05664231 -0.04248173  0.08496346]]), v偏导数([[0.17372139]\n",
            " [0.        ]]), 隐藏层b偏导数[ 3.77087694 -1.66781977], 输出层b3偏导数0.04720192407597423\n",
            "\n",
            "更新后w的值([[ 0.48896238 -0.29172178  0.78344357]\n",
            " [-0.20946082  0.40709561 -0.21419123]]), 更新后隐藏节点b的值[-0.12819777 -0.10159809], 更新后b3的值0.04211598426099254\n",
            "隐藏层h1,h2节点:[ 3.63764036 -1.77373683]\n",
            "\n",
            "y输出值:1.5242221354729517\n",
            "\n",
            "loss的值0.00029335592343501284\n",
            "\n",
            "w偏导数([[ 0.03391099 -0.02543324  0.05086648]\n",
            " [ 0.02906656 -0.02179992  0.04359984]]), v偏导数([[0.08811142]\n",
            " [0.        ]]), 隐藏层b偏导数[ 3.76583813 -1.67213874], 输出层b3偏导数0.02422213547295171\n",
            "\n",
            "更新后w的值([[ 0.48862327 -0.29146745  0.7829349 ]\n",
            " [-0.20975148  0.40731361 -0.21462723]]), 更新后隐藏节点b的值[-0.16585615 -0.0848767 ], 更新后b3的值0.041873762906263025\n",
            "隐藏层h1,h2节点:[ 3.59739627 -1.75923177]\n",
            "\n",
            "y输出值:1.5045120853477099\n",
            "\n",
            "loss的值1.0179457092509004e-05\n",
            "\n",
            "w偏导数([[ 0.00631692 -0.00473769  0.00947538]\n",
            " [ 0.0054145  -0.00406088  0.00812175]]), v偏导数([[0.01623176]\n",
            " [0.        ]]), 隐藏层b偏导数[ 3.76325242 -1.67435507], 输出层b3偏导数0.00451208534770986\n",
            "\n",
            "更新后w的值([[ 0.4885601  -0.29142007  0.78284015]\n",
            " [-0.20980563  0.40735422 -0.21470844]]), 更新后隐藏节点b的值[-0.20348868 -0.06813315], 更新后b3的值0.04182864205278593\n",
            "隐藏层h1,h2节点:[ 3.55928208 -1.74290108]\n",
            "\n",
            "y输出值:1.487585448914311\n",
            "\n",
            "loss的值7.706053932959105e-05\n",
            "\n",
            "w偏导数([[-0.01738037  0.01303528 -0.02607056]\n",
            " [-0.01489746  0.0111731  -0.02234619]]), v偏导数([[-0.04418689]\n",
            " [-0.        ]]), 隐藏层b偏导数[ 3.76277075 -1.67476793], 输出层b3偏导数-0.012414551085689007\n",
            "\n",
            "更新后w的值([[ 0.4887339  -0.29155043  0.78310085]\n",
            " [-0.20965665  0.40724249 -0.21448498]]), 更新后隐藏节点b的值[-0.24111639 -0.05138547], 更新后b3的值0.04195278756364282\n",
            "隐藏层h1,h2节点:[ 3.52297962 -1.72501747]\n",
            "\n",
            "y输出值:1.4730280428835576\n",
            "\n",
            "loss的值0.000363743235345604\n",
            "\n",
            "w偏导数([[-0.03776074  0.02832055 -0.05664111]\n",
            " [-0.03236635  0.02427476 -0.04854952]]), v偏导数([[-0.09502166]\n",
            " [-0.        ]]), 隐藏层b偏导数[ 3.76409601 -1.67363199], 输出层b3偏导数-0.026971957116442402\n",
            "\n",
            "更新后w的值([[ 0.48911151 -0.29183363  0.78366726]\n",
            " [-0.20933299  0.40699974 -0.21399949]]), 更新后隐藏节点b的值[-0.27875735 -0.03464915], 更新后b3的值0.04222250713480724\n"
          ]
        }
      ],
      "source": [
        "#初始化\n",
        "X = np.array([2.0, -1.5, 3.0])\n",
        "W1 = np.array([0.5, -0.3, 0.8])\n",
        "W2 = np.array([-0.2, 0.4, -0.2])\n",
        "W = np.array([\n",
        "   [0.5, -0.3, 0.8],\n",
        "   [-0.2, 0.4, -0.2]\n",
        "   ])\n",
        "\n",
        "V = np.array([0.7, 0.6])\n",
        "b1 = 0.1\n",
        "b2 = -0.2\n",
        "B = np.array([0.1, -0.2])\n",
        "b3 = 0.05\n",
        "y_true = 1.5\n",
        "lr = 0.01\n",
        "\n",
        "eporchs = 10\n",
        "\n",
        "for eporch in range(eporchs):\n",
        "  H, y_pred = forward(W, X, V, B, b3)\n",
        "  loss = computer_loss(y_pred, y_true)\n",
        "\n",
        "  W_grad, V_grad, B_grad, b3_grad = computer_gradian(y_pred, y_true, H, V, W, X)\n",
        "  print(f\"w偏导数({W_grad}), v偏导数({V_grad}), 隐藏层b偏导数{B_grad}, 输出层b3偏导数{b3_grad}\\n\")\n",
        "\n",
        "  W, B, b3 = backward(lr, W, B, b3, W_grad, B_grad, b3_grad)\n",
        "  print(f\"更新后w的值({W}), 更新后隐藏节点b的值{B}, 更新后b3的值{b3}\")"
      ]
    }
  ]
}