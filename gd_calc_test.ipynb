{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucker3900/machine_learning/blob/main/gd_calc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKJe8iwGU3Wz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otaTTLNwU5Hl"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQsi4DWYU7Xn"
      },
      "outputs": [],
      "source": [
        "#Relu函数\n",
        "def relu(a):\n",
        "  a= np.maximum(0,a)\n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3hjIxW1U9In"
      },
      "outputs": [],
      "source": [
        "#前向传播,求输出\n",
        "def forward(W, X, V, B, b3):\n",
        "  Z = np.dot(W,X) + B\n",
        "  H = relu(Z)\n",
        "\n",
        "  print(f\"隐藏层h1,h2节点:{H}\\n\")\n",
        "  y_pred = np.dot(V,H) + b3\n",
        "  print(f\"y输出值:{y_pred}\\n\")\n",
        "  H = np.reshape(H, (2,1))\n",
        "\n",
        "  return Z, H, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrZa1x32U-gT"
      },
      "outputs": [],
      "source": [
        "#计算loss值\n",
        "def computer_loss(y_pred, y_true):\n",
        "  loss = pow((y_pred - y_true),2) / 2\n",
        "  print(f\"loss的值{loss}\\n\")\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "co7KCgqrVBWI"
      },
      "outputs": [],
      "source": [
        "#计算v1,v2,b3,w1,w2,b1,b2的梯度\n",
        "def computer_gradian(y_pred, y_true, Z, H, V, W, X):\n",
        "  W_grad = []\n",
        "  y_diff = y_pred - y_true\n",
        "  B_grad = y_diff * V\n",
        "\n",
        "  W_grad.append(y_diff * np.reshape(V,(2,1)) * (np.reshape(Z,(2,1)) > 0) * X)\n",
        "\n",
        "  Wg = np.reshape(W_grad, (2,3))\n",
        "\n",
        "  return Wg, y_diff * H, B_grad, y_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHweahgRVDO4"
      },
      "outputs": [],
      "source": [
        "#反向传导,更新weight, bias\n",
        "def backward(lr, W, B, b3, W_grad, B_grad, b3_grad):\n",
        "  W -= lr * W_grad\n",
        "  B -= lr * B_grad\n",
        "  b3 -= lr * b3_grad\n",
        "  return W, B, b3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYSq1lSUUsAf",
        "outputId": "15908301-4a6f-4e76-b4f5-585bbb56567a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "隐藏层h1,h2节点:[3.95 0.  ]\n",
            "\n",
            "y输出值:2.815\n",
            "\n",
            "loss的值0.8646124999999999\n",
            "\n",
            "w偏导数([[ 1.841   -1.38075  2.7615 ]\n",
            " [ 0.      -0.       0.     ]]), v偏导数([[5.19425]\n",
            " [0.     ]]), 隐藏层b偏导数[0.9205 0.789 ], 输出层b3偏导数1.315\n",
            "\n",
            "更新后w的值([[ 0.48159   -0.2861925  0.772385 ]\n",
            " [-0.2        0.4       -0.2      ]]), 更新后隐藏节点b的值[ 0.090795 -0.20789 ], 更新后b3的值0.03685\n",
            "隐藏层h1,h2节点:[3.80041875 0.        ]\n",
            "\n",
            "y输出值:2.6971431249999998\n",
            "\n",
            "loss的值0.7165758308673825\n",
            "\n",
            "w偏导数([[ 1.67600037 -1.25700028  2.51400056]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[4.54964518]\n",
            " [0.        ]]), 隐藏层b偏导数[0.83800019 0.71828587], 输出层b3偏导数1.1971431249999998\n",
            "\n",
            "更新后w的值([[ 0.46483    -0.2736225   0.74724499]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.082415   -0.21507286], 更新后b3的值0.024878568750000003\n",
            "隐藏层h1,h2节点:[3.66424372 0.        ]\n",
            "\n",
            "y输出值:2.5898491724218755\n",
            "\n",
            "loss的值0.5938856093143234\n",
            "\n",
            "w偏导数([[ 1.52578884 -1.14434163  2.28868326]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[3.99347299]\n",
            " [0.        ]]), 隐藏层b偏导数[0.76289442 0.6539095 ], 输出层b3偏导数1.0898491724218755\n",
            "\n",
            "更新后w的值([[ 0.44957211 -0.26217908  0.72435816]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.07478605 -0.22161195], 更新后b3的值0.013980077025781247\n",
            "隐藏层h1,h2节点:[3.54027338 0.        ]\n",
            "\n",
            "y输出值:2.492171440343565\n",
            "\n",
            "loss的值0.49220208351671224\n",
            "\n",
            "w偏导数([[ 1.38904002 -1.04178001  2.08356002]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[3.51255813]\n",
            " [0.        ]]), 隐藏层b偏导数[0.69452001 0.59530286], 输出层b3偏导数0.9921714403435651\n",
            "\n",
            "更新后w的值([[ 0.43568171 -0.25176128  0.70352256]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.06784085 -0.22756498], 更新后b3的值0.004058362622345596\n",
            "隐藏层h1,h2节点:[3.42741387 0.        ]\n",
            "\n",
            "y输出值:2.403248075002773\n",
            "\n",
            "loss的值0.40792854249810745\n",
            "\n",
            "w偏导数([[ 1.26454731 -0.94841048  1.89682096]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[3.09580498]\n",
            " [0.        ]]), 隐藏层b偏导数[0.63227365 0.54194885], 输出层b3偏导数0.9032480750027729\n",
            "\n",
            "更新后w的值([[ 0.42303623 -0.24227718  0.68455435]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.06151812 -0.23298447], 更新后b3的值-0.0049741181276821336\n",
            "隐藏层h1,h2节点:[3.32466941 0.        ]\n",
            "\n",
            "y输出值:2.3222944662806495\n",
            "\n",
            "loss的值0.33808409463788913\n",
            "\n",
            "w偏导数([[ 1.15121225 -0.86340919  1.72681838]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[2.73385726]\n",
            " [0.        ]]), 隐藏层b偏导数[0.57560613 0.49337668], 输出层b3偏导数0.8222944662806495\n",
            "\n",
            "更新后w的值([[ 0.41152411 -0.23364308  0.66728617]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.05576206 -0.23791824], 更新后b3的值-0.013197062790488628\n",
            "隐藏层h1,h2节点:[3.23113341 0.        ]\n",
            "\n",
            "y输出值:2.248596324740246\n",
            "\n",
            "loss的值0.2801982287073018\n",
            "\n",
            "w偏导数([[ 1.04803485 -0.78602614  1.57205228]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[2.4188146]\n",
            " [0.       ]]), 隐藏层b偏导数[0.52401743 0.44915779], 输出层b3偏导数0.7485963247402458\n",
            "\n",
            "更新后w的值([[ 0.40104376 -0.22578282  0.65156565]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.05052188 -0.24240982], 更新后b3的值-0.020683026037891086\n",
            "隐藏层h1,h2节点:[3.14598058 0.        ]\n",
            "\n",
            "y输出值:2.181503379135402\n",
            "\n",
            "loss的值0.2322234278864857\n",
            "\n",
            "w偏导数([[ 0.95410473 -0.71557855  1.4311571 ]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[2.1439964]\n",
            " [0.       ]]), 隐藏层b偏导数[0.47705237 0.40890203], 输出层b3偏导数0.6815033791354019\n",
            "\n",
            "更新后w的值([[ 0.39150272 -0.21862704  0.63725407]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.04575136 -0.24649884], 更新后b3的值-0.027498059829245105\n",
            "隐藏层h1,h2节点:[3.06845957 0.        ]\n",
            "\n",
            "y输出值:2.120423638780391\n",
            "\n",
            "loss的值0.19246274577875053\n",
            "\n",
            "w偏导数([[ 0.86859309 -0.65144482  1.30288964]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[1.90374485]\n",
            " [0.        ]]), 隐藏层b偏导数[0.43429655 0.37225418], 输出层b3偏导数0.620423638780391\n",
            "\n",
            "更新后w的值([[ 0.38281679 -0.21211259  0.62422518]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.04140839 -0.25022138], 更新后b3的值-0.03370229621704902\n",
            "隐藏层h1,h2节点:[2.99788638 0.        ]\n",
            "\n",
            "y输出值:2.0648181701546986\n",
            "\n",
            "loss的值0.15950978266845103\n",
            "\n",
            "w偏导数([[ 0.79074544 -0.59305908  1.18611816]\n",
            " [ 0.         -0.          0.        ]]), v偏导数([[1.6932607]\n",
            " [0.       ]]), 隐藏层b偏导数[0.39537272 0.3388909 ], 输出层b3偏导数0.5648181701546986\n",
            "\n",
            "更新后w的值([[ 0.37490933 -0.206182    0.612364  ]\n",
            " [-0.2         0.4        -0.2       ]]), 更新后隐藏节点b的值[ 0.03745467 -0.25361029], 更新后b3的值-0.039350477918596\n"
          ]
        }
      ],
      "source": [
        "#初始化\n",
        "X = np.array([2.0, -1.5, 3.0])\n",
        "W1 = np.array([0.5, -0.3, 0.8])\n",
        "W2 = np.array([-0.2, 0.4, -0.2])\n",
        "W = np.array([\n",
        "   [0.5, -0.3, 0.8],\n",
        "   [-0.2, 0.4, -0.2]\n",
        "   ])\n",
        "\n",
        "V = np.array([0.7, 0.6])\n",
        "b1 = 0.1\n",
        "b2 = -0.2\n",
        "B = np.array([0.1, -0.2])\n",
        "b3 = 0.05\n",
        "y_true = 1.5\n",
        "lr = 0.01\n",
        "\n",
        "eporchs = 10\n",
        "\n",
        "for eporch in range(eporchs):\n",
        "  Z, H, y_pred = forward(W, X, V, B, b3)\n",
        "  loss = computer_loss(y_pred, y_true)\n",
        "\n",
        "  W_grad, V_grad, B_grad, b3_grad = computer_gradian(y_pred, y_true, Z, H, V, W, X)\n",
        "  print(f\"w偏导数({W_grad}), v偏导数({V_grad}), 隐藏层b偏导数{B_grad}, 输出层b3偏导数{b3_grad}\\n\")\n",
        "\n",
        "  W, B, b3 = backward(lr, W, B, b3, W_grad, B_grad, b3_grad)\n",
        "  print(f\"更新后w的值({W}), 更新后隐藏节点b的值{B}, 更新后b3的值{b3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEpJqR-N4fMk"
      },
      "outputs": [],
      "source": [
        "a = np.array([1, 2])\n",
        "b = np.array([3, 4, 5])\n",
        "print(np.outer(a, b))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO4saSnyhOV3lLOAbukWt4C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}