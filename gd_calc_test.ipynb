{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucker3900/machine_learning/blob/main/gd_calc_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKJe8iwGU3Wz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otaTTLNwU5Hl"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQsi4DWYU7Xn"
      },
      "outputs": [],
      "source": [
        "#Relu函数\n",
        "def relu(a):\n",
        "  a= np.maximum(0,a)\n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3hjIxW1U9In"
      },
      "outputs": [],
      "source": [
        "#前向传播,求输出\n",
        "def forward(W, X, V, B, b3):\n",
        "  H = np.dot(W,X) + B\n",
        "\n",
        "  print(f\"隐藏层h1,h2节点:{H}\\n\")\n",
        "  y_pred = np.dot(V,H) + b3\n",
        "  print(f\"y输出值:{y_pred}\\n\")\n",
        "  H = np.reshape(H, (2,1))\n",
        "\n",
        "  return H, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrZa1x32U-gT"
      },
      "outputs": [],
      "source": [
        "#计算loss值\n",
        "def computer_loss(y_pred, y_true):\n",
        "  loss = pow((y_pred - y_true),2) / 2\n",
        "  print(f\"loss的值{loss}\\n\")\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co7KCgqrVBWI"
      },
      "outputs": [],
      "source": [
        "#计算v1,v2,b3,w1,w2,b1,b2的梯度\n",
        "def computer_gradian(y_pred, y_true, H, V, W, X):\n",
        "  W_grad = []\n",
        "  y_diff = y_pred - y_true\n",
        "  B_grad = y_diff * V\n",
        "\n",
        "  W_grad.append(y_diff * np.reshape(V, (2,1)) * 1* X)\n",
        "\n",
        "  Wg = np.reshape(W_grad, (2,3))\n",
        "\n",
        "  return Wg, y_diff * relu(H), B_grad, y_diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHweahgRVDO4"
      },
      "outputs": [],
      "source": [
        "#反向传导,更新weight, bias\n",
        "def backward(lr, W, B, b3, W_grad, B_grad, b3_grad):\n",
        "  W -= lr * W_grad\n",
        "  B -= lr * B_grad\n",
        "  b3 -= lr * b3_grad\n",
        "  return W, B, b3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYSq1lSUUsAf",
        "outputId": "5577f677-cc74-48ff-e922-553e7186bfa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "隐藏层h1,h2节点:[ 3.95 -1.8 ]\n",
            "\n",
            "y输出值:1.735\n",
            "\n",
            "loss的值0.027612500000000022\n",
            "\n",
            "w偏导数([[ 0.329   -0.24675  0.4935 ]\n",
            " [ 0.282   -0.2115   0.423  ]]), v偏导数([[0.92825]\n",
            " [0.     ]]), 隐藏层b偏导数[0.1645 0.141 ], 输出层b3偏导数0.2350000000000001\n",
            "\n",
            "更新后w的值([[ 0.49671   -0.2975325  0.795065 ]\n",
            " [-0.20282    0.402115  -0.20423  ]]), 更新后隐藏节点b的值[ 0.098355 -0.20141 ], 更新后b3的值0.047650000000000005\n",
            "隐藏层h1,h2节点:[ 3.92326875 -1.8229125 ]\n",
            "\n",
            "y输出值:1.7001906249999998\n",
            "\n",
            "loss的值0.020038143168945283\n",
            "\n",
            "w偏导数([[ 0.28026687 -0.21020016  0.42040031]\n",
            " [ 0.24022875 -0.18017156  0.36034312]]), v偏导数([[0.78540162]\n",
            " [0.        ]]), 隐藏层b偏导数[0.14013344 0.12011437], 输出层b3偏导数0.20019062499999984\n",
            "\n",
            "更新后w的值([[ 0.49390733 -0.2954305   0.790861  ]\n",
            " [-0.20522229  0.40391672 -0.20783343]]), 更新后隐藏节点b的值[ 0.09695367 -0.20261114], 更新后b3的值0.04564809375000001\n",
            "隐藏层h1,h2节点:[ 3.90049707 -1.84243109]\n",
            "\n",
            "y输出值:1.670537388671875\n",
            "\n",
            "loss的值0.014541500467511091\n",
            "\n",
            "w偏导数([[ 0.23875234 -0.17906426  0.35812852]\n",
            " [ 0.20464487 -0.15348365  0.3069673 ]]), v偏导数([[0.66518058]\n",
            " [0.        ]]), 隐藏层b偏导数[0.11937617 0.10232243], 输出层b3偏导数0.17053738867187507\n",
            "\n",
            "更新后w的值([[ 0.49151981 -0.29363986  0.78727971]\n",
            " [-0.20726874  0.40545155 -0.2109031 ]]), 更新后隐藏节点b的值[ 0.0957599  -0.20363437], 更新后b3的值0.04394271986328126\n",
            "隐藏层h1,h2节点:[ 3.88109844 -1.85905848]\n",
            "\n",
            "y输出值:1.6452765379748528\n",
            "\n",
            "loss的值0.01055263624297943\n",
            "\n",
            "w偏导数([[ 0.20338715 -0.15254036  0.30508073]\n",
            " [ 0.17433185 -0.13074888  0.26149777]]), v偏导数([[0.56383254]\n",
            " [0.        ]]), 隐藏层b偏导数[0.10169358 0.08716592], 输出层b3偏导数0.14527653797485285\n",
            "\n",
            "更新后w的值([[ 0.48948594 -0.29211445  0.7842289 ]\n",
            " [-0.20901205  0.40675904 -0.21351808]]), 更新后隐藏节点b的值[ 0.09474297 -0.20450603], 更新后b3的值0.04248995448353273\n",
            "隐藏层h1,h2节点:[ 3.86457323 -1.87322294]\n",
            "\n",
            "y输出值:1.6237574507873285\n",
            "\n",
            "loss的值0.007657953312689014\n",
            "\n",
            "w偏导数([[ 0.17326043 -0.12994532  0.25989065]\n",
            " [ 0.14850894 -0.11138171  0.22276341]]), v偏导数([[0.47826973]\n",
            " [0.        ]]), 隐藏层b偏导数[0.08663022 0.07425447], 输出层b3偏导数0.12375745078732847\n",
            "\n",
            "更新后w的值([[ 0.48775333 -0.290815    0.78163   ]\n",
            " [-0.21049714  0.40787286 -0.21574572]]), 更新后隐藏节点b的值[ 0.09387667 -0.20524857], 更新后b3的值0.04125237997565945\n",
            "隐藏层h1,h2节点:[ 3.85049582 -1.8852893 ]\n",
            "\n",
            "y输出值:1.605425878389455\n",
            "\n",
            "loss的值0.005557307917094083\n",
            "\n",
            "w偏导数([[ 0.14759623 -0.11069717  0.22139434]\n",
            " [ 0.12651105 -0.09488329  0.18976658]]), v偏导数([[0.4059419]\n",
            " [0.       ]]), 隐藏层b偏导数[0.07379811 0.06325553], 输出层b3偏导数0.10542587838945505\n",
            "\n",
            "更新后w的值([[ 0.48627737 -0.28970803  0.77941605]\n",
            " [-0.21176225  0.40882169 -0.21764338]]), 更新后隐藏节点b的值[ 0.09313868 -0.20588113], 更新后b3的值0.0401981211917649\n",
            "隐藏层h1,h2节点:[ 3.83850363 -1.89556832]\n",
            "\n",
            "y输出值:1.589809670153017\n",
            "\n",
            "loss的值0.004032888426496866\n",
            "\n",
            "w偏导数([[ 0.12573354 -0.09430015  0.18860031]\n",
            " [ 0.1077716  -0.0808287   0.16165741]]), v偏导数([[0.34473474]\n",
            " [0.        ]]), 隐藏层b偏导数[0.06286677 0.0538858 ], 输出层b3偏导数0.08980967015301711\n",
            "\n",
            "更新后w的值([[ 0.48502003 -0.28876503  0.77753005]\n",
            " [-0.21283997  0.40962998 -0.21925996]]), 更新后隐藏节点b的值[ 0.09251002 -0.20641999], 更新后b3的值0.03930002449023473\n",
            "隐藏层h1,h2节点:[ 3.82828778 -1.90432476]\n",
            "\n",
            "y输出值:1.5765066127616012\n",
            "\n",
            "loss的值0.0029266308981268\n",
            "\n",
            "w偏导数([[ 0.10710926 -0.08033194  0.16066389]\n",
            " [ 0.09180794 -0.06885595  0.1377119 ]]), v偏导数([[0.29288933]\n",
            " [0.        ]]), 隐藏层b偏导数[0.05355463 0.04590397], 输出层b3偏导数0.0765066127616012\n",
            "\n",
            "更新后w的值([[ 0.48394894 -0.28796171  0.77592341]\n",
            " [-0.21375805  0.41031854 -0.22063707]]), 更新后隐藏节点b的值[ 0.09197447 -0.20687902], 更新后b3的值0.03853495836261872\n",
            "隐藏层h1,h2节点:[ 3.81958515 -1.91178416]\n",
            "\n",
            "y输出值:1.5651740707462891\n",
            "\n",
            "loss的值0.0021238297488211494\n",
            "\n",
            "w偏导数([[ 0.0912437  -0.06843277  0.13686555]\n",
            " [ 0.07820888 -0.05865666  0.11731333]]), v偏导数([[0.24893791]\n",
            " [0.        ]]), 隐藏层b偏导数[0.04562185 0.03910444], 输出层b3偏导数0.06517407074628911\n",
            "\n",
            "更新后w的值([[ 0.4830365  -0.28727738  0.77455476]\n",
            " [-0.21454014  0.4109051  -0.22181021]]), 更新后隐藏节点b的值[ 0.09151825 -0.20727007], 更新后b3的值0.03788321765515583\n",
            "隐藏层h1,h2节点:[ 3.8121716  -1.91813863]\n",
            "\n",
            "y输出值:1.5555201615169945\n",
            "\n",
            "loss的值0.0015412441674365763\n",
            "\n",
            "w偏导数([[ 0.07772823 -0.05829617  0.11659234]\n",
            " [ 0.06662419 -0.04996815  0.09993629]]), v偏导数([[0.21165238]\n",
            " [0.        ]]), 隐藏层b偏导数[0.03886411 0.0333121 ], 输出层b3偏导数0.05552016151699446\n",
            "\n",
            "更新后w的值([[ 0.48225922 -0.28669442  0.77338883]\n",
            " [-0.21520638  0.41140479 -0.22280957]]), 更新后隐藏节点b的值[ 0.09112961 -0.20760319], 更新后b3的值0.03732801603998588\n"
          ]
        }
      ],
      "source": [
        "#初始化\n",
        "X = np.array([2.0, -1.5, 3.0])\n",
        "W1 = np.array([0.5, -0.3, 0.8])\n",
        "W2 = np.array([-0.2, 0.4, -0.2])\n",
        "W = np.array([\n",
        "   [0.5, -0.3, 0.8],\n",
        "   [-0.2, 0.4, -0.2]\n",
        "   ])\n",
        "\n",
        "V = np.array([0.7, 0.6])\n",
        "b1 = 0.1\n",
        "b2 = -0.2\n",
        "B = np.array([0.1, -0.2])\n",
        "b3 = 0.05\n",
        "y_true = 1.5\n",
        "lr = 0.01\n",
        "\n",
        "eporchs = 10\n",
        "\n",
        "for eporch in range(eporchs):\n",
        "  H, y_pred = forward(W, X, V, B, b3)\n",
        "  loss = computer_loss(y_pred, y_true)\n",
        "\n",
        "  W_grad, V_grad, B_grad, b3_grad = computer_gradian(y_pred, y_true, H, V, W, X)\n",
        "  print(f\"w偏导数({W_grad}), v偏导数({V_grad}), 隐藏层b偏导数{B_grad}, 输出层b3偏导数{b3_grad}\\n\")\n",
        "\n",
        "  W, B, b3 = backward(lr, W, B, b3, W_grad, B_grad, b3_grad)\n",
        "  print(f\"更新后w的值({W}), 更新后隐藏节点b的值{B}, 更新后b3的值{b3}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNGNqSxdspY2sA9GRuhvyZv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}