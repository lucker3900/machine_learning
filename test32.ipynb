{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBtmNMln+M5kQL9Ligr0Es"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Ct5Ny9lPaTO"
      },
      "outputs": [],
      "source": [
        "#网络结构：\n",
        "#输入层：4 个神经元\n",
        "\n",
        "#隐藏层1：5 个神经元，激活函数使用 ReLU\n",
        "\n",
        "#隐藏层2：3 个神经元，激活函数使用 Tanh\n",
        "\n",
        "#输出层：2 个神经元，使用 Softmax，用于 2 分类任务（标签为 one-hot 向量）"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "1cON2b1lP43I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算softmax激活函数\n",
        "def softmax(a):\n",
        "  a_max = np.max(a, axis=1, keepdims=True)\n",
        "  z = np.exp(a - a_max)\n",
        "\n",
        "  sums = np.sum(z, axis=1, keepdims=True)\n",
        "\n",
        "  return z / sums"
      ],
      "metadata": {
        "id": "mvJ-UsdSQOIS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播，计算y_pred\n",
        "def forward(w1, w2, w3, b1, b2, b3, x):\n",
        "  z1 = np.dot(x, w1) + b1 #shape (2,5)\n",
        "  h1 = np.maximum(0, z1)\n",
        "\n",
        "  z2 = np.dot(h1, w2) + b2 #shape (2,3)\n",
        "  h2 = np.tanh(z2)\n",
        "\n",
        "  z3 = np.dot(h2, w3) + b3 #shape (2,2)\n",
        "  y_pred = softmax(z3) #shape (2,2)\n",
        "  return z1, h1, h2, y_pred"
      ],
      "metadata": {
        "id": "uGl5aWRkSNsy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算损失函数loss\n",
        "def compute_loss(y_pred, y_true):\n",
        "  loss = -(np.sum(y_true * np.log(y_pred + 1e-10)) / y_pred.shape[0])\n",
        "  return loss"
      ],
      "metadata": {
        "id": "nvjIPkAsUlmr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#反向传播，计算梯度\n",
        "def backward(y_pred, y_true, h1, h2, z1, w2, w3, x):\n",
        "  dz3 = y_pred - y_true\n",
        "  b3_grad = np.mean(dz3, axis=0, keepdims=True).flatten()\n",
        "  w3_grad = np.dot(h2.T, dz3) / h2.shape[0] # shape(3,2)\n",
        "\n",
        "  dh2 = np.dot(dz3, w3.T) # shape(2,3)\n",
        "  dz2 = dh2 * (1 - h2**2) # shape(2,3)\n",
        "  b2_grad = np.mean(dz2, axis=0, keepdims=True).flatten()\n",
        "  w2_grad = np.dot(h1.T, dz2) / h1.shape[0] # shape (5,3)\n",
        "\n",
        "  dh1 = np.dot(dz2, w2.T) # shape(2,5)\n",
        "  dz1 = dh1 * (z1 > 0)\n",
        "  b1_grad = np.mean(dz1, axis=0, keepdims=True).flatten()\n",
        "  w1_grad = np.dot(x.T, dz1) / x.shape[0]#shape (4,5)\n",
        "\n",
        "  return w1_grad, w2_grad, w3_grad, b1_grad, b2_grad, b3_grad"
      ],
      "metadata": {
        "id": "K48nGvjJWHDb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#更新参数值\n",
        "def update_params(w1, w2, w3, b1, b2, b3, w1_grad, w2_grad, w3_grad, b1_grad, b2_grad, b3_grad, learning_rate):\n",
        "  w1 -= learning_rate * w1_grad\n",
        "  w2 -= learning_rate * w2_grad\n",
        "  w3 -= learning_rate * w3_grad\n",
        "  b1 -= learning_rate * b1_grad\n",
        "  b2 -= learning_rate * b2_grad\n",
        "  b3 -= learning_rate * b3_grad\n",
        "  return w1, w2, w3, b1, b2, b3"
      ],
      "metadata": {
        "id": "SAAHhO7kbHdd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机数种子以保证可复现\n",
        "np.random.seed(42)\n",
        "\n",
        "# 网络层次：\n",
        "# 输入层：4 个神经元\n",
        "# 隐藏层1：5 个神经元 => W1 shape: (4, 5), b1 shape: (5,)\n",
        "# 隐藏层2：3 个神经元 => W2 shape: (5, 3), b2 shape: (3,)\n",
        "# 输出层：2 个神经元    => W3 shape: (3, 2), b3 shape: (2,)\n",
        "\n",
        "w1 = np.random.randn(4, 5) * 0.1 #shape (4,5)\n",
        "b1 = np.random.randn(5) * 0.1 #shape (1,5)\n",
        "\n",
        "w2 = np.random.randn(5, 3) * 0.1 #shape (5,3)\n",
        "b2 = np.random.randn(3) * 0.1 #shape (1,3)\n",
        "\n",
        "w3 = np.random.randn(3, 2) * 0.1 #shape (3,2)\n",
        "b3 = np.random.randn(2) * 0.1 #shape (1,2)\n",
        "\n",
        "x = np.array([[0.2, 0.5, 0.1, 0.9],\n",
        "        [0.7, 0.3, 0.6, 0.2]]) #shape (2,4)\n",
        "\n",
        "y_true = np.array([[1, 0],\n",
        "          [0, 1]]) #shape (2,2)\n",
        "\n",
        "losses = []\n",
        "learning_rate = 0.01\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  z1, h1, h2, y_pred = forward(w1, w2, w3, b1, b2, b3, x)\n",
        "  loss = compute_loss(y_pred, y_true)\n",
        "  losses.append(loss)\n",
        "\n",
        "  w1_grad, w2_grad, w3_grad, b1_grad, b2_grad, b3_grad = backward(y_pred, y_true, h1, h2, z1, w2, w3, x)\n",
        "  w1, w2, w3, b1, b2, b3 = update_params(w1, w2, w3, b1, b2, b3, w1_grad, w2_grad, w3_grad, b1_grad, b2_grad, b3_grad, learning_rate)\n",
        "\n",
        "  if epoch%100 == 0:\n",
        "    print(\"epoch:\", epoch + 1,\n",
        "      \"loss\", np.round(loss, 4),\n",
        "      \"y_pred\", np.round(y_pred.flatten(), 2),\n",
        "      \"w1\", np.round(w1.flatten(), 2),\n",
        "      \"w2\", np.round(w2.flatten(), 2),\n",
        "      \"w3\", np.round(w3.flatten(), 2),\n",
        "      \"b1\", np.round(b1.flatten(), 2),\n",
        "      \"b2\", np.round(b2.flatten(), 2),\n",
        "      \"b3\", np.round(b3.flatten(), 2),\n",
        "      )\n",
        "\n",
        "plt.plot(range(epochs), losses, \"blue\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ysefU_TUPy66",
        "outputId": "17c001e3-c12a-4144-f162-9d5f7eeb0911"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss 0.6982 y_pred [0.45 0.55 0.45 0.55] w1 [ 0.05 -0.01  0.06  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.02 -0.19 -0.17 -0.06 -0.1   0.03 -0.09 -0.14] w2 [ 0.01 -0.12  0.04 -0.06 -0.03 -0.06  0.19 -0.   -0.11  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.03 -0.15 -0.07 -0.05  0.11  0.03] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.07  0.02 -0.01] b3 [-0.18  0.03]\n",
            "epoch: 101 loss 0.695 y_pred [0.47 0.53 0.47 0.53] w1 [ 0.05 -0.01  0.06  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.02 -0.19 -0.17 -0.05 -0.1   0.03 -0.09 -0.14] w2 [ 0.01 -0.11  0.04 -0.06 -0.03 -0.06  0.19 -0.   -0.11  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.03 -0.15 -0.07 -0.05  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.14 -0.01]\n",
            "epoch: 201 loss 0.6939 y_pred [0.48 0.52 0.48 0.52] w1 [ 0.05 -0.01  0.06  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.02 -0.19 -0.17 -0.05 -0.1   0.04 -0.09 -0.14] w2 [ 0.01 -0.11  0.04 -0.06 -0.03 -0.06  0.19 -0.   -0.11  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.15 -0.07 -0.05  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.11 -0.03]\n",
            "epoch: 301 loss 0.6934 y_pred [0.49 0.51 0.49 0.51] w1 [ 0.05 -0.01  0.06  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.02 -0.19 -0.17 -0.05 -0.1   0.04 -0.09 -0.14] w2 [ 0.01 -0.11  0.04 -0.06 -0.03 -0.06  0.19 -0.   -0.11  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.15 -0.07 -0.05  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.1  -0.04]\n",
            "epoch: 401 loss 0.6932 y_pred [0.49 0.51 0.49 0.51] w1 [ 0.05 -0.01  0.06  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.02 -0.19 -0.17 -0.05 -0.1   0.04 -0.09 -0.14] w2 [ 0.01 -0.11  0.04 -0.06 -0.03 -0.06  0.19 -0.   -0.11  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.16 -0.07 -0.05  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.09 -0.05]\n",
            "epoch: 501 loss 0.6932 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01  0.05  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.01 -0.19 -0.17 -0.05 -0.1   0.05 -0.09 -0.14] w2 [ 0.01 -0.11  0.03 -0.06 -0.03 -0.06  0.19 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.16 -0.07 -0.05  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.01] b3 [-0.09 -0.06]\n",
            "epoch: 601 loss 0.6931 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01  0.05  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.01 -0.19 -0.17 -0.05 -0.1   0.05 -0.09 -0.14] w2 [ 0.   -0.11  0.03 -0.06 -0.03 -0.06  0.19 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.16 -0.06 -0.05  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 701 loss 0.6931 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01  0.05  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.01 -0.19 -0.17 -0.05 -0.1   0.05 -0.09 -0.14] w2 [ 0.   -0.11  0.03 -0.06 -0.03 -0.06  0.19 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.16 -0.06 -0.05  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 801 loss 0.693 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.05  0.15 -0.02 -0.02  0.16  0.08 -0.05  0.05 -0.05 -0.05\n",
            "  0.01 -0.19 -0.17 -0.05 -0.1   0.06 -0.09 -0.14] w2 [ 0.   -0.11  0.03 -0.06 -0.03 -0.06  0.19 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.16 -0.06 -0.06  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 901 loss 0.693 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.05  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            "  0.   -0.19 -0.17 -0.05 -0.1   0.06 -0.09 -0.14] w2 [ 0.   -0.11  0.03 -0.06 -0.03 -0.06  0.19 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.02 -0.16 -0.06 -0.06  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.  ] b3 [-0.08 -0.06]\n",
            "epoch: 1001 loss 0.6929 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.04  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            "  0.   -0.19 -0.17 -0.05 -0.1   0.06 -0.09 -0.14] w2 [-0.   -0.11  0.03 -0.06 -0.03 -0.06  0.19 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.01 -0.16 -0.06 -0.06  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.  ] b3 [-0.08 -0.06]\n",
            "epoch: 1101 loss 0.6929 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.04  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            " -0.   -0.19 -0.17 -0.05 -0.1   0.07 -0.09 -0.14] w2 [-0.   -0.11  0.03 -0.06 -0.03 -0.06  0.19 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.01 -0.17 -0.06 -0.06  0.1   0.04] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.  ] b3 [-0.08 -0.06]\n",
            "epoch: 1201 loss 0.6928 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.04  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            " -0.   -0.19 -0.17 -0.05 -0.1   0.07 -0.09 -0.14] w2 [-0.   -0.11  0.03 -0.06 -0.03 -0.06  0.2  -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.01 -0.17 -0.06 -0.06  0.09  0.05] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.  ] b3 [-0.08 -0.06]\n",
            "epoch: 1301 loss 0.6927 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.03  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            " -0.01 -0.19 -0.17 -0.05 -0.1   0.08 -0.09 -0.14] w2 [-0.   -0.11  0.03 -0.06 -0.03 -0.06  0.2  -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.01 -0.17 -0.06 -0.06  0.09  0.05] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.  ] b3 [-0.08 -0.06]\n",
            "epoch: 1401 loss 0.6926 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.03  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            " -0.01 -0.19 -0.17 -0.05 -0.1   0.08 -0.09 -0.14] w2 [-0.01 -0.11  0.03 -0.06 -0.03 -0.06  0.2  -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.   -0.17 -0.06 -0.06  0.09  0.05] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.  ] b3 [-0.08 -0.06]\n",
            "epoch: 1501 loss 0.6925 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.03  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            " -0.02 -0.19 -0.17 -0.05 -0.1   0.09 -0.09 -0.14] w2 [-0.01 -0.11  0.03 -0.06 -0.03 -0.06  0.2  -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [-0.   -0.18 -0.06 -0.06  0.09  0.05] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.09  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 1601 loss 0.6924 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.02  0.15 -0.02 -0.02  0.16  0.09 -0.05  0.05 -0.05 -0.05\n",
            " -0.02 -0.19 -0.17 -0.05 -0.1   0.09 -0.09 -0.14] w2 [-0.01 -0.11  0.03 -0.06 -0.03 -0.06  0.21 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.   -0.18 -0.06 -0.06  0.09  0.05] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 1701 loss 0.6922 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.02  0.15 -0.02 -0.02  0.16  0.1  -0.05  0.05 -0.05 -0.05\n",
            " -0.02 -0.19 -0.17 -0.05 -0.1   0.1  -0.09 -0.14] w2 [-0.01 -0.11  0.03 -0.06 -0.03 -0.06  0.21 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.01 -0.19 -0.05 -0.06  0.08  0.06] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 1801 loss 0.692 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.04 -0.01  0.01  0.15 -0.02 -0.02  0.16  0.1  -0.05  0.05 -0.05 -0.05\n",
            " -0.03 -0.19 -0.17 -0.05 -0.1   0.11 -0.09 -0.14] w2 [-0.01 -0.11  0.03 -0.06 -0.03 -0.06  0.22 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.01 -0.19 -0.05 -0.06  0.08  0.06] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 1901 loss 0.6918 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01  0.01  0.15 -0.02 -0.02  0.16  0.1  -0.05  0.05 -0.05 -0.05\n",
            " -0.03 -0.19 -0.17 -0.05 -0.1   0.11 -0.09 -0.14] w2 [-0.01 -0.11  0.03 -0.06 -0.03 -0.06  0.22 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.02 -0.2  -0.05 -0.07  0.08  0.06] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 2001 loss 0.6915 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01  0.    0.15 -0.02 -0.02  0.16  0.1  -0.05  0.05 -0.05 -0.05\n",
            " -0.04 -0.19 -0.17 -0.05 -0.1   0.12 -0.09 -0.14] w2 [-0.02 -0.11  0.03 -0.06 -0.03 -0.06  0.23 -0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.03 -0.2  -0.05 -0.07  0.08  0.06] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 2101 loss 0.6911 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01 -0.01  0.15 -0.02 -0.02  0.16  0.11 -0.05  0.05 -0.05 -0.05\n",
            " -0.05 -0.19 -0.17 -0.05 -0.1   0.13 -0.09 -0.14] w2 [-0.02 -0.11  0.03 -0.06 -0.03 -0.06  0.24  0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.03 -0.21 -0.05 -0.07  0.07  0.07] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 2201 loss 0.6906 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01 -0.01  0.15 -0.02 -0.02  0.16  0.11 -0.05  0.05 -0.05 -0.05\n",
            " -0.05 -0.19 -0.17 -0.05 -0.1   0.14 -0.09 -0.14] w2 [-0.02 -0.11  0.03 -0.06 -0.03 -0.06  0.24  0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.04 -0.22 -0.05 -0.07  0.07  0.07] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.08 -0.06]\n",
            "epoch: 2301 loss 0.6899 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01 -0.02  0.15 -0.02 -0.02  0.16  0.11 -0.05  0.05 -0.05 -0.05\n",
            " -0.06 -0.19 -0.17 -0.05 -0.1   0.15 -0.09 -0.14] w2 [-0.02 -0.12  0.03 -0.06 -0.03 -0.06  0.26  0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.05 -0.23 -0.05 -0.07  0.06  0.08] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.09 -0.06]\n",
            "epoch: 2401 loss 0.6889 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01 -0.03  0.15 -0.02 -0.02  0.16  0.12 -0.05  0.05 -0.05 -0.05\n",
            " -0.07 -0.19 -0.17 -0.06 -0.1   0.17 -0.09 -0.14] w2 [-0.03 -0.12  0.03 -0.06 -0.03 -0.06  0.27  0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.07 -0.24 -0.05 -0.07  0.06  0.08] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.02 -0.01] b3 [-0.09 -0.06]\n",
            "epoch: 2501 loss 0.6877 y_pred [0.5 0.5 0.5 0.5] w1 [ 0.05 -0.01 -0.04  0.15 -0.02 -0.02  0.16  0.12 -0.05  0.05 -0.04 -0.05\n",
            " -0.08 -0.19 -0.17 -0.06 -0.1   0.18 -0.09 -0.14] w2 [-0.03 -0.12  0.03 -0.06 -0.03 -0.06  0.29  0.   -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.08 -0.26 -0.04 -0.07  0.05  0.09] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.01 -0.01] b3 [-0.09 -0.06]\n",
            "epoch: 2601 loss 0.6859 y_pred [0.51 0.49 0.5  0.5 ] w1 [ 0.05 -0.01 -0.05  0.15 -0.02 -0.02  0.16  0.13 -0.05  0.05 -0.04 -0.05\n",
            " -0.09 -0.19 -0.17 -0.06 -0.1   0.2  -0.09 -0.14] w2 [-0.04 -0.12  0.03 -0.06 -0.03 -0.06  0.31  0.01 -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.1  -0.27 -0.04 -0.07  0.05  0.09] b1 [ 0.15 -0.02  0.01 -0.14 -0.05] b2 [ 0.08  0.01 -0.  ] b3 [-0.09 -0.05]\n",
            "epoch: 2701 loss 0.6835 y_pred [0.51 0.49 0.5  0.5 ] w1 [ 0.06 -0.01 -0.06  0.15 -0.02 -0.03  0.16  0.14 -0.05  0.05 -0.04 -0.05\n",
            " -0.11 -0.19 -0.17 -0.06 -0.1   0.23 -0.09 -0.14] w2 [-0.04 -0.12  0.03 -0.06 -0.03 -0.06  0.33  0.01 -0.1   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.12 -0.29 -0.04 -0.08  0.04  0.1 ] b1 [ 0.15 -0.02  0.02 -0.14 -0.05] b2 [ 0.07  0.01 -0.  ] b3 [-0.09 -0.05]\n",
            "epoch: 2801 loss 0.6798 y_pred [0.51 0.49 0.5  0.5 ] w1 [ 0.06 -0.01 -0.08  0.15 -0.02 -0.03  0.16  0.15 -0.05  0.05 -0.04 -0.05\n",
            " -0.12 -0.19 -0.17 -0.07 -0.1   0.26 -0.09 -0.14] w2 [-0.05 -0.12  0.03 -0.06 -0.03 -0.06  0.36  0.01 -0.11  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.14 -0.32 -0.04 -0.08  0.03  0.11] b1 [ 0.15 -0.02  0.03 -0.14 -0.05] b2 [ 0.07  0.01 -0.  ] b3 [-0.09 -0.05]\n",
            "epoch: 2901 loss 0.6742 y_pred [0.51 0.49 0.49 0.51] w1 [ 0.06 -0.01 -0.09  0.15 -0.02 -0.03  0.16  0.16 -0.05  0.05 -0.03 -0.05\n",
            " -0.14 -0.19 -0.17 -0.07 -0.1   0.29 -0.09 -0.14] w2 [-0.06 -0.12  0.03 -0.06 -0.03 -0.06  0.4   0.01 -0.12  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.17 -0.35 -0.04 -0.08  0.02  0.12] b1 [ 0.15 -0.02  0.04 -0.14 -0.05] b2 [ 0.07  0.01 -0.  ] b3 [-0.1  -0.05]\n",
            "epoch: 3001 loss 0.6652 y_pred [0.52 0.48 0.49 0.51] w1 [ 0.07 -0.01 -0.11  0.15 -0.02 -0.03  0.16  0.17 -0.05  0.05 -0.03 -0.05\n",
            " -0.16 -0.19 -0.17 -0.08 -0.1   0.33 -0.09 -0.14] w2 [-0.07 -0.12  0.04 -0.06 -0.03 -0.06  0.44  0.02 -0.13  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.21 -0.39 -0.03 -0.09  0.01  0.13] b1 [ 0.15 -0.02  0.05 -0.14 -0.05] b2 [ 0.06  0.01 -0.  ] b3 [-0.1  -0.04]\n",
            "epoch: 3101 loss 0.6504 y_pred [0.53 0.47 0.49 0.51] w1 [ 0.08 -0.01 -0.14  0.15 -0.02 -0.03  0.16  0.19 -0.05  0.05 -0.02 -0.05\n",
            " -0.18 -0.19 -0.17 -0.09 -0.1   0.39 -0.09 -0.14] w2 [-0.08 -0.12  0.04 -0.06 -0.03 -0.06  0.51  0.02 -0.14  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.26 -0.44 -0.03 -0.09 -0.    0.14] b1 [ 0.15 -0.02  0.07 -0.14 -0.05] b2 [ 0.04  0.01 -0.  ] b3 [-0.11 -0.03]\n",
            "epoch: 3201 loss 0.625 y_pred [0.55 0.45 0.48 0.52] w1 [ 0.09 -0.01 -0.17  0.15 -0.02 -0.04  0.16  0.22 -0.05  0.05 -0.01 -0.05\n",
            " -0.22 -0.19 -0.17 -0.1  -0.1   0.45 -0.09 -0.14] w2 [-0.1  -0.12  0.04 -0.06 -0.03 -0.06  0.59  0.03 -0.16  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.32 -0.5  -0.02 -0.1  -0.02  0.16] b1 [ 0.15 -0.02  0.09 -0.14 -0.05] b2 [ 0.02  0.01 -0.  ] b3 [-0.12 -0.02]\n",
            "epoch: 3301 loss 0.5815 y_pred [0.58 0.42 0.46 0.54] w1 [ 0.1  -0.01 -0.21  0.15 -0.02 -0.04  0.16  0.25 -0.05  0.05  0.01 -0.05\n",
            " -0.26 -0.19 -0.17 -0.12 -0.1   0.54 -0.09 -0.14] w2 [-0.13 -0.12  0.05 -0.06 -0.03 -0.06  0.69  0.04 -0.18  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.41 -0.58 -0.01 -0.11 -0.05  0.19] b1 [ 0.16 -0.02  0.12 -0.14 -0.05] b2 [-0.02  0.01  0.  ] b3 [-0.13 -0.01]\n",
            "epoch: 3401 loss 0.5108 y_pred [0.62 0.38 0.42 0.58] w1 [ 0.13 -0.01 -0.25  0.15 -0.02 -0.04  0.16  0.29 -0.05  0.05  0.03 -0.05\n",
            " -0.31 -0.19 -0.17 -0.14 -0.1   0.65 -0.09 -0.14] w2 [-0.18 -0.13  0.06 -0.06 -0.03 -0.06  0.82  0.06 -0.22  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.51 -0.69 -0.   -0.12 -0.08  0.22] b1 [ 0.17 -0.02  0.15 -0.14 -0.05] b2 [-0.08  0.01  0.01] b3 [-0.15  0.01]\n",
            "epoch: 3501 loss 0.4127 y_pred [0.68 0.32 0.36 0.64] w1 [ 0.16 -0.01 -0.31  0.15 -0.02 -0.04  0.16  0.33 -0.05  0.05  0.06 -0.05\n",
            " -0.37 -0.19 -0.17 -0.16 -0.1   0.76 -0.09 -0.14] w2 [-0.23 -0.13  0.07 -0.06 -0.03 -0.06  0.95  0.08 -0.27  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.65 -0.82  0.01 -0.13 -0.12  0.26] b1 [ 0.19 -0.02  0.19 -0.14 -0.05] b2 [-0.18  0.01  0.02] b3 [-0.18  0.03]\n",
            "epoch: 3601 loss 0.3069 y_pred [0.75 0.25 0.28 0.72] w1 [ 0.2  -0.01 -0.36  0.15 -0.02 -0.04  0.16  0.37 -0.05  0.05  0.1  -0.05\n",
            " -0.42 -0.19 -0.17 -0.18 -0.1   0.87 -0.09 -0.14] w2 [-0.3  -0.14  0.09 -0.06 -0.03 -0.06  1.08  0.1  -0.32  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.78 -0.96  0.03 -0.15 -0.16  0.3 ] b1 [ 0.22 -0.02  0.22 -0.14 -0.05] b2 [-0.28  0.    0.03] b3 [-0.2   0.05]\n",
            "epoch: 3701 loss 0.2195 y_pred [0.82 0.18 0.21 0.79] w1 [ 0.24 -0.01 -0.4   0.15 -0.02 -0.04  0.16  0.4  -0.05  0.05  0.14 -0.05\n",
            " -0.47 -0.19 -0.17 -0.21 -0.1   0.97 -0.09 -0.14] w2 [-0.37 -0.15  0.11 -0.06 -0.03 -0.06  1.19  0.13 -0.38  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 0.92 -1.09  0.05 -0.17 -0.21  0.35] b1 [ 0.25 -0.02  0.25 -0.14 -0.05] b2 [-0.37  0.    0.04] b3 [-0.21  0.07]\n",
            "epoch: 3801 loss 0.1588 y_pred [0.86 0.14 0.15 0.85] w1 [ 0.28 -0.01 -0.44  0.15 -0.02 -0.04  0.16  0.43 -0.05  0.05  0.17 -0.05\n",
            " -0.5  -0.19 -0.17 -0.22 -0.1   1.04 -0.09 -0.14] w2 [-0.42 -0.16  0.13 -0.06 -0.03 -0.06  1.27  0.15 -0.43  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.03 -1.2   0.07 -0.19 -0.25  0.39] b1 [ 0.28 -0.02  0.27 -0.14 -0.05] b2 [-0.45 -0.    0.06] b3 [-0.22  0.08]\n",
            "epoch: 3901 loss 0.119 y_pred [0.89 0.11 0.12 0.88] w1 [ 0.31 -0.01 -0.46  0.15 -0.02 -0.04  0.16  0.45 -0.05  0.05  0.2  -0.05\n",
            " -0.53 -0.19 -0.17 -0.24 -0.1   1.1  -0.09 -0.14] w2 [-0.47 -0.16  0.15 -0.06 -0.03 -0.06  1.33  0.17 -0.47  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.12 -1.3   0.09 -0.21 -0.29  0.43] b1 [ 0.3  -0.02  0.29 -0.14 -0.05] b2 [-0.5  -0.    0.07] b3 [-0.23  0.08]\n",
            "epoch: 4001 loss 0.0926 y_pred [0.92 0.08 0.09 0.91] w1 [ 0.34 -0.01 -0.48  0.15 -0.02 -0.03  0.16  0.46 -0.05  0.05  0.22 -0.05\n",
            " -0.55 -0.19 -0.17 -0.25 -0.1   1.14 -0.09 -0.14] w2 [-0.51 -0.17  0.17 -0.06 -0.03 -0.06  1.37  0.19 -0.5   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.19 -1.37  0.1  -0.22 -0.32  0.46] b1 [ 0.33 -0.02  0.3  -0.14 -0.05] b2 [-0.54 -0.01  0.08] b3 [-0.23  0.09]\n",
            "epoch: 4101 loss 0.0745 y_pred [0.93 0.07 0.07 0.93] w1 [ 0.36 -0.01 -0.5   0.15 -0.02 -0.03  0.16  0.48 -0.05  0.05  0.24 -0.05\n",
            " -0.57 -0.19 -0.17 -0.26 -0.1   1.18 -0.09 -0.14] w2 [-0.54 -0.18  0.19 -0.06 -0.03 -0.06  1.41  0.21 -0.54  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.26 -1.43  0.12 -0.24 -0.35  0.49] b1 [ 0.34 -0.02  0.31 -0.14 -0.05] b2 [-0.56 -0.01  0.09] b3 [-0.24  0.09]\n",
            "epoch: 4201 loss 0.0615 y_pred [0.94 0.06 0.06 0.94] w1 [ 0.38 -0.01 -0.51  0.15 -0.02 -0.03  0.16  0.49 -0.05  0.05  0.26 -0.05\n",
            " -0.58 -0.19 -0.17 -0.27 -0.1   1.2  -0.09 -0.14] w2 [-0.56 -0.19  0.2  -0.06 -0.03 -0.06  1.43  0.22 -0.56  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.31 -1.49  0.13 -0.25 -0.37  0.51] b1 [ 0.36 -0.02  0.32 -0.14 -0.05] b2 [-0.59 -0.01  0.1 ] b3 [-0.24  0.09]\n",
            "epoch: 4301 loss 0.052 y_pred [0.95 0.05 0.05 0.95] w1 [ 0.39 -0.01 -0.52  0.15 -0.02 -0.03  0.16  0.5  -0.05  0.05  0.27 -0.05\n",
            " -0.59 -0.19 -0.17 -0.27 -0.1   1.23 -0.09 -0.14] w2 [-0.59 -0.19  0.22 -0.06 -0.03 -0.06  1.46  0.24 -0.58  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.36 -1.53  0.14 -0.26 -0.4   0.54] b1 [ 0.37 -0.02  0.33 -0.14 -0.05] b2 [-0.61 -0.01  0.11] b3 [-0.24  0.1 ]\n",
            "epoch: 4401 loss 0.0448 y_pred [0.96 0.04 0.05 0.95] w1 [ 0.41 -0.01 -0.53  0.15 -0.02 -0.03  0.16  0.5  -0.05  0.05  0.29 -0.05\n",
            " -0.6  -0.19 -0.17 -0.28 -0.1   1.25 -0.09 -0.14] w2 [-0.6  -0.2   0.23 -0.06 -0.03 -0.06  1.47  0.25 -0.6   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.39 -1.57  0.15 -0.27 -0.42  0.56] b1 [ 0.38 -0.02  0.33 -0.14 -0.05] b2 [-0.62 -0.01  0.12] b3 [-0.24  0.1 ]\n",
            "epoch: 4501 loss 0.0391 y_pred [0.96 0.04 0.04 0.96] w1 [ 0.42 -0.01 -0.54  0.15 -0.02 -0.03  0.16  0.51 -0.05  0.05  0.3  -0.05\n",
            " -0.61 -0.19 -0.17 -0.28 -0.1   1.27 -0.09 -0.14] w2 [-0.62 -0.2   0.24 -0.06 -0.03 -0.06  1.49  0.26 -0.62  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.43 -1.61  0.16 -0.28 -0.44  0.58] b1 [ 0.39 -0.02  0.34 -0.14 -0.05] b2 [-0.63 -0.01  0.13] b3 [-0.24  0.1 ]\n",
            "epoch: 4601 loss 0.0346 y_pred [0.97 0.03 0.03 0.97] w1 [ 0.43 -0.01 -0.55  0.15 -0.02 -0.03  0.16  0.52 -0.05  0.05  0.31 -0.05\n",
            " -0.62 -0.19 -0.17 -0.29 -0.1   1.28 -0.09 -0.14] w2 [-0.63 -0.21  0.25 -0.06 -0.03 -0.06  1.5   0.27 -0.64  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.46 -1.64  0.17 -0.29 -0.46  0.6 ] b1 [ 0.4  -0.02  0.34 -0.14 -0.05] b2 [-0.64 -0.01  0.13] b3 [-0.24  0.1 ]\n",
            "epoch: 4701 loss 0.0309 y_pred [0.97 0.03 0.03 0.97] w1 [ 0.44 -0.01 -0.55  0.15 -0.02 -0.03  0.16  0.52 -0.05  0.05  0.32 -0.05\n",
            " -0.63 -0.19 -0.17 -0.29 -0.1   1.3  -0.09 -0.14] w2 [-0.64 -0.21  0.27 -0.06 -0.03 -0.06  1.52  0.28 -0.65  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.49 -1.67  0.18 -0.3  -0.47  0.61] b1 [ 0.41 -0.02  0.35 -0.14 -0.05] b2 [-0.65 -0.02  0.14] b3 [-0.24  0.1 ]\n",
            "epoch: 4801 loss 0.0279 y_pred [0.97 0.03 0.03 0.97] w1 [ 0.45 -0.01 -0.56  0.15 -0.02 -0.03  0.16  0.53 -0.05  0.05  0.32 -0.05\n",
            " -0.63 -0.19 -0.17 -0.3  -0.1   1.31 -0.09 -0.14] w2 [-0.65 -0.22  0.28 -0.06 -0.03 -0.06  1.53  0.29 -0.67  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.51 -1.69  0.19 -0.31 -0.49  0.63] b1 [ 0.41 -0.02  0.35 -0.14 -0.05] b2 [-0.66 -0.02  0.15] b3 [-0.25  0.1 ]\n",
            "epoch: 4901 loss 0.0253 y_pred [0.98 0.02 0.03 0.97] w1 [ 0.45 -0.01 -0.56  0.15 -0.02 -0.03  0.16  0.53 -0.05  0.05  0.33 -0.05\n",
            " -0.64 -0.19 -0.17 -0.3  -0.1   1.32 -0.09 -0.14] w2 [-0.66 -0.22  0.28 -0.06 -0.03 -0.06  1.54  0.3  -0.68  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.54 -1.72  0.2  -0.32 -0.5   0.64] b1 [ 0.42 -0.02  0.35 -0.14 -0.05] b2 [-0.67 -0.02  0.15] b3 [-0.25  0.1 ]\n",
            "epoch: 5001 loss 0.0231 y_pred [0.98 0.02 0.02 0.98] w1 [ 0.46 -0.01 -0.57  0.15 -0.02 -0.03  0.16  0.53 -0.05  0.05  0.34 -0.05\n",
            " -0.64 -0.19 -0.17 -0.3  -0.1   1.33 -0.09 -0.14] w2 [-0.67 -0.22  0.29 -0.06 -0.03 -0.06  1.54  0.31 -0.69  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.56 -1.74  0.21 -0.32 -0.51  0.65] b1 [ 0.43 -0.02  0.36 -0.14 -0.05] b2 [-0.67 -0.02  0.16] b3 [-0.25  0.1 ]\n",
            "epoch: 5101 loss 0.0213 y_pred [0.98 0.02 0.02 0.98] w1 [ 0.47 -0.01 -0.57  0.15 -0.02 -0.03  0.16  0.54 -0.05  0.05  0.34 -0.05\n",
            " -0.65 -0.19 -0.17 -0.31 -0.1   1.34 -0.09 -0.14] w2 [-0.68 -0.23  0.3  -0.06 -0.03 -0.06  1.55  0.32 -0.7   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.58 -1.76  0.21 -0.33 -0.53  0.67] b1 [ 0.43 -0.02  0.36 -0.14 -0.05] b2 [-0.68 -0.02  0.16] b3 [-0.25  0.1 ]\n",
            "epoch: 5201 loss 0.0197 y_pred [0.98 0.02 0.02 0.98] w1 [ 0.48 -0.01 -0.58  0.15 -0.02 -0.03  0.16  0.54 -0.05  0.05  0.35 -0.05\n",
            " -0.65 -0.19 -0.17 -0.31 -0.1   1.35 -0.09 -0.14] w2 [-0.69 -0.23  0.31 -0.06 -0.03 -0.06  1.56  0.33 -0.71  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.6  -1.77  0.22 -0.34 -0.54  0.68] b1 [ 0.44 -0.02  0.36 -0.14 -0.05] b2 [-0.68 -0.02  0.17] b3 [-0.25  0.1 ]\n",
            "epoch: 5301 loss 0.0183 y_pred [0.98 0.02 0.02 0.98] w1 [ 0.48 -0.01 -0.58  0.15 -0.02 -0.03  0.16  0.54 -0.05  0.05  0.36 -0.05\n",
            " -0.66 -0.19 -0.17 -0.31 -0.1   1.36 -0.09 -0.14] w2 [-0.69 -0.24  0.32 -0.06 -0.03 -0.06  1.56  0.33 -0.72  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.61 -1.79  0.22 -0.34 -0.55  0.69] b1 [ 0.44 -0.02  0.37 -0.14 -0.05] b2 [-0.69 -0.02  0.17] b3 [-0.25  0.1 ]\n",
            "epoch: 5401 loss 0.0171 y_pred [0.98 0.02 0.02 0.98] w1 [ 0.49 -0.01 -0.58  0.15 -0.02 -0.02  0.16  0.55 -0.05  0.05  0.36 -0.05\n",
            " -0.66 -0.19 -0.17 -0.31 -0.1   1.36 -0.09 -0.14] w2 [-0.7  -0.24  0.32 -0.06 -0.03 -0.06  1.57  0.34 -0.72  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.63 -1.81  0.23 -0.35 -0.56  0.7 ] b1 [ 0.45 -0.02  0.37 -0.14 -0.05] b2 [-0.69 -0.02  0.18] b3 [-0.25  0.1 ]\n",
            "epoch: 5501 loss 0.016 y_pred [0.98 0.02 0.02 0.98] w1 [ 0.49 -0.01 -0.59  0.15 -0.02 -0.02  0.16  0.55 -0.05  0.05  0.37 -0.05\n",
            " -0.66 -0.19 -0.17 -0.32 -0.1   1.37 -0.09 -0.14] w2 [-0.7  -0.24  0.33 -0.06 -0.03 -0.06  1.57  0.35 -0.73  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.64 -1.82  0.24 -0.35 -0.57  0.71] b1 [ 0.45 -0.02  0.37 -0.14 -0.05] b2 [-0.7  -0.02  0.18] b3 [-0.25  0.1 ]\n",
            "epoch: 5601 loss 0.015 y_pred [0.99 0.01 0.02 0.98] w1 [ 0.5  -0.01 -0.59  0.15 -0.02 -0.02  0.16  0.55 -0.05  0.05  0.37 -0.05\n",
            " -0.67 -0.19 -0.17 -0.32 -0.1   1.38 -0.09 -0.14] w2 [-0.71 -0.24  0.34 -0.06 -0.03 -0.06  1.58  0.35 -0.74  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.66 -1.84  0.24 -0.36 -0.58  0.72] b1 [ 0.45 -0.02  0.37 -0.14 -0.05] b2 [-0.7  -0.02  0.18] b3 [-0.25  0.1 ]\n",
            "epoch: 5701 loss 0.0141 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.5  -0.01 -0.59  0.15 -0.02 -0.02  0.16  0.55 -0.05  0.05  0.37 -0.05\n",
            " -0.67 -0.19 -0.17 -0.32 -0.1   1.38 -0.09 -0.14] w2 [-0.71 -0.25  0.34 -0.06 -0.03 -0.06  1.58  0.36 -0.75  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.67 -1.85  0.25 -0.36 -0.59  0.73] b1 [ 0.46 -0.02  0.37 -0.14 -0.05] b2 [-0.7  -0.02  0.19] b3 [-0.25  0.1 ]\n",
            "epoch: 5801 loss 0.0134 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.51 -0.01 -0.6   0.15 -0.02 -0.02  0.16  0.55 -0.05  0.05  0.38 -0.05\n",
            " -0.67 -0.19 -0.17 -0.32 -0.1   1.39 -0.09 -0.14] w2 [-0.72 -0.25  0.35 -0.06 -0.03 -0.06  1.59  0.36 -0.75  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.68 -1.86  0.25 -0.37 -0.6   0.74] b1 [ 0.46 -0.02  0.38 -0.14 -0.05] b2 [-0.71 -0.03  0.19] b3 [-0.25  0.11]\n",
            "epoch: 5901 loss 0.0126 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.51 -0.01 -0.6   0.15 -0.02 -0.02  0.16  0.56 -0.05  0.05  0.38 -0.05\n",
            " -0.68 -0.19 -0.17 -0.33 -0.1   1.4  -0.09 -0.14] w2 [-0.72 -0.25  0.35 -0.06 -0.03 -0.06  1.59  0.37 -0.76  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.7  -1.87  0.26 -0.37 -0.6   0.74] b1 [ 0.46 -0.02  0.38 -0.14 -0.05] b2 [-0.71 -0.03  0.19] b3 [-0.25  0.11]\n",
            "epoch: 6001 loss 0.012 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.51 -0.01 -0.6   0.15 -0.02 -0.02  0.16  0.56 -0.05  0.05  0.39 -0.05\n",
            " -0.68 -0.19 -0.17 -0.33 -0.1   1.4  -0.09 -0.14] w2 [-0.73 -0.26  0.36 -0.06 -0.03 -0.06  1.6   0.37 -0.76  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.71 -1.88  0.26 -0.38 -0.61  0.75] b1 [ 0.47 -0.02  0.38 -0.14 -0.05] b2 [-0.71 -0.03  0.2 ] b3 [-0.25  0.11]\n",
            "epoch: 6101 loss 0.0114 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.52 -0.01 -0.6   0.15 -0.02 -0.02  0.16  0.56 -0.05  0.05  0.39 -0.05\n",
            " -0.68 -0.19 -0.17 -0.33 -0.1   1.41 -0.09 -0.14] w2 [-0.73 -0.26  0.36 -0.06 -0.03 -0.06  1.6   0.38 -0.77  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.72 -1.9   0.27 -0.38 -0.62  0.76] b1 [ 0.47 -0.02  0.38 -0.14 -0.05] b2 [-0.71 -0.03  0.2 ] b3 [-0.25  0.11]\n",
            "epoch: 6201 loss 0.0109 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.52 -0.01 -0.6   0.15 -0.02 -0.02  0.16  0.56 -0.05  0.05  0.39 -0.05\n",
            " -0.68 -0.19 -0.17 -0.33 -0.1   1.41 -0.09 -0.14] w2 [-0.73 -0.26  0.37 -0.06 -0.03 -0.06  1.6   0.38 -0.78  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.73 -1.91  0.27 -0.39 -0.63  0.77] b1 [ 0.47 -0.02  0.38 -0.14 -0.05] b2 [-0.71 -0.03  0.2 ] b3 [-0.25  0.11]\n",
            "epoch: 6301 loss 0.0104 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.52 -0.01 -0.61  0.15 -0.02 -0.02  0.16  0.56 -0.05  0.05  0.39 -0.05\n",
            " -0.68 -0.19 -0.17 -0.33 -0.1   1.42 -0.09 -0.14] w2 [-0.74 -0.26  0.37 -0.06 -0.03 -0.06  1.61  0.39 -0.78  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.74 -1.92  0.27 -0.39 -0.63  0.77] b1 [ 0.47 -0.02  0.38 -0.14 -0.05] b2 [-0.72 -0.03  0.2 ] b3 [-0.25  0.11]\n",
            "epoch: 6401 loss 0.0099 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.53 -0.01 -0.61  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.4  -0.05\n",
            " -0.69 -0.19 -0.17 -0.33 -0.1   1.42 -0.09 -0.14] w2 [-0.74 -0.27  0.38 -0.06 -0.03 -0.06  1.61  0.39 -0.79  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.75 -1.93  0.28 -0.4  -0.64  0.78] b1 [ 0.48 -0.02  0.38 -0.14 -0.05] b2 [-0.72 -0.03  0.21] b3 [-0.25  0.11]\n",
            "epoch: 6501 loss 0.0095 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.53 -0.01 -0.61  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.4  -0.05\n",
            " -0.69 -0.19 -0.17 -0.34 -0.1   1.42 -0.09 -0.14] w2 [-0.74 -0.27  0.38 -0.06 -0.03 -0.06  1.61  0.4  -0.79  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.76 -1.93  0.28 -0.4  -0.65  0.79] b1 [ 0.48 -0.02  0.39 -0.14 -0.05] b2 [-0.72 -0.03  0.21] b3 [-0.25  0.11]\n",
            "epoch: 6601 loss 0.0091 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.53 -0.01 -0.61  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.4  -0.05\n",
            " -0.69 -0.19 -0.17 -0.34 -0.1   1.43 -0.09 -0.14] w2 [-0.75 -0.27  0.39 -0.06 -0.03 -0.06  1.61  0.4  -0.79  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.76 -1.94  0.29 -0.4  -0.65  0.79] b1 [ 0.48 -0.02  0.39 -0.14 -0.05] b2 [-0.72 -0.03  0.21] b3 [-0.25  0.11]\n",
            "epoch: 6701 loss 0.0088 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.54 -0.01 -0.61  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.41 -0.05\n",
            " -0.69 -0.19 -0.17 -0.34 -0.1   1.43 -0.09 -0.14] w2 [-0.75 -0.27  0.39 -0.06 -0.03 -0.06  1.62  0.4  -0.8   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.77 -1.95  0.29 -0.41 -0.66  0.8 ] b1 [ 0.48 -0.02  0.39 -0.14 -0.05] b2 [-0.72 -0.03  0.21] b3 [-0.25  0.11]\n",
            "epoch: 6801 loss 0.0085 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.54 -0.01 -0.62  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.41 -0.05\n",
            " -0.69 -0.19 -0.17 -0.34 -0.1   1.44 -0.09 -0.14] w2 [-0.75 -0.28  0.39 -0.06 -0.03 -0.06  1.62  0.41 -0.8   0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.78 -1.96  0.29 -0.41 -0.66  0.8 ] b1 [ 0.49 -0.02  0.39 -0.14 -0.05] b2 [-0.73 -0.03  0.22] b3 [-0.25  0.11]\n",
            "epoch: 6901 loss 0.0081 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.54 -0.01 -0.62  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.41 -0.05\n",
            " -0.7  -0.19 -0.17 -0.34 -0.1   1.44 -0.09 -0.14] w2 [-0.75 -0.28  0.4  -0.06 -0.03 -0.06  1.62  0.41 -0.81  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.79 -1.97  0.3  -0.42 -0.67  0.81] b1 [ 0.49 -0.02  0.39 -0.14 -0.05] b2 [-0.73 -0.03  0.22] b3 [-0.25  0.11]\n",
            "epoch: 7001 loss 0.0079 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.54 -0.01 -0.62  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.41 -0.05\n",
            " -0.7  -0.19 -0.17 -0.34 -0.1   1.44 -0.09 -0.14] w2 [-0.76 -0.28  0.4  -0.06 -0.03 -0.06  1.62  0.42 -0.81  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.8  -1.97  0.3  -0.42 -0.67  0.81] b1 [ 0.49 -0.02  0.39 -0.14 -0.05] b2 [-0.73 -0.03  0.22] b3 [-0.25  0.11]\n",
            "epoch: 7101 loss 0.0076 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.55 -0.01 -0.62  0.15 -0.02 -0.02  0.16  0.57 -0.05  0.05  0.42 -0.05\n",
            " -0.7  -0.19 -0.17 -0.34 -0.1   1.45 -0.09 -0.14] w2 [-0.76 -0.28  0.4  -0.06 -0.03 -0.06  1.63  0.42 -0.81  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.8  -1.98  0.3  -0.42 -0.68  0.82] b1 [ 0.49 -0.02  0.39 -0.14 -0.05] b2 [-0.73 -0.03  0.22] b3 [-0.25  0.11]\n",
            "epoch: 7201 loss 0.0073 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.55 -0.01 -0.62  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.42 -0.05\n",
            " -0.7  -0.19 -0.17 -0.34 -0.1   1.45 -0.09 -0.14] w2 [-0.76 -0.28  0.41 -0.06 -0.03 -0.06  1.63  0.42 -0.82  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.81 -1.99  0.31 -0.43 -0.68  0.82] b1 [ 0.49 -0.02  0.39 -0.14 -0.05] b2 [-0.73 -0.03  0.22] b3 [-0.25  0.11]\n",
            "epoch: 7301 loss 0.0071 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.55 -0.01 -0.62  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.42 -0.05\n",
            " -0.7  -0.19 -0.17 -0.35 -0.1   1.45 -0.09 -0.14] w2 [-0.76 -0.29  0.41 -0.06 -0.03 -0.06  1.63  0.43 -0.82  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.82 -1.99  0.31 -0.43 -0.69  0.83] b1 [ 0.5  -0.02  0.39 -0.14 -0.05] b2 [-0.73 -0.04  0.22] b3 [-0.25  0.11]\n",
            "epoch: 7401 loss 0.0069 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.55 -0.01 -0.62  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.42 -0.05\n",
            " -0.7  -0.19 -0.17 -0.35 -0.1   1.45 -0.09 -0.14] w2 [-0.76 -0.29  0.41 -0.06 -0.03 -0.06  1.63  0.43 -0.82  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.82 -2.    0.31 -0.43 -0.69  0.83] b1 [ 0.5  -0.02  0.4  -0.14 -0.05] b2 [-0.73 -0.04  0.23] b3 [-0.25  0.11]\n",
            "epoch: 7501 loss 0.0067 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.56 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.42 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.46 -0.09 -0.14] w2 [-0.77 -0.29  0.42 -0.06 -0.03 -0.06  1.63  0.43 -0.83  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.83 -2.01  0.32 -0.43 -0.7   0.84] b1 [ 0.5  -0.02  0.4  -0.14 -0.05] b2 [-0.73 -0.04  0.23] b3 [-0.25  0.11]\n",
            "epoch: 7601 loss 0.0065 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.56 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.43 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.46 -0.09 -0.14] w2 [-0.77 -0.29  0.42 -0.06 -0.03 -0.06  1.63  0.43 -0.83  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.84 -2.01  0.32 -0.44 -0.7   0.84] b1 [ 0.5  -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.23] b3 [-0.25  0.11]\n",
            "epoch: 7701 loss 0.0063 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.56 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.43 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.46 -0.09 -0.14] w2 [-0.77 -0.29  0.42 -0.06 -0.03 -0.06  1.64  0.44 -0.83  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.84 -2.02  0.32 -0.44 -0.71  0.85] b1 [ 0.5  -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.23] b3 [-0.25  0.11]\n",
            "epoch: 7801 loss 0.0061 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.56 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.43 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.47 -0.09 -0.14] w2 [-0.77 -0.29  0.43 -0.06 -0.03 -0.06  1.64  0.44 -0.84  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.85 -2.03  0.33 -0.44 -0.71  0.85] b1 [ 0.5  -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.23] b3 [-0.25  0.11]\n",
            "epoch: 7901 loss 0.0059 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.56 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.43 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.47 -0.09 -0.14] w2 [-0.77 -0.3   0.43 -0.06 -0.03 -0.06  1.64  0.44 -0.84  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.85 -2.03  0.33 -0.45 -0.72  0.86] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.23] b3 [-0.25  0.11]\n",
            "epoch: 8001 loss 0.0058 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.57 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.43 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.47 -0.09 -0.14] w2 [-0.77 -0.3   0.43 -0.06 -0.03 -0.06  1.64  0.45 -0.84  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.86 -2.04  0.33 -0.45 -0.72  0.86] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.23] b3 [-0.25  0.11]\n",
            "epoch: 8101 loss 0.0056 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.57 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.58 -0.05  0.05  0.43 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.47 -0.09 -0.14] w2 [-0.78 -0.3   0.43 -0.06 -0.03 -0.06  1.64  0.45 -0.85  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.86 -2.04  0.33 -0.45 -0.72  0.86] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8201 loss 0.0055 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.57 -0.01 -0.63  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.44 -0.05\n",
            " -0.71 -0.19 -0.17 -0.35 -0.1   1.48 -0.09 -0.14] w2 [-0.78 -0.3   0.44 -0.06 -0.03 -0.06  1.64  0.45 -0.85  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.87 -2.05  0.34 -0.45 -0.73  0.87] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8301 loss 0.0053 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.57 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.44 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.48 -0.09 -0.14] w2 [-0.78 -0.3   0.44 -0.06 -0.03 -0.06  1.65  0.45 -0.85  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.87 -2.05  0.34 -0.46 -0.73  0.87] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8401 loss 0.0052 y_pred [0.99 0.01 0.01 0.99] w1 [ 0.57 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.44 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.48 -0.09 -0.14] w2 [-0.78 -0.3   0.44 -0.06 -0.03 -0.06  1.65  0.46 -0.85  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.88 -2.06  0.34 -0.46 -0.74  0.88] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8501 loss 0.0051 y_pred [0.99 0.01 0.   1.  ] w1 [ 0.57 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.44 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.48 -0.09 -0.14] w2 [-0.78 -0.31  0.44 -0.06 -0.03 -0.06  1.65  0.46 -0.86  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.88 -2.06  0.34 -0.46 -0.74  0.88] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8601 loss 0.0049 y_pred [1. 0. 0. 1.] w1 [ 0.58 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.44 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.48 -0.09 -0.14] w2 [-0.78 -0.31  0.45 -0.06 -0.03 -0.06  1.65  0.46 -0.86  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.89 -2.07  0.35 -0.46 -0.74  0.88] b1 [ 0.51 -0.02  0.4  -0.14 -0.05] b2 [-0.74 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8701 loss 0.0048 y_pred [1. 0. 0. 1.] w1 [ 0.58 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.44 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.49 -0.09 -0.14] w2 [-0.78 -0.31  0.45 -0.06 -0.03 -0.06  1.65  0.46 -0.86  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.89 -2.07  0.35 -0.47 -0.75  0.89] b1 [ 0.52 -0.02  0.4  -0.14 -0.05] b2 [-0.75 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8801 loss 0.0047 y_pred [1. 0. 0. 1.] w1 [ 0.58 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.49 -0.09 -0.14] w2 [-0.79 -0.31  0.45 -0.06 -0.03 -0.06  1.65  0.47 -0.86  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.9  -2.08  0.35 -0.47 -0.75  0.89] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.24] b3 [-0.25  0.11]\n",
            "epoch: 8901 loss 0.0046 y_pred [1. 0. 0. 1.] w1 [ 0.58 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.49 -0.09 -0.14] w2 [-0.79 -0.31  0.45 -0.06 -0.03 -0.06  1.65  0.47 -0.86  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.9  -2.08  0.35 -0.47 -0.75  0.89] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9001 loss 0.0045 y_pred [1. 0. 0. 1.] w1 [ 0.58 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.49 -0.09 -0.14] w2 [-0.79 -0.31  0.45 -0.06 -0.03 -0.06  1.65  0.47 -0.87  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.91 -2.08  0.35 -0.47 -0.76  0.9 ] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9101 loss 0.0044 y_pred [1. 0. 0. 1.] w1 [ 0.58 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.49 -0.09 -0.14] w2 [-0.79 -0.31  0.46 -0.06 -0.03 -0.06  1.66  0.47 -0.87  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.91 -2.09  0.36 -0.48 -0.76  0.9 ] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9201 loss 0.0043 y_pred [1. 0. 0. 1.] w1 [ 0.58 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.5  -0.09 -0.14] w2 [-0.79 -0.31  0.46 -0.06 -0.03 -0.06  1.66  0.47 -0.87  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.91 -2.09  0.36 -0.48 -0.76  0.9 ] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9301 loss 0.0042 y_pred [1. 0. 0. 1.] w1 [ 0.59 -0.01 -0.64  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.72 -0.19 -0.17 -0.36 -0.1   1.5  -0.09 -0.14] w2 [-0.79 -0.32  0.46 -0.06 -0.03 -0.06  1.66  0.48 -0.87  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.92 -2.1   0.36 -0.48 -0.77  0.91] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9401 loss 0.0041 y_pred [1. 0. 0. 1.] w1 [ 0.59 -0.01 -0.65  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.73 -0.19 -0.17 -0.36 -0.1   1.5  -0.09 -0.14] w2 [-0.79 -0.32  0.46 -0.06 -0.03 -0.06  1.66  0.48 -0.88  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.92 -2.1   0.36 -0.48 -0.77  0.91] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9501 loss 0.0041 y_pred [1. 0. 0. 1.] w1 [ 0.59 -0.01 -0.65  0.15 -0.02 -0.02  0.16  0.59 -0.05  0.05  0.45 -0.05\n",
            " -0.73 -0.19 -0.17 -0.36 -0.1   1.5  -0.09 -0.14] w2 [-0.79 -0.32  0.46 -0.06 -0.03 -0.06  1.66  0.48 -0.88  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.93 -2.1   0.37 -0.48 -0.77  0.91] b1 [ 0.52 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.04  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9601 loss 0.004 y_pred [1. 0. 0. 1.] w1 [ 0.59 -0.01 -0.65  0.15 -0.02 -0.02  0.16  0.6  -0.05  0.05  0.46 -0.05\n",
            " -0.73 -0.19 -0.17 -0.37 -0.1   1.5  -0.09 -0.14] w2 [-0.8  -0.32  0.47 -0.06 -0.03 -0.06  1.66  0.48 -0.88  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.93 -2.11  0.37 -0.49 -0.78  0.92] b1 [ 0.53 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.05  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9701 loss 0.0039 y_pred [1. 0. 0. 1.] w1 [ 0.59 -0.01 -0.65  0.15 -0.02 -0.02  0.16  0.6  -0.05  0.05  0.46 -0.05\n",
            " -0.73 -0.19 -0.17 -0.37 -0.1   1.5  -0.09 -0.14] w2 [-0.8  -0.32  0.47 -0.06 -0.03 -0.06  1.66  0.48 -0.88  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.93 -2.11  0.37 -0.49 -0.78  0.92] b1 [ 0.53 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.05  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9801 loss 0.0038 y_pred [1. 0. 0. 1.] w1 [ 0.59 -0.01 -0.65  0.15 -0.02 -0.02  0.16  0.6  -0.05  0.05  0.46 -0.05\n",
            " -0.73 -0.19 -0.17 -0.37 -0.1   1.51 -0.09 -0.14] w2 [-0.8  -0.32  0.47 -0.06 -0.03 -0.06  1.66  0.49 -0.88  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.94 -2.12  0.37 -0.49 -0.78  0.92] b1 [ 0.53 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.05  0.25] b3 [-0.25  0.1 ]\n",
            "epoch: 9901 loss 0.0038 y_pred [1. 0. 0. 1.] w1 [ 0.59 -0.01 -0.65  0.15 -0.02 -0.02  0.16  0.6  -0.05  0.05  0.46 -0.05\n",
            " -0.73 -0.19 -0.17 -0.37 -0.1   1.51 -0.09 -0.14] w2 [-0.8  -0.32  0.47 -0.06 -0.03 -0.06  1.66  0.49 -0.88  0.08 -0.12  0.02\n",
            " -0.2  -0.13  0.02] w3 [ 1.94 -2.12  0.37 -0.49 -0.78  0.93] b1 [ 0.53 -0.02  0.41 -0.14 -0.05] b2 [-0.75 -0.05  0.25] b3 [-0.25  0.1 ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAO59JREFUeJzt3XtcVXW+//H33lw2kgIqCooYXspLKpgkoTXViWLKapwzZ6KOjQ5NNjk2Y9F0sSad6hROF49TOVn+cnKmi043a9KxjLI5GmZCmJqjmRdI3YCpQGig7PX7Y83euBMQEPbal9fz8fg+1mLt79581rLgzXd911o2wzAMAQAABAm71QUAAAB0JMINAAAIKoQbAAAQVAg3AAAgqBBuAABAUCHcAACAoEK4AQAAQSXc6gJ8zeVyad++ferWrZtsNpvV5QAAgFYwDEM1NTXq27ev7PaWx2ZCLtzs27dPycnJVpcBAADaoaysTP369WuxT8iFm27dukkyD05MTIzF1QAAgNaorq5WcnKy5/d4S0Iu3LhPRcXExBBuAAAIMK2ZUsKEYgAAEFQINwAAIKgQbgAAQFAh3AAAgKBCuAEAAEGFcAMAAIIK4QYAAAQVwg0AAAgqhBsAABBU/CLczJ8/XykpKYqKilJGRobWr1/fbN+LL75YNpvtpDZhwgQfVgwAAPyV5eFm6dKlysvL0+zZs1VcXKzU1FRlZ2eroqKiyf5vvPGG9u/f72mbN29WWFiYfvrTn/q4cgAA4I8sDzdz587V1KlTlZubq+HDh2vBggWKjo7WokWLmuzfo0cPJSYmetqqVasUHR1NuAEAAJIsDjf19fUqKipSVlaWZ5vdbldWVpYKCwtb9RnPP/+8rrvuOp1xxhlNvl5XV6fq6mqv1lk++ECqr++0jwcAAK1gabg5cOCAGhoalJCQ4LU9ISFBTqfzlO9fv369Nm/erJtuuqnZPvn5+YqNjfW05OTk0667KTt2SFlZ0oAB0h/+IJWVdcq3AQAAp2D5aanT8fzzz2vkyJEaO3Zss31mzpypqqoqTyvrpNSxc6eUmCjt2yfdc4/Uv780erT0y19Kzz4rvfee9K9/SdXVksvVKSUAAABJ4VZ+8/j4eIWFham8vNxre3l5uRITE1t8b21trZYsWaIHH3ywxX4Oh0MOh+O0az2Vyy+Xdu2SXnpJWrRI+vhjqaTEbN9ns0kxMWY74wwpMlKKiDDbiethYWZfu91ctrTe2n52e2MLC/P+uqXtbenb3PYT96+ty/Bws34AAE7F0nATGRmpMWPGqKCgQBMnTpQkuVwuFRQU6NZbb23xva+++qrq6up0ww03+KDS1nE4pBtvNJvTKa1ZI336qbR5s1RaKu3ZI9XUSIYhVVWZDa1js0nR0WYYdLfvf+1ucXFSjx7Nt3BL/6sHAHQ2y3/M5+XlacqUKUpPT9fYsWM1b9481dbWKjc3V5I0efJkJSUlKT8/3+t9zz//vCZOnKiePXtaUfYpJSZK//VfZnMzDOm77xqDTXW1VFsrHTvW2OrrG5cul/kew2jdemv6uZcNDeb6ia2pbW3d3lLf7++fe9nUtoYG7+NpGOaxqq09vX8Xu938t+nXT0pKMpf9+kmDBklDhkiDB0tRUaf3PQAA1rI83OTk5KiyslKzZs2S0+lUWlqaVq5c6ZlkXFpaKrvde2rQtm3btGbNGr333ntWlNxuNpvUpYvZTnHWLeS5XN6B57vvpKNHGwPOkSNNr9fWSocPSwcPNrZvvjGXhw+bn7tvn9maYrdLKSnS0KHmnKmxY83GvxcABA6bYRiG1UX4UnV1tWJjY1VVVaWYmBiry4EPNTRIlZXS3r3S1183trIy6csvGyd8N6V/f/NquCuvNJexsb6tHQBCXVt+fxNugH8zDKm83Aw5W7dKGzZIn3wiffGF+ZpbeLh00UVSbq70n/9pjsQBADoX4aYFhBu0VU2NVFgo/eMfZtu2rfG12Fhp0iQpL8+ctwMA6ByEmxYQbnC6vvpKevFF6c9/Nq+Ak8xL32+4QXrkEalvX2vrA4Bg1Jbf3wF9Ez/ACoMGSbNnmzdufO896Yc/NOfzLF5sTkT+4x+l48etrhIAQhfhBmgnu1267DLzVNUnn5hXVdXUSLfdJo0bZ97UEQDge4QboAOMHWvOy3n2WfMmgp9+Kp17rrRqldWVAUDoIdwAHcRul26+Wdq4UTr/fPO+OhMmSK+/bnVlABBaCDdAB+vfX1q92rw79bFj0rXXSi+8YHVVABA6CDdAJ3A4pCVLpJtuMu+KfNNNnKICAF8h3ACdJCxMeu45afJk82qqn/7UvEEgAKBzEW6ATmSzmQFn/HjzYalXX336D/8EALSMcAN0ModDeuMNKTlZ2rFDuu8+qysCgOBGuAF8oHdvaeFCc/3JJ6W1a62tBwCCGeEG8JHsbPNhm4Yh/eIX0nffWV0RAAQnwg3gQ088ISUmmg/ffPZZq6sBgOBEuAF8qHt36YEHzPVHHmFyMQB0BsIN4GO5udLAgVJFhfT001ZXAwDBh3AD+FhEhPT735vrf/gDozcA0NEIN4AF/vu/pUGDpEOHzDsZAwA6DuEGsEBYmPTLX5rrCxZYWwsABBvCDWCRn/9cioyUNmwwGwCgYxBuAIv06mU+OVzisnAA6EiEG8BCt9xiLl9+2Xz2FADg9BFuAAtdcIE0dKh05Ij09ttWVwMAwYFwA1jIZms8NbVsmaWlAEDQINwAFps40VyuXCkdPWppKQAQFAg3gMXOPVdKTjZPTb3/vtXVAEDgI9wAFrPZGkdvODUFAKePcAP4AXe4efttqaHB0lIAIOARbgA/cOGF5hPDDxyQ1q61uhoACGyEG8APRERIV1xhrjPvBgBOD+EG8BM/+IG5/L//s7YOAAh0hBvAT1x4oblct06qr7e2FgAIZIQbwE8MGyb17Cl9951UVGR1NQAQuAg3gJ+w2czHMUicmgKA00G4AfyI+9QU4QYA2o9wA/gRd7hZu1ZyuaytBQACFeEG8COjR0vR0dKhQ9KWLVZXAwCByfJwM3/+fKWkpCgqKkoZGRlav359i/0PHz6s6dOnq0+fPnI4HDr77LO1YsUKH1ULdK6ICCkz01zn1BQAtI+l4Wbp0qXKy8vT7NmzVVxcrNTUVGVnZ6uioqLJ/vX19brsssu0e/duvfbaa9q2bZsWLlyopKQkH1cOdB7m3QDA6Qm38pvPnTtXU6dOVW5uriRpwYIFWr58uRYtWqR77rnnpP6LFi3SwYMH9fHHHysiIkKSlJKS0uL3qKurU11dnefr6urqjtsBoBOMH28uP/3U2joAIFBZNnJTX1+voqIiZWVlNRZjtysrK0uFhYVNvuftt99WZmampk+froSEBI0YMUKPPPKIGlp40mB+fr5iY2M9LTk5ucP3BehIo0aZy507pdpaa2sBgEBkWbg5cOCAGhoalJCQ4LU9ISFBTqezyffs3LlTr732mhoaGrRixQrdf//9euKJJ/Q///M/zX6fmTNnqqqqytPKyso6dD+Ajta7t9kMg0nFANAelp6WaiuXy6XevXvrueeeU1hYmMaMGaO9e/fqscce0+zZs5t8j8PhkMPh8HGlwOkZNcp8gOamTdLYsVZXAwCBxbKRm/j4eIWFham8vNxre3l5uRITE5t8T58+fXT22WcrLCzMs23YsGFyOp2q52E8CCIjR5rLzz+3tg4ACESWhZvIyEiNGTNGBQUFnm0ul0sFBQXKdF8L+z3jx4/Xjh075Drh7mbbt29Xnz59FBkZ2ek1A77iDjebNllbBwAEIksvBc/Ly9PChQu1ePFibd26VdOmTVNtba3n6qnJkydr5syZnv7Tpk3TwYMHNWPGDG3fvl3Lly/XI488ounTp1u1C0CnODHcGIa1tQBAoLF0zk1OTo4qKys1a9YsOZ1OpaWlaeXKlZ5JxqWlpbLbG/NXcnKy3n33Xd1+++0aNWqUkpKSNGPGDN19991W7QLQKYYPl+x26cABqbxcauZMLQCgCTbDCK2/C6urqxUbG6uqqirFxMRYXQ7QrCFDpO3bpXfflS6/3OpqAMBabfn9bfnjFwA0jXk3ANA+hBvAT7lv5ke4AYC2IdwAfoqRGwBoH8IN4Kfc4WbLFun4cWtrAYBAQrgB/NTAgVJ0tFRXJ+3YYXU1ABA4CDeAn7LbpREjzHVOTQFA6xFuAD924qkpAEDrEG4APzZ4sLncudPaOgAgkBBuAD82cKC5JNwAQOsRbgA/RrgBgLYj3AB+zB1u9u+XjhyxthYACBSEG8CPde8uxcaa67t3W1oKAAQMwg3gx2w2Tk0BQFsRbgA/N2iQuSTcAEDrEG4AP8fIDQC0DeEG8HOEGwBoG8IN4OcINwDQNoQbwM+dGG4Mw9paACAQEG4AP9e/v/kQzaNHpfJyq6sBAP9HuAH8XESEGXAkTk0BQGsQboAAwLwbAGg9wg0QANzh5quvrK0DAAIB4QYIAIzcAEDrEW6AAEC4AYDWI9wAAYBwAwCtR7gBAoA73OzbZ14SDgBoHuEGCAA9ekgxMeb67t2WlgIAfo9wAwQAm01KSTHX9+yxtBQA8HuEGyBA9OtnLvfutbYOAPB3hBsgQCQlmcuvv7a2DgDwd4QbIEC4ww0jNwDQMsINECAINwDQOoQbIEAw5wYAWodwAwQI5twAQOsQboAA4Q4333wjffedtbUAgD8j3AABont3KSrKXN+3z9paAMCfEW6AAGGzMakYAFrDL8LN/PnzlZKSoqioKGVkZGj9+vXN9n3hhRdks9m8WpT7z1kgyLknFTPvBgCaZ3m4Wbp0qfLy8jR79mwVFxcrNTVV2dnZqqioaPY9MTEx2r9/v6ft4X70CBGM3ADAqVkebubOnaupU6cqNzdXw4cP14IFCxQdHa1FixY1+x6bzabExERPS0hI8GHFgHUINwBwapaGm/r6ehUVFSkrK8uzzW63KysrS4WFhc2+79tvv9WZZ56p5ORk/ehHP9KWLVua7VtXV6fq6mqvBgQqwg0AnJql4ebAgQNqaGg4aeQlISFBTqezyfcMGTJEixYt0ltvvaUXX3xRLpdL48aN09fNTELIz89XbGyspyUnJ3f4fgC+wpwbADg1y09LtVVmZqYmT56stLQ0XXTRRXrjjTfUq1cvPfvss032nzlzpqqqqjytrKzMxxUDHYeRGwA4tXArv3l8fLzCwsJUXl7utb28vFyJiYmt+oyIiAiNHj1aO3bsaPJ1h8Mhh8Nx2rUC/sAdbvbtk1wuyR5wf54AQOez9EdjZGSkxowZo4KCAs82l8ulgoICZWZmtuozGhoatGnTJvXp06ezygT8RmKieb+b48elykqrqwEA/2T53315eXlauHChFi9erK1bt2ratGmqra1Vbm6uJGny5MmaOXOmp/+DDz6o9957Tzt37lRxcbFuuOEG7dmzRzfddJNVuwD4TESE5J6ixrwbAGiapaelJCknJ0eVlZWaNWuWnE6n0tLStHLlSs8k49LSUtlPGHs/dOiQpk6dKqfTqe7du2vMmDH6+OOPNXz4cKt2AfCpfv0kp9OcdzNmjNXVAID/sRmGYVhdhC9VV1crNjZWVVVViomJsbocoM0mTpTeekv605+kadOsrgYAfKMtv78tPy0FoG24YgoAWka4AQKMO9ww5wYAmka4AQIMIzcA0DLCDRBgCDcA0DLCDRBg3Ld0auYJJQAQ8gg3QIBxh5tDh6S6OmtrAQB/RLgBAkz37lJkpLnO6A0AnIxwAwQYm818DINEuAGAphBugABEuAGA5hFugADknnezf7+1dQCAPyLcAAGIkRsAaB7hBghA7ieDl5dbWwcA+CPCDRCACDcA0DzCDRCAOC0FAM0j3AABiJEbAGge4QYIQIQbAGge4QYIQO5wU1srffuttbUAgL8h3AABqGtXKTraXGf0BgC8EW6AAGSzcWoKAJpDuAECFOEGAJpGuAECFJeDA0DTCDdAgHKP3BBuAMAb4QYIUO6RG05LAYA3wg0QoAg3ANA0wg0QoDgtBQBNI9wAAYqrpQCgaYQbIED17m0uKyqsrQMA/A3hBghQJz6CobbW2loAwJ8QboAA1bWrFBVlrjN6AwCNCDdAgLLZODUFAE0h3AABjEnFAHAywg0QwBi5AYCTEW6AAEa4AYCTEW6AAMZpKQA4GeEGCGCM3ADAyQg3QAAj3ADAyQg3QABzhxtOSwFAI8INEMDcc24YuQGARn4RbubPn6+UlBRFRUUpIyND69evb9X7lixZIpvNpokTJ3ZugYCfco/cHDggHT9ubS0A4C8sDzdLly5VXl6eZs+ereLiYqWmpio7O1sVp/hTdPfu3frtb3+rCy+80EeVAv4nPt68U7FhSN98Y3U1AOAfLA83c+fO1dSpU5Wbm6vhw4drwYIFio6O1qJFi5p9T0NDgyZNmqQHHnhAAwcObPHz6+rqVF1d7dWAYBEeLvXsaa5zagoATJaGm/r6ehUVFSkrK8uzzW63KysrS4WFhc2+78EHH1Tv3r31i1/84pTfIz8/X7GxsZ6WnJzcIbUD/oIrpgDAm6Xh5sCBA2poaFCCe1bkvyUkJMjpdDb5njVr1uj555/XwoULW/U9Zs6cqaqqKk8rKys77boBf8KN/ADAW7jVBbRFTU2Nfvazn2nhwoWKj49v1XscDoccDkcnVwZYh3ADAN4sDTfx8fEKCwtT+fd+KpeXlysxMfGk/l999ZV2796tq6++2rPN5XJJksLDw7Vt2zYNGjSoc4sG/Iz7tFRlpbV1AIC/sPS0VGRkpMaMGaOCggLPNpfLpYKCAmVmZp7Uf+jQodq0aZNKSko87ZprrtEll1yikpIS5tMgJDHnBgC8WX5aKi8vT1OmTFF6errGjh2refPmqba2Vrm5uZKkyZMnKykpSfn5+YqKitKIESO83h8XFydJJ20HQgXhBgC8WR5ucnJyVFlZqVmzZsnpdCotLU0rV670TDIuLS2V3W75FeuA3yLcAIA3m2EYhtVF+FJ1dbViY2NVVVWlmJgYq8sBTlthoTRunJSSIu3aZXU1ANA52vL7myERIMDxfCkA8Ea4AQKc+7TUkSNSba21tQCAPyDcAAHujDOkLl3MdUZvAIBwAwQ8m41JxQBwIsINEAQINwDQiHADBAHCDQA0ItwAQYBwAwCN2hVuFi9erOXLl3u+vuuuuxQXF6dx48Zpz549HVYcgNYh3ABAo3aFm0ceeURd/n15RmFhoebPn69HH31U8fHxuv322zu0QACnRrgBgEbtevxCWVmZBg8eLElatmyZfvKTn+jmm2/W+PHjdfHFF3dkfQBawR1uysutrQMA/EG7Rm66du2qb775RpL03nvv6bLLLpMkRUVF6ejRox1XHYBW4S7FANCoXSM3l112mW666SaNHj1a27dv15VXXilJ2rJli1JSUjqyPgCtwGkpAGjUrpGb+fPnKzMzU5WVlXr99dfVs2dPSVJRUZGuv/76Di0QwKm5w01lpeRyWVsLAFiNp4IDQeDYMSky0lyvrJTi462tBwA6Wqc/FXzlypVas2aN5+v58+crLS1N//3f/61Dhw615yMBnIaICKlHD3OdU1MAQl27ws2dd96p6upqSdKmTZt0xx136Morr9SuXbuUl5fXoQUCaB3m3QCAqV0Tinft2qXhw4dLkl5//XVdddVVeuSRR1RcXOyZXAzAt3r3lv71Ly4HB4B2jdxERkbqyJEjkqT3339fl19+uSSpR48enhEdAL7lvhyccAMg1LVr5OaCCy5QXl6exo8fr/Xr12vp0qWSpO3bt6tfv34dWiCA1klMNJdOp7V1AIDV2jVy8/TTTys8PFyvvfaannnmGSUlJUmS/vGPf+iHP/xhhxYIoHUYuQEAU7tGbvr376933nnnpO3/+7//e9oFAWgfwg0AmNoVbiSpoaFBy5Yt09atWyVJ55xzjq655hqFhYV1WHEAWo9HMACAqV3hZseOHbryyiu1d+9eDRkyRJKUn5+v5ORkLV++XIMGDerQIgGcGg/PBABTu+bc/OY3v9GgQYNUVlam4uJiFRcXq7S0VAMGDNBvfvObjq4RQCucOHITWvcdBwBv7Rq5+eijj7Ru3Tr1cN8SVVLPnj01Z84cjR8/vsOKA9B67pGb776Tamokni4CIFS1a+TG4XCopqbmpO3ffvutIt0PuAHgU9HRUteu5jrzbgCEsnaFm6uuuko333yzPvnkExmGIcMwtG7dOt1yyy265pprOrpGAK3kHr3hXjcAQlm7ws2TTz6pQYMGKTMzU1FRUYqKitK4ceM0ePBgzZs3r4NLBNBa7hv5MakYQChr15ybuLg4vfXWW9qxY4fnUvBhw4Zp8ODBHVocgLbhLsUA0IZwc6qnfX/44Yee9blz57a/IgDtRrgBgDaEm88++6xV/Ww2W7uLAXB6CDcA0IZwc+LIDAD/xJwbAGjnhGIA/omRGwAg3ABBxX2XYsINgFBGuAGCyIkjNzyCAUCoItwAQcQ9cnPsmHTokLW1AIBVCDdAEHE4pO7dzXVOTQEIVX4RbubPn6+UlBRFRUUpIyND69evb7bvG2+8ofT0dMXFxemMM85QWlqa/vrXv/qwWsC/MakYQKizPNwsXbpUeXl5mj17toqLi5Wamqrs7GxVNPPkvx49eui+++5TYWGhPv/8c+Xm5io3N1fvvvuujysH/BPhBkCoszzczJ07V1OnTlVubq6GDx+uBQsWKDo6WosWLWqy/8UXX6wf//jHGjZsmAYNGqQZM2Zo1KhRWrNmjY8rB/wT97oBEOosDTf19fUqKipSVlaWZ5vdbldWVpYKCwtP+X7DMFRQUKBt27bpBz/4QZN96urqVF1d7dWAYMbl4ABCnaXh5sCBA2poaFCC+6fxvyUkJMjZwk/mqqoqde3aVZGRkZowYYKeeuopXXbZZU32zc/PV2xsrKclJyd36D4A/obTUgBCneWnpdqjW7duKikp0aeffqqHH35YeXl5Wr16dZN9Z86cqaqqKk8rKyvzbbGAjxFuAIS6Vj9bqjPEx8crLCxM5d+bHFBeXq5E90/oJtjtdg0ePFiSlJaWpq1btyo/P18XX3zxSX0dDoccDkeH1g34M8INgFBn6chNZGSkxowZo4KCAs82l8ulgoICZWZmtvpzXC6X6urqOqNEIOAQbgCEOktHbiQpLy9PU6ZMUXp6usaOHat58+aptrZWubm5kqTJkycrKSlJ+fn5ksw5NOnp6Ro0aJDq6uq0YsUK/fWvf9Uzzzxj5W4AfsMdbiorpePHpXDL/y8HAN+y/MdeTk6OKisrNWvWLDmdTqWlpWnlypWeScalpaWy2xsHmGpra/WrX/1KX3/9tbp06aKhQ4fqxRdfVE5OjlW7APiV+HjJbpdcLjPg9OljdUUA4Fs2wwitx+tVV1crNjZWVVVViomJsbocoFP06WOelioqks491+pqAOD0teX3d0BeLQWgZX37msv9+62tAwCsQLgBgpA73OzbZ20dAGAFwg0QhNzzbBi5ARCKCDdAEHKP3Ozda20dAGAFwg0QhJhzAyCUEW6AIJSUZC6ZcwMgFBFugCDEhGIAoYxwAwQhd7gpLzfvUgwAoYRwAwShXr2ksDDzLsXfey4tAAQ9wg0QhOz2xsvBOTUFINQQboAgxbwbAKGKcAMEKfcVU19/bW0dAOBrhBsgSLnDDTfyAxBqCDdAkOrXz1wycgMg1BBugCBFuAEQqgg3QJAi3AAIVYQbIEglJ5vLsjLJMKytBQB8iXADBCn3hOLvvpMOHLC2FgDwJcINEKQcDikhwVwvK7O2FgDwJcINEMROPDUFAKGCcAMEMcINgFBEuAGCWP/+5pJwAyCUEG6AIOYeuSkttbYOAPAlwg0QxDgtBSAUEW6AIEa4ARCKCDdAEHOHm717pYYGa2sBAF8h3ABBrE8fKSzMDDb791tdDQD4BuEGCGJhYY2jN3v2WFsLAPgK4QYIcikp5nL3biurAADfIdwAQY5wAyDUEG6AIOcON7t2WVoGAPgM4QYIcgMGmEtGbgCECsINEOQ4LQUg1BBugCDnDjelpdzrBkBoINwAQS4pSYqIkI4dM2/mBwDBjnADBLmwsMbRm6++srQUAPAJwg0QAgYNMpeEGwChwC/Czfz585WSkqKoqChlZGRo/fr1zfZduHChLrzwQnXv3l3du3dXVlZWi/0BEG4AhBbLw83SpUuVl5en2bNnq7i4WKmpqcrOzlZFRUWT/VevXq3rr79eH374oQoLC5WcnKzLL79ce5lMADRr4EBzSbgBEApshmEYVhaQkZGh8847T08//bQkyeVyKTk5Wb/+9a91zz33nPL9DQ0N6t69u55++mlNnjz5lP2rq6sVGxurqqoqxcTEnHb9QCB46y1p4kTp3HOloiKrqwGAtmvL729LR27q6+tVVFSkrKwszza73a6srCwVFha26jOOHDmiY8eOqUePHk2+XldXp+rqaq8GhJoTT0tZ++cMAHQ+S8PNgQMH1NDQoISEBK/tCQkJcjqdrfqMu+++W3379vUKSCfKz89XbGyspyW7H5EMhBD3aamqKungQWtrAYDOZvmcm9MxZ84cLVmyRG+++aaioqKa7DNz5kxVVVV5WllZmY+rBKwXHS317Wuu79hhbS0A0NksDTfx8fEKCwtTeXm51/by8nIlJia2+N7HH39cc+bM0XvvvadRo0Y128/hcCgmJsarAaFoyBBzuW2btXUAQGezNNxERkZqzJgxKigo8GxzuVwqKChQZmZms+979NFH9dBDD2nlypVKT0/3RalAwHOHm3/9y9o6AKCzhVtdQF5enqZMmaL09HSNHTtW8+bNU21trXJzcyVJkydPVlJSkvLz8yVJf/jDHzRr1iy9/PLLSklJ8czN6dq1q7p27WrZfgD+buhQc8nIDYBgZ3m4ycnJUWVlpWbNmiWn06m0tDStXLnSM8m4tLRUdnvjANMzzzyj+vp6/dd//ZfX58yePVu///3vfVk6EFDc4YaRGwDBzvL73Pga97lBqNqzx3zGVESEdOSIFG75nzYA0HoBc58bAL6TnCx16WI+HXzXLqurAYDOQ7gBQoTdzqRiAKGBcAOEEC4HBxAKCDdACGFSMYBQQLgBQgjhBkAoINwAIcQdbr74ggdoAghehBsghAwdKoWFSYcOSXv3Wl0NAHQOwg0QQqKiGicVf/65tbUAQGch3AAhJjXVXG7caG0dANBZCDdAiBk1ylwycgMgWBFugBDDyA2AYEe4AUKMO9xs2yYdPWptLQDQGQg3QIjp00fq2VNyucxLwgEg2BBugBBjs3FqCkBwI9wAIcg9qZhwAyAYEW6AEDRmjLlct87aOgCgMxBugBB0wQXmsrhYOnLE2loAoKMRboAQdOaZUt++0vHj0vr1VlcDAB2LcAOEIJutcfRm7VprawGAjka4AULU+PHmcs0aa+sAgI5GuAFClHvkprBQamiwthYA6EiEGyBEjRolnXGGVFUlbdlidTUA0HEIN0CICg+XMjPNdebdAAgmhBsghDHvBkAwItwAIYwrpgAEI8INEMIyMiS7XdqzR/r6a6urAYCOQbgBQli3blJamrnO6A2AYEG4AUKce94N4QZAsCDcACHOPe+GScUAggXhBghx7pGbjRvNe94AQKAj3AAhLilJOvtsyeWS3n3X6moA4PQRbgBo4kRzuWyZlVUAQMcg3ADwhJvly6X6ektLAYDTRrgBoIwMKSFBqq6WPvrI6moA4PQQbgDIbpeuucZc59QUgEBHuAEgqfHU1FtvSYZhaSkAcFoINwAkSf/xH9IZZ0h790pFRVZXAwDtR7gBIEmKipKuuMJc59QUgEBmebiZP3++UlJSFBUVpYyMDK1fv77Zvlu2bNFPfvITpaSkyGazad68eb4rFAgB7lNTb7zBqSkAgcvScLN06VLl5eVp9uzZKi4uVmpqqrKzs1VRUdFk/yNHjmjgwIGaM2eOEhMTfVwtEPwmTJAcDmnrVumzz6yuBgDax9JwM3fuXE2dOlW5ubkaPny4FixYoOjoaC1atKjJ/uedd54ee+wxXXfddXI4HK36HnV1daqurvZqAJoWFyf96Efm+uLFlpYCAO1mWbipr69XUVGRsrKyGoux25WVlaXCwsIO+z75+fmKjY31tOTk5A77bCAYTZliLl96iRv6AQhMloWbAwcOqKGhQQkJCV7bExIS5HQ6O+z7zJw5U1VVVZ5WVlbWYZ8NBKPLL5cSE6VvvpHeftvqagCg7SyfUNzZHA6HYmJivBqA5oWHS7/4hbn+pz9ZWwsAtIdl4SY+Pl5hYWEqLy/32l5eXs5kYcBiN99s3rX4ww+lLVusrgYA2saycBMZGakxY8aooKDAs83lcqmgoECZmZlWlQVAUv/+jZeFc8cFAIHG0tNSeXl5WrhwoRYvXqytW7dq2rRpqq2tVW5uriRp8uTJmjlzpqd/fX29SkpKVFJSovr6eu3du1clJSXasWOHVbsABK3bbzeXixdLu3dbWgoAtEm4ld88JydHlZWVmjVrlpxOp9LS0rRy5UrPJOPS0lLZ7Y35a9++fRo9erTn68cff1yPP/64LrroIq1evdrX5QNB7YILpMsuk1atkh54QPrzn62uCABax2YYoXUf0urqasXGxqqqqorJxcAprF8vZWSY8282b5aGDbO6IgChqi2/v4P+aikA7Td2rHlTP5dLmj3b6moAoHUINwBa9NBDks0mvfoqj2QAEBgINwBaNHKkdP315vrvfmdtLQDQGoQbAKf0wANSWJi0YoW0Zo3V1QBAywg3AE5p8GDpxhvN9VtvlY4ds7YeAGgJ4QZAqzz8sNSjh7Rxo/TYY1ZXAwDNI9wAaJVevaQ//tFcf+ABqbjY2noAoDmEGwCtNmmS+ViG+nopJ0eqqbG6IgA4GeEGQKvZbNLzz0vJydKOHdK0aVJo3QYUQCAg3ABokx49pFdeMa+eeukl6ZlnrK4IALwRbgC02fjx5gRjSfr1r6Xly62tBwBORLgB0C533SX9/OfmoxlycqSiIqsrAgAT4QZAu9hs0nPPmU8Or62VrrxS+te/rK4KAAg3AE5DRIT02mtSWppUUSFdfLG0ZYvVVQEIdYQbAKclJkZatUpKTZXKy6WLLpLWrbO6KgChjHAD4LTFx0sffCCNHSt9840ZcJ5/3uqqAIQqwg2ADtGjh1RQ0HiTv5tukm65Raqrs7oyAKGGcAOgw3TtKr3+uvQ//2NOOH72WemSS6Svv7a6MgChhHADoEPZ7dJ995n3vomLkwoLpREjpMWLuZsxAN8g3ADoFFdcIW3YIGVkSFVV5j1xsrOl7dutrgxAsCPcAOg0gwZJa9ZIc+ZIDod5VdWIEVJennTokNXVAQhWhBsAnSo8XLr7bmnzZvNGf8eOSf/7v9KZZ0p33CGVlVldIYBgQ7gB4BODB5vzcFaulEaOlGpqpLlzpYEDpRtukEpKrK4QQLAg3ADwqexsaeNGacUK80qq48fNp4uPHm0+yuHdd5l4DOD0EG4A+JzNZk44/uADc9LxdddJYWHS++9LP/yhdM455uXkO3ZYXSmAQGQzjND6G6m6ulqxsbGqqqpSTEyM1eUA+Lfdu6V586T/9//MB3G6paeb4efaa6XkZKuqA2C1tvz+JtwA8CuHD0tvviktWWLe8bihofG10aOlq64yT22NHWs+uBNAaCDctIBwAwSOigrzqeOvvCKtXes9F6drV+kHP5AuvdRcpqWZV2YBCE6EmxYQboDAVFEh/eMf5hVXH3xgPqDzRGecYd4wMD3dDDqpqdLZZxN4gGBBuGkB4QYIfC6X9Pnn5mmrDz6QPv7YPJ31fVFR5k0DU1MbA8+oUVJsrK8rBnC6CDctINwAwcflkr74wgw5JSXmpeYbN3pPTD7RgAFm6DnrLO/Wr5/5bCwA/qctv78ZsAUQ8Ox2M6yMGNG4zeWSdu40Q4478JSUmHdE3rXLbN8XFWXeOfnMM6X+/U9uyclSZKSv9gpAezFyAyCkHDxontLaulX68kvzQZ5ffmkGoePHW36vzSYlJkp9+0p9+pgtMbFxvU8fqVcvKT5e6tbN7A+gY3BaqgWEGwBNOX5c2rPHbKWlZjtxvbRU+u671n9eZKQZcuLjGwOPe71nTykuzmyxsd7rhCKgaZyWAoA2Cg83n2I+aFDTrxuGdOCAGXj27zeb0+m97nRKlZXSkSNSfb20b5/Z2sJuN0PO90PPiesxMebVYc216OjGdU6jIRQRbgCgFWw2c9SlV69T9z1yxAxC7lZZ6b08cECqqjLb4cON7dgxc67QoUNm6wjh4S0HoaYCUVTUyc3haHr7919jQjb8AeEGADpYdHTjJOTWMgzztNfhw42h58Twc+J6TY15JVhLzT1/6PjxxiDlCxERjYHH4TBHjtrbTnx/RITZwsPNduL6qb5uS9/wcPM5ZwhsfhFu5s+fr8cee0xOp1Opqal66qmnNHbs2Gb7v/rqq7r//vu1e/dunXXWWfrDH/6gK6+80ocVA0DHstmkLl3M1qfP6X9efX3zwefIkZaDUV2dGbTc7ftfn7j96FFztMnt2DGz1dSc/j5YxWZrfRByh6GwMHPUqqn1ll7z9/e0t0VFmZPtrWJ5uFm6dKny8vK0YMECZWRkaN68ecrOzta2bdvUu3fvk/p//PHHuv7665Wfn6+rrrpKL7/8siZOnKji4mKNOPE6UAAIYe4Rj+7dO/97HT/edPg5dswMWS21urpT93G348fNzzx+vLGd+HVrX3OvHzvW9P4YRmNIO3q0849fMMrMNO87ZRXLr5bKyMjQeeedp6efflqS5HK5lJycrF//+te65557Tuqfk5Oj2tpavfPOO55t559/vtLS0rRgwYJTfj+ulgIAuLlc7QtIJ37d0GB+TkNDYzvx69as++t7DMNcb2vLyJA+/LBj/60C5mqp+vp6FRUVaebMmZ5tdrtdWVlZKiwsbPI9hYWFysvL89qWnZ2tZcuWNdm/rq5OdXV1nq+rq6tPv3AAQFCw2xvnByF4WDqv/cCBA2poaFBCQoLX9oSEBDmdzibf43Q629Q/Pz9fsbGxnpacnNwxxQMAAL8U9BftzZw5U1VVVZ5WVlZmdUkAAKATWXpaKj4+XmFhYSovL/faXl5ersRmplknJia2qb/D4ZCD8UYAAEKGpSM3kZGRGjNmjAoKCjzbXC6XCgoKlJmZ2eR7MjMzvfpL0qpVq5rtDwAAQovll4Ln5eVpypQpSk9P19ixYzVv3jzV1tYqNzdXkjR58mQlJSUpPz9fkjRjxgxddNFFeuKJJzRhwgQtWbJEGzZs0HPPPWflbgAAAD9hebjJyclRZWWlZs2aJafTqbS0NK1cudIzabi0tFT2E+7nPW7cOL388sv63e9+p3vvvVdnnXWWli1bxj1uAACAJD+4z42vcZ8bAAACT1t+fwf91VIAACC0EG4AAEBQIdwAAICgQrgBAABBhXADAACCCuEGAAAEFcINAAAIKpbfxM/X3Lf1qa6utrgSAADQWu7f2625PV/IhZuamhpJUnJyssWVAACAtqqpqVFsbGyLfULuDsUul0v79u1Tt27dZLPZOvSzq6urlZycrLKyMu5+3Ik4zr7BcfYNjrPvcKx9o7OOs2EYqqmpUd++fb0ey9SUkBu5sdvt6tevX6d+j5iYGP7H8QGOs29wnH2D4+w7HGvf6IzjfKoRGzcmFAMAgKBCuAEAAEGFcNOBHA6HZs+eLYfDYXUpQY3j7BscZ9/gOPsOx9o3/OE4h9yEYgAAENwYuQEAAEGFcAMAAIIK4QYAAAQVwg0AAAgqhJsOMn/+fKWkpCgqKkoZGRlav3691SX5tfz8fJ133nnq1q2bevfurYkTJ2rbtm1efb777jtNnz5dPXv2VNeuXfWTn/xE5eXlXn1KS0s1YcIERUdHq3fv3rrzzjt1/Phxrz6rV6/WueeeK4fDocGDB+uFF17o7N3zS3PmzJHNZtNtt93m2cYx7jh79+7VDTfcoJ49e6pLly4aOXKkNmzY4HndMAzNmjVLffr0UZcuXZSVlaUvv/zS6zMOHjyoSZMmKSYmRnFxcfrFL36hb7/91qvP559/rgsvvFBRUVFKTk7Wo48+6pP98wcNDQ26//77NWDAAHXp0kWDBg3SQw895PWsIY5z2/3zn//U1Vdfrb59+8pms2nZsmVer/vymL766qsaOnSooqKiNHLkSK1YsaJ9O2XgtC1ZssSIjIw0Fi1aZGzZssWYOnWqERcXZ5SXl1tdmt/Kzs42/vznPxubN282SkpKjCuvvNLo37+/8e2333r63HLLLUZycrJRUFBgbNiwwTj//PONcePGeV4/fvy4MWLECCMrK8v47LPPjBUrVhjx8fHGzJkzPX127txpREdHG3l5ecYXX3xhPPXUU0ZYWJixcuVKn+6v1davX2+kpKQYo0aNMmbMmOHZzjHuGAcPHjTOPPNM4+c//7nxySefGDt37jTeffddY8eOHZ4+c+bMMWJjY41ly5YZGzduNK655hpjwIABxtGjRz19fvjDHxqpqanGunXrjP/7v/8zBg8ebFx//fWe16uqqoyEhARj0qRJxubNm41XXnnF6NKli/Hss8/6dH+t8vDDDxs9e/Y03nnnHWPXrl3Gq6++anTt2tX44x//6OnDcW67FStWGPfdd5/xxhtvGJKMN9980+t1Xx3TtWvXGmFhYcajjz5qfPHFF8bvfvc7IyIiwti0aVOb94lw0wHGjh1rTJ8+3fN1Q0OD0bdvXyM/P9/CqgJLRUWFIcn46KOPDMMwjMOHDxsRERHGq6++6umzdetWQ5JRWFhoGIb5P6TdbjecTqenzzPPPGPExMQYdXV1hmEYxl133WWcc845Xt8rJyfHyM7O7uxd8hs1NTXGWWedZaxatcq46KKLPOGGY9xx7r77buOCCy5o9nWXy2UkJiYajz32mGfb4cOHDYfDYbzyyiuGYRjGF198YUgyPv30U0+ff/zjH4bNZjP27t1rGIZh/OlPfzK6d+/uOfbu7z1kyJCO3iW/NGHCBOPGG2/02vaf//mfxqRJkwzD4Dh3hO+HG18e02uvvdaYMGGCVz0ZGRnGL3/5yzbvB6elTlN9fb2KioqUlZXl2Wa325WVlaXCwkILKwssVVVVkqQePXpIkoqKinTs2DGv4zp06FD179/fc1wLCws1cuRIJSQkePpkZ2erurpaW7Zs8fQ58TPcfULp32b69OmaMGHCSceBY9xx3n77baWnp+unP/2pevfurdGjR2vhwoWe13ft2iWn0+l1nGJjY5WRkeF1rOPi4pSenu7pk5WVJbvdrk8++cTT5wc/+IEiIyM9fbKzs7Vt2zYdOnSos3fTcuPGjVNBQYG2b98uSdq4caPWrFmjK664QhLHuTP48ph25M8Sws1pOnDggBoaGrx++EtSQkKCnE6nRVUFFpfLpdtuu03jx4/XiBEjJElOp1ORkZGKi4vz6nvicXU6nU0ed/drLfWprq7W0aNHO2N3/MqSJUtUXFys/Pz8k17jGHecnTt36plnntFZZ52ld999V9OmTdNvfvMbLV68WFLjsWrp54TT6VTv3r29Xg8PD1ePHj3a9O8RzO655x5dd911Gjp0qCIiIjR69GjddtttmjRpkiSOc2fw5TFtrk97jnnIPRUc/mf69OnavHmz1qxZY3UpQaWsrEwzZszQqlWrFBUVZXU5Qc3lcik9PV2PPPKIJGn06NHavHmzFixYoClTplhcXfD429/+ppdeekkvv/yyzjnnHJWUlOi2225T3759Oc7wwsjNaYqPj1dYWNhJV5iUl5crMTHRoqoCx6233qp33nlHH374ofr16+fZnpiYqPr6eh0+fNir/4nHNTExscnj7n6tpT4xMTHq0qVLR++OXykqKlJFRYXOPfdchYeHKzw8XB999JGefPJJhYeHKyEhgWPcQfr06aPhw4d7bRs2bJhKS0slNR6rln5OJCYmqqKiwuv148eP6+DBg2369whmd955p2f0ZuTIkfrZz36m22+/3TMyyXHueL48ps31ac8xJ9ycpsjISI0ZM0YFBQWebS6XSwUFBcrMzLSwMv9mGIZuvfVWvfnmm/rggw80YMAAr9fHjBmjiIgIr+O6bds2lZaWeo5rZmamNm3a5PU/1apVqxQTE+P5RZOZmen1Ge4+ofBvc+mll2rTpk0qKSnxtPT0dE2aNMmzzjHuGOPHjz/pVgbbt2/XmWeeKUkaMGCAEhMTvY5TdXW1PvnkE69jffjwYRUVFXn6fPDBB3K5XMrIyPD0+ec//6ljx455+qxatUpDhgxR9+7dO23//MWRI0dkt3v/2goLC5PL5ZLEce4MvjymHfqzpM1TkHGSJUuWGA6Hw3jhhReML774wrj55puNuLg4rytM4G3atGlGbGyssXr1amP//v2eduTIEU+fW265xejfv7/xwQcfGBs2bDAyMzONzMxMz+vuy5Qvv/xyo6SkxFi5cqXRq1evJi9TvvPOO42tW7ca8+fPD7nLlE904tVShsEx7ijr1683wsPDjYcfftj48ssvjZdeesmIjo42XnzxRU+fOXPmGHFxccZbb71lfP7558aPfvSjJi+nHT16tPHJJ58Ya9asMc466yyvy2kPHz5sJCQkGD/72c+MzZs3G0uWLDGio6OD9hLl75syZYqRlJTkuRT8jTfeMOLj44277rrL04fj3HY1NTXGZ599Znz22WeGJGPu3LnGZ599ZuzZs8cwDN8d07Vr1xrh4eHG448/bmzdutWYPXs2l4Jb7amnnjL69+9vREZGGmPHjjXWrVtndUl+TVKT7c9//rOnz9GjR41f/epXRvfu3Y3o6Gjjxz/+sbF//36vz9m9e7dxxRVXGF26dDHi4+ONO+64wzh27JhXnw8//NBIS0szIiMjjYEDB3p9j1Dz/XDDMe44f//7340RI0YYDofDGDp0qPHcc895ve5yuYz777/fSEhIMBwOh3HppZca27Zt8+rzzTffGNdff73RtWtXIyYmxsjNzTVqamq8+mzcuNG44IILDIfDYSQlJRlz5szp9H3zF9XV1caMGTOM/v37G1FRUcbAgQON++67z+vyYo5z23344YdN/jyeMmWKYRi+PaZ/+9vfjLPPPtuIjIw0zjnnHGP58uXt2iebYZxwa0cAAIAAx5wbAAAQVAg3AAAgqBBuAABAUCHcAACAoEK4AQAAQYVwAwAAggrhBgAABBXCDQAACCqEGwAhb/Xq1bLZbCc9RBRAYCLcAACAoEK4AQAAQYVwA8ByLpdL+fn5GjBggLp06aLU1FS99tprkhpPGS1fvlyjRo1SVFSUzj//fG3evNnrM15//XWdc845cjgcSklJ0RNPPOH1el1dne6++24lJyfL4XBo8ODBev755736FBUVKT09XdHR0Ro3bpy2bdvWuTsOoFMQbgBYLj8/X3/5y1+0YMECbdmyRbfffrtuuOEGffTRR54+d955p5544gl9+umn6tWrl66++modO3ZMkhlKrr32Wl133XXatGmTfv/73+v+++/XCy+84Hn/5MmT9corr+jJJ5/U1q1b9eyzz6pr165eddx333164okntGHDBoWHh+vGG2/0yf4D6Fg8FRyAperq6tSjRw+9//77yszM9Gy/6aabdOTIEd1888265JJLtGTJEuXk5EiSDh48qH79+umFF17Qtddeq0mTJqmyslLvvfee5/133XWXli9fri1btmj79u0aMmSIVq1apaysrJNqWL16tS655BK9//77uvTSSyVJK1as0IQJE3T06FFFRUV18lEA0JEYuQFgqR07dujIkSO67LLL1LVrV0/7y1/+oq+++srT78Tg06NHDw0ZMkRbt26VJG3dulXjx4/3+tzx48fryy+/VENDg0pKShQWFqaLLrqoxVpGjRrlWe/Tp48kqaKi4rT3EYBvhVtdAIDQ9u2330qSli9frqSkJK/XHA6HV8Bpry5durSqX0REhGfdZrNJMucDAQgsjNwAsNTw4cPlcDhUWlqqwYMHe7Xk5GRPv3Xr1nnWDx06pO3bt2vYsGGSpGHDhmnt2rVen7t27VqdffbZCgsL08iRI+Vyubzm8AAIXozcALBUt27d9Nvf/la33367XC6XLrjgAlVVVWnt2rWKiYnRmWeeKUl68MEH1bNnTyUkJOi+++5TfHy8Jk6cKEm64447dN555+mhhx5STk6OCgsL9fTTT+tPf/qTJCklJUVTpkzRjTfeqCeffFKpqanas2ePKioqdO2111q16wA6CeEGgOUeeugh9erVS/n5+dq5c6fi4uJ07rnn6t577/WcFpozZ45mzJihL7/8Umlpafr73/+uyMhISdK5556rv/3tb5o1a5Yeeugh9enTRw8++KB+/vOfe77HM888o3vvvVe/+tWv9M0336h///669957rdhdAJ2Mq6UA+DX3lUyHDh1SXFyc1eUACADMuQEAAEGFcAMAAIIKp6UAAEBQYeQGAAAEFcINAAAIKoQbAAAQVAg3AAAgqBBuAABAUCHcAACAoEK4AQAAQYVwAwAAgsr/B7ST/kJF1ojIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "W9EtO2eBd_Uf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播，计算y_pred\n",
        "def th_forward(w1, w2, w3, b1, b2, b3, x):\n",
        "  z1 = torch.matmul(x, w1) + b1 #shape (2,5)\n",
        "  h1 = torch.relu(z1)\n",
        "\n",
        "  z2 = torch.matmul(h1, w2) + b2 #shape (2,3)\n",
        "  h2 = torch.tanh(z2)\n",
        "\n",
        "  z3 = torch.matmul(h2, w3) + b3 #shape (2,2)\n",
        "  y_pred = torch.softmax(z3, dim=1) #shape (2,2)\n",
        "  return z1, h1, h2, y_pred"
      ],
      "metadata": {
        "id": "nV9BFs8Mk-8p"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算损失函数loss\n",
        "def th_compute_loss(y_pred, y_true):\n",
        "  loss = -(torch.sum(y_true * torch.log(y_pred + 1e-10)) / y_pred.shape[0])\n",
        "  return loss"
      ],
      "metadata": {
        "id": "usc7_ygrlbxv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置随机数种子以保证可复现\n",
        "np.random.seed(42)\n",
        "\n",
        "# 网络层次：\n",
        "# 输入层：4 个神经元\n",
        "# 隐藏层1：5 个神经元 => W1 shape: (4, 5), b1 shape: (5,)\n",
        "# 隐藏层2：3 个神经元 => W2 shape: (5, 3), b2 shape: (3,)\n",
        "# 输出层：2 个神经元    => W3 shape: (3, 2), b3 shape: (2,)\n",
        "\n",
        "w1 = torch.randn(4, 5) * 0.1 #shape (4,5)\n",
        "w1.requires_grad=True\n",
        "\n",
        "b1 = torch.randn(5) * 0.1 #shape (1,5)\n",
        "b1.requires_grad=True\n",
        "\n",
        "w2 = torch.randn(5, 3) * 0.1 #shape (5,3)\n",
        "w2.requires_grad=True\n",
        "b2 = torch.randn(3) * 0.1 #shape (1,3)\n",
        "b2.requires_grad=True\n",
        "\n",
        "w3 = torch.randn(3, 2) * 0.1 #shape (3,2)\n",
        "w3.requires_grad=True\n",
        "b3 = torch.randn(2) * 0.1 #shape (1,2)\n",
        "b3.requires_grad=True\n",
        "\n",
        "x = torch.tensor([[0.2, 0.5, 0.1, 0.9],\n",
        "          [0.7, 0.3, 0.6, 0.2]]) #shape (2,4)\n",
        "\n",
        "y_true = torch.tensor([[1, 0],\n",
        "            [0, 1]]) #shape (2,2)\n",
        "\n",
        "losses = []\n",
        "learning_rate = 0.01\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  z1, h1, h2, y_pred = th_forward(w1, w2, w3, b1, b2, b3, x)\n",
        "  loss = th_compute_loss(y_pred, y_true)\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  if w1.grad is not None:\n",
        "    w1.grad.zero_()\n",
        "    w2.grad.zero_()\n",
        "    w3.grad.zero_()\n",
        "    b1.grad.zero_()\n",
        "    b2.grad.zero_()\n",
        "    b3.grad.zero_()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w1 -= learning_rate * w1.grad\n",
        "    w2 -= learning_rate * w2.grad\n",
        "    w3 -= learning_rate * w3.grad\n",
        "    b1 -= learning_rate * b1.grad\n",
        "    b2 -= learning_rate * b2.grad\n",
        "    b3 -= learning_rate * b3.grad\n",
        "\n",
        "  if epoch%100 == 0:\n",
        "    print(f\"epoch: {epoch + 1}\",\n",
        "      f\"loss: {loss.item():.4f}\",\n",
        "      f\"y_pred: {y_pred.flatten().detach().numpy().round(2)}\",\n",
        "      f\"w1: {w1.flatten().detach().numpy().round(2)}\",\n",
        "      f\"w2: {w2.flatten().detach().numpy().round(2)}\",\n",
        "      f\"w3: {w3.flatten().detach().numpy().round(2)}\",\n",
        "      f\"b1: {b1.flatten().detach().numpy().round(2)}\",\n",
        "      f\"b2: {b2.flatten().detach().numpy().round(2)}\",\n",
        "      f\"b3: {b3.flatten().detach().numpy().round(2)}\"\n",
        "      )\n",
        "\n",
        "plt.plot(range(epochs), losses, \"blue\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8reqw7iteICF",
        "outputId": "b94f43eb-2140-417c-dc1e-89d77cb5f46e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: 0.6932 y_pred: [0.49 0.51 0.49 0.51] w1: [ 0.12  0.   -0.05 -0.08 -0.1   0.13 -0.08  0.16 -0.    0.03 -0.15 -0.1\n",
            " -0.11  0.1   0.13  0.08 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.01 -0.07 -0.08  0.15 -0.1  -0.14  0.06 -0.03  0.   -0.04  0.07\n",
            "  0.11 -0.09  0.13] w3: [ 0.04  0.04 -0.06  0.05 -0.07  0.05] b1: [-0.   -0.17  0.06  0.07 -0.03] b2: [0.08 0.03 0.06] b3: [0.06 0.09]\n",
            "epoch: 101 loss: 0.6930 y_pred: [0.49 0.51 0.49 0.51] w1: [ 0.12  0.   -0.05 -0.08 -0.1   0.13 -0.08  0.16 -0.    0.03 -0.15 -0.1\n",
            " -0.11  0.1   0.13  0.08 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.02 -0.07 -0.08  0.15 -0.1  -0.14  0.06 -0.04  0.   -0.04  0.07\n",
            "  0.11 -0.09  0.13] w3: [ 0.04  0.04 -0.06  0.05 -0.07  0.06] b1: [-0.   -0.17  0.06  0.07 -0.03] b2: [0.08 0.03 0.06] b3: [0.07 0.08]\n",
            "epoch: 201 loss: 0.6928 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.12  0.   -0.05 -0.07 -0.1   0.13 -0.08  0.16 -0.    0.03 -0.16 -0.1\n",
            " -0.11  0.1   0.13  0.08 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.02 -0.07 -0.08  0.15 -0.1  -0.14  0.06 -0.04  0.   -0.03  0.07\n",
            "  0.11 -0.09  0.13] w3: [ 0.04  0.04 -0.06  0.05 -0.07  0.06] b1: [-0.   -0.17  0.06  0.07 -0.04] b2: [0.08 0.02 0.06] b3: [0.07 0.08]\n",
            "epoch: 301 loss: 0.6927 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.11  0.   -0.05 -0.07 -0.1   0.13 -0.08  0.16 -0.    0.02 -0.16 -0.1\n",
            " -0.11  0.1   0.13  0.08 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.02 -0.08 -0.08  0.15 -0.1  -0.14  0.06 -0.04  0.   -0.03  0.07\n",
            "  0.11 -0.09  0.13] w3: [ 0.04  0.05 -0.06  0.05 -0.08  0.06] b1: [-0.   -0.17  0.06  0.07 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.08]\n",
            "epoch: 401 loss: 0.6927 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.11  0.   -0.05 -0.07 -0.1   0.13 -0.08  0.16 -0.    0.02 -0.16 -0.1\n",
            " -0.11  0.1   0.13  0.08 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.02 -0.08 -0.08  0.15 -0.1  -0.14  0.06 -0.04  0.   -0.03  0.07\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.08  0.06] b1: [-0.   -0.17  0.06  0.07 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 501 loss: 0.6926 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.11  0.   -0.05 -0.07 -0.1   0.13 -0.08  0.16 -0.    0.02 -0.16 -0.1\n",
            " -0.11  0.1   0.13  0.09 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.03 -0.09 -0.08  0.15 -0.1  -0.14  0.06 -0.04  0.   -0.03  0.07\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.08  0.07] b1: [-0.   -0.17  0.06  0.08 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 601 loss: 0.6925 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.11  0.   -0.05 -0.07 -0.1   0.13 -0.08  0.16 -0.    0.02 -0.16 -0.1\n",
            " -0.11  0.11  0.13  0.09 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.03 -0.09 -0.08  0.15 -0.1  -0.14  0.06 -0.04  0.   -0.03  0.08\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.09  0.07] b1: [-0.   -0.17  0.06  0.08 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 701 loss: 0.6923 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.11  0.   -0.05 -0.07 -0.1   0.13 -0.08  0.16 -0.    0.02 -0.17 -0.1\n",
            " -0.11  0.11  0.13  0.09 -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.03 -0.09 -0.08  0.15 -0.1  -0.14  0.06 -0.04  0.   -0.03  0.08\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.09  0.08] b1: [-0.   -0.17  0.07  0.08 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 801 loss: 0.6922 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.1   0.   -0.05 -0.07 -0.1   0.14 -0.08  0.16  0.    0.02 -0.17 -0.1\n",
            " -0.11  0.11  0.13  0.1  -0.01 -0.09 -0.13  0.04] w2: [ 0.02 -0.04 -0.1  -0.08  0.15 -0.1  -0.14  0.05 -0.05  0.   -0.02  0.08\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.1   0.08] b1: [-0.   -0.17  0.07  0.08 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 901 loss: 0.6920 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.1   0.   -0.05 -0.06 -0.1   0.14 -0.08  0.16  0.    0.02 -0.17 -0.1\n",
            " -0.11  0.11  0.13  0.1  -0.01 -0.08 -0.13  0.04] w2: [ 0.02 -0.04 -0.11 -0.08  0.15 -0.1  -0.14  0.05 -0.05  0.   -0.02  0.09\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.1   0.09] b1: [-0.   -0.17  0.07  0.09 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 1001 loss: 0.6917 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.1   0.   -0.05 -0.06 -0.1   0.14 -0.08  0.16  0.    0.02 -0.17 -0.1\n",
            " -0.11  0.11  0.13  0.11 -0.01 -0.08 -0.13  0.04] w2: [ 0.02 -0.04 -0.11 -0.08  0.15 -0.1  -0.14  0.05 -0.05  0.   -0.02  0.09\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.11  0.09] b1: [-0.   -0.17  0.07  0.09 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 1101 loss: 0.6914 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.09  0.   -0.05 -0.06 -0.1   0.14 -0.08  0.16  0.    0.02 -0.18 -0.1\n",
            " -0.12  0.12  0.13  0.11 -0.01 -0.08 -0.13  0.04] w2: [ 0.02 -0.05 -0.12 -0.08  0.15 -0.1  -0.14  0.05 -0.05  0.01 -0.02  0.1\n",
            "  0.11 -0.09  0.13] w3: [ 0.03  0.05 -0.06  0.05 -0.12  0.1 ] b1: [-0.   -0.17  0.07  0.09 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 1201 loss: 0.6910 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.09  0.   -0.05 -0.05 -0.1   0.14 -0.08  0.16  0.01  0.02 -0.18 -0.1\n",
            " -0.12  0.12  0.13  0.12 -0.01 -0.08 -0.13  0.04] w2: [ 0.01 -0.05 -0.13 -0.08  0.15 -0.1  -0.14  0.05 -0.06  0.01 -0.01  0.1\n",
            "  0.11 -0.09  0.13] w3: [ 0.02  0.06 -0.06  0.05 -0.12  0.11] b1: [-0.   -0.17  0.07  0.1  -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 1301 loss: 0.6904 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.09  0.   -0.05 -0.05 -0.1   0.14 -0.08  0.16  0.01  0.02 -0.19 -0.1\n",
            " -0.12  0.12  0.13  0.12 -0.01 -0.08 -0.13  0.04] w2: [ 0.01 -0.06 -0.14 -0.08  0.15 -0.1  -0.14  0.05 -0.06  0.01 -0.01  0.11\n",
            "  0.11 -0.09  0.13] w3: [ 0.02  0.06 -0.06  0.05 -0.13  0.12] b1: [-0.   -0.17  0.07  0.11 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 1401 loss: 0.6898 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.08  0.   -0.05 -0.05 -0.1   0.15 -0.08  0.16  0.01  0.02 -0.19 -0.1\n",
            " -0.12  0.13  0.13  0.13 -0.01 -0.07 -0.13  0.04] w2: [ 0.01 -0.06 -0.15 -0.08  0.15 -0.1  -0.14  0.05 -0.07  0.01 -0.01  0.12\n",
            "  0.11 -0.09  0.13] w3: [ 0.02  0.06 -0.06  0.05 -0.14  0.13] b1: [-0.   -0.17  0.07  0.11 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 1501 loss: 0.6888 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.07  0.   -0.05 -0.04 -0.1   0.15 -0.08  0.16  0.01  0.02 -0.2  -0.1\n",
            " -0.12  0.13  0.13  0.14 -0.01 -0.07 -0.13  0.04] w2: [ 0.01 -0.07 -0.16 -0.08  0.15 -0.1  -0.14  0.04 -0.07  0.01 -0.    0.13\n",
            "  0.11 -0.09  0.13] w3: [ 0.02  0.06 -0.06  0.05 -0.16  0.14] b1: [-0.   -0.17  0.07  0.11 -0.04] b2: [0.08 0.02 0.06] b3: [0.08 0.07]\n",
            "epoch: 1601 loss: 0.6876 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.07  0.   -0.05 -0.04 -0.1   0.15 -0.08  0.17  0.01  0.02 -0.21 -0.1\n",
            " -0.12  0.14  0.13  0.15 -0.01 -0.06 -0.14  0.04] w2: [ 0.01 -0.07 -0.18 -0.08  0.15 -0.1  -0.14  0.04 -0.08  0.01  0.    0.14\n",
            "  0.11 -0.09  0.13] w3: [ 0.02  0.06 -0.07  0.06 -0.17  0.16] b1: [ 0.   -0.17  0.07  0.11 -0.04] b2: [0.08 0.02 0.05] b3: [0.08 0.07]\n",
            "epoch: 1701 loss: 0.6859 y_pred: [0.5 0.5 0.5 0.5] w1: [ 0.06  0.   -0.06 -0.03 -0.1   0.16 -0.08  0.17  0.01  0.02 -0.21 -0.1\n",
            " -0.13  0.14  0.13  0.16 -0.01 -0.06 -0.14  0.04] w2: [ 0.   -0.08 -0.2  -0.08  0.15 -0.1  -0.15  0.04 -0.08  0.01  0.    0.15\n",
            "  0.11 -0.09  0.13] w3: [ 0.01  0.07 -0.07  0.06 -0.19  0.17] b1: [ 0.   -0.17  0.08  0.12 -0.04] b2: [0.08 0.02 0.05] b3: [0.08 0.07]\n",
            "epoch: 1801 loss: 0.6834 y_pred: [0.5  0.5  0.49 0.51] w1: [ 0.05  0.   -0.06 -0.02 -0.1   0.16 -0.08  0.17  0.    0.02 -0.22 -0.1\n",
            " -0.13  0.15  0.13  0.18 -0.01 -0.05 -0.15  0.04] w2: [ 0.   -0.09 -0.22 -0.08  0.15 -0.1  -0.15  0.04 -0.09  0.02  0.01  0.16\n",
            "  0.11 -0.09  0.13] w3: [ 0.01  0.07 -0.07  0.06 -0.21  0.19] b1: [ 0.01 -0.17  0.08  0.12 -0.04] b2: [0.08 0.02 0.05] b3: [0.09 0.07]\n",
            "epoch: 1901 loss: 0.6797 y_pred: [0.51 0.49 0.49 0.51] w1: [ 0.04  0.   -0.06 -0.01 -0.1   0.17 -0.08  0.17  0.    0.02 -0.23 -0.1\n",
            " -0.13  0.16  0.13  0.2  -0.01 -0.04 -0.16  0.04] w2: [-0.   -0.1  -0.24 -0.08  0.15 -0.1  -0.15  0.03 -0.1   0.02  0.02  0.18\n",
            "  0.11 -0.09  0.13] w3: [ 0.01  0.07 -0.08  0.07 -0.23  0.22] b1: [ 0.02 -0.17  0.08  0.13 -0.04] b2: [0.08 0.02 0.05] b3: [0.09 0.07]\n",
            "epoch: 2001 loss: 0.6739 y_pred: [0.51 0.49 0.49 0.51] w1: [ 0.03  0.   -0.07  0.   -0.1   0.18 -0.08  0.18  0.    0.02 -0.24 -0.1\n",
            " -0.14  0.17  0.13  0.23 -0.01 -0.03 -0.17  0.04] w2: [-0.01 -0.11 -0.28 -0.08  0.15 -0.1  -0.15  0.03 -0.11  0.02  0.02  0.21\n",
            "  0.11 -0.09  0.13] w3: [ 0.    0.08 -0.09  0.08 -0.26  0.25] b1: [ 0.02 -0.17  0.08  0.13 -0.04] b2: [0.08 0.02 0.05] b3: [0.09 0.07]\n",
            "epoch: 2101 loss: 0.6644 y_pred: [0.52 0.48 0.49 0.51] w1: [ 0.02  0.   -0.07  0.02 -0.1   0.19 -0.08  0.18 -0.    0.02 -0.26 -0.1\n",
            " -0.14  0.19  0.13  0.26 -0.01 -0.02 -0.18  0.04] w2: [-0.01 -0.12 -0.32 -0.08  0.15 -0.1  -0.15  0.02 -0.13  0.03  0.03  0.23\n",
            "  0.11 -0.09  0.13] w3: [-0.01  0.09 -0.1   0.09 -0.3   0.29] b1: [ 0.03 -0.17  0.09  0.14 -0.04] b2: [0.08 0.02 0.05] b3: [0.09 0.07]\n",
            "epoch: 2201 loss: 0.6481 y_pred: [0.52 0.48 0.48 0.52] w1: [-0.    0.   -0.08  0.04 -0.1   0.21 -0.08  0.19 -0.    0.02 -0.28 -0.1\n",
            " -0.15  0.21  0.13  0.3  -0.01 -0.   -0.2   0.04] w2: [-0.02 -0.14 -0.38 -0.08  0.15 -0.1  -0.16  0.02 -0.15  0.03  0.05  0.27\n",
            "  0.11 -0.09  0.13] w3: [-0.01  0.1  -0.11  0.1  -0.35  0.34] b1: [ 0.05 -0.17  0.09  0.15 -0.04] b2: [0.08 0.02 0.05] b3: [0.08 0.07]\n",
            "epoch: 2301 loss: 0.6185 y_pred: [0.54 0.46 0.47 0.53] w1: [-0.03  0.   -0.09  0.07 -0.1   0.23 -0.08  0.2  -0.01  0.02 -0.31 -0.1\n",
            " -0.17  0.24  0.13  0.36 -0.01  0.02 -0.23  0.04] w2: [-0.04 -0.16 -0.45 -0.08  0.15 -0.1  -0.16  0.01 -0.18  0.04  0.06  0.32\n",
            "  0.11 -0.09  0.13] w3: [-0.03  0.11 -0.13  0.12 -0.42  0.4 ] b1: [ 0.06 -0.17  0.1   0.17 -0.04] b2: [0.08 0.02 0.05] b3: [0.08 0.07]\n",
            "epoch: 2401 loss: 0.5642 y_pred: [0.58 0.42 0.44 0.56] w1: [-0.07  0.   -0.11  0.12 -0.1   0.26 -0.08  0.21 -0.01  0.02 -0.35 -0.1\n",
            " -0.18  0.28  0.13  0.44 -0.01  0.05 -0.26  0.04] w2: [-0.05 -0.19 -0.55 -0.08  0.15 -0.1  -0.17 -0.   -0.22  0.05  0.08  0.39\n",
            "  0.11 -0.09  0.13] w3: [-0.04  0.12 -0.15  0.14 -0.51  0.5 ] b1: [ 0.09 -0.17  0.11  0.19 -0.04] b2: [0.08 0.03 0.06] b3: [0.08 0.08]\n",
            "epoch: 2501 loss: 0.4723 y_pred: [0.64 0.36 0.39 0.61] w1: [-0.11  0.   -0.13  0.17 -0.1   0.29 -0.08  0.22 -0.02  0.02 -0.4  -0.1\n",
            " -0.2   0.34  0.13  0.54 -0.01  0.09 -0.31  0.04] w2: [-0.08 -0.23 -0.67 -0.08  0.15 -0.1  -0.18 -0.02 -0.27  0.07  0.11  0.49\n",
            "  0.11 -0.09  0.13] w3: [-0.07  0.15 -0.19  0.18 -0.63  0.62] b1: [ 0.12 -0.17  0.12  0.22 -0.04] b2: [0.08 0.03 0.09] b3: [0.07 0.09]\n",
            "epoch: 2601 loss: 0.3510 y_pred: [0.72 0.28 0.31 0.69] w1: [-0.16  0.   -0.15  0.24 -0.1   0.33 -0.08  0.24 -0.02  0.02 -0.45 -0.1\n",
            " -0.22  0.4   0.13  0.65 -0.01  0.14 -0.36  0.04] w2: [-0.1  -0.28 -0.8  -0.08  0.15 -0.1  -0.19 -0.04 -0.32  0.09  0.15  0.59\n",
            "  0.11 -0.09  0.13] w3: [-0.09  0.17 -0.23  0.22 -0.78  0.76] b1: [ 0.15 -0.17  0.14  0.25 -0.04] b2: [0.08 0.04 0.13] b3: [0.05 0.1 ]\n",
            "epoch: 2701 loss: 0.2406 y_pred: [0.8  0.2  0.22 0.78] w1: [-0.2   0.   -0.16  0.31 -0.1   0.37 -0.08  0.25 -0.03  0.02 -0.49 -0.1\n",
            " -0.24  0.47  0.13  0.74 -0.01  0.18 -0.42  0.04] w2: [-0.14 -0.33 -0.91 -0.08  0.15 -0.1  -0.2  -0.06 -0.36  0.11  0.19  0.7\n",
            "  0.11 -0.09  0.13] w3: [-0.12  0.2  -0.28  0.27 -0.92  0.9 ] b1: [ 0.18 -0.17  0.15  0.29 -0.04] b2: [0.09 0.04 0.17] b3: [0.04 0.11]\n",
            "epoch: 2801 loss: 0.1653 y_pred: [0.85 0.15 0.16 0.84] w1: [-0.24  0.   -0.18  0.36 -0.1   0.39 -0.08  0.26 -0.04  0.02 -0.53 -0.1\n",
            " -0.26  0.52  0.13  0.82 -0.01  0.21 -0.46  0.04] w2: [-0.17 -0.38 -0.99 -0.08  0.15 -0.1  -0.21 -0.08 -0.39  0.14  0.23  0.78\n",
            "  0.11 -0.09  0.13] w3: [-0.15  0.23 -0.33  0.32 -1.04  1.02] b1: [ 0.2  -0.17  0.16  0.31 -0.04] b2: [0.09 0.05 0.2 ] b3: [0.03 0.12]\n",
            "epoch: 2901 loss: 0.1188 y_pred: [0.89 0.11 0.12 0.88] w1: [-0.26  0.   -0.19  0.41 -0.1   0.41 -0.08  0.27 -0.04  0.02 -0.56 -0.1\n",
            " -0.27  0.56  0.13  0.87 -0.01  0.23 -0.5   0.04] w2: [-0.19 -0.42 -1.04 -0.08  0.15 -0.1  -0.22 -0.09 -0.42  0.16  0.26  0.84\n",
            "  0.11 -0.09  0.13] w3: [-0.18  0.26 -0.37  0.36 -1.13  1.12] b1: [ 0.22 -0.17  0.16  0.33 -0.04] b2: [0.09 0.06 0.22] b3: [0.03 0.12]\n",
            "epoch: 3001 loss: 0.0897 y_pred: [0.92 0.08 0.09 0.91] w1: [-0.28  0.   -0.2   0.44 -0.1   0.43 -0.08  0.28 -0.05  0.02 -0.58 -0.1\n",
            " -0.27  0.59  0.13  0.91 -0.01  0.25 -0.52  0.04] w2: [-0.21 -0.45 -1.08 -0.08  0.15 -0.1  -0.23 -0.11 -0.43  0.18  0.3   0.89\n",
            "  0.11 -0.09  0.13] w3: [-0.2   0.28 -0.41  0.4  -1.21  1.2 ] b1: [ 0.23 -0.17  0.17  0.35 -0.04] b2: [0.09 0.06 0.24] b3: [0.03 0.13]\n",
            "epoch: 3101 loss: 0.0706 y_pred: [0.93 0.07 0.07 0.93] w1: [-0.3   0.   -0.2   0.46 -0.1   0.44 -0.08  0.28 -0.05  0.02 -0.59 -0.1\n",
            " -0.28  0.61  0.13  0.94 -0.01  0.26 -0.54  0.04] w2: [-0.23 -0.48 -1.11 -0.08  0.15 -0.1  -0.24 -0.12 -0.44  0.2   0.32  0.92\n",
            "  0.11 -0.09  0.13] w3: [-0.22  0.3  -0.44  0.43 -1.27  1.26] b1: [ 0.24 -0.17  0.17  0.36 -0.04] b2: [0.09 0.07 0.25] b3: [0.02 0.13]\n",
            "epoch: 3201 loss: 0.0574 y_pred: [0.95 0.05 0.06 0.94] w1: [-0.31  0.   -0.21  0.49 -0.1   0.45 -0.08  0.29 -0.05  0.02 -0.6  -0.1\n",
            " -0.29  0.63  0.13  0.97 -0.01  0.27 -0.56  0.04] w2: [-0.25 -0.5  -1.14 -0.08  0.15 -0.1  -0.25 -0.13 -0.45  0.21  0.35  0.95\n",
            "  0.11 -0.09  0.13] w3: [-0.24  0.32 -0.46  0.45 -1.33  1.31] b1: [ 0.25 -0.17  0.18  0.37 -0.04] b2: [0.1  0.08 0.26] b3: [0.02 0.13]\n",
            "epoch: 3301 loss: 0.0479 y_pred: [0.95 0.05 0.05 0.95] w1: [-0.32  0.   -0.21  0.5  -0.1   0.45 -0.08  0.29 -0.05  0.02 -0.61 -0.1\n",
            " -0.29  0.65  0.13  0.99 -0.01  0.28 -0.58  0.04] w2: [-0.27 -0.52 -1.15 -0.08  0.15 -0.1  -0.25 -0.14 -0.46  0.22  0.37  0.97\n",
            "  0.11 -0.09  0.13] w3: [-0.26  0.34 -0.49  0.48 -1.37  1.35] b1: [ 0.26 -0.17  0.18  0.38 -0.04] b2: [0.1  0.08 0.26] b3: [0.02 0.13]\n",
            "epoch: 3401 loss: 0.0408 y_pred: [0.96 0.04 0.04 0.96] w1: [-0.32  0.   -0.21  0.52 -0.1   0.46 -0.08  0.29 -0.06  0.02 -0.62 -0.1\n",
            " -0.29  0.66  0.13  1.01 -0.01  0.29 -0.59  0.04] w2: [-0.28 -0.54 -1.17 -0.08  0.15 -0.1  -0.26 -0.14 -0.47  0.24  0.38  0.98\n",
            "  0.11 -0.09  0.13] w3: [-0.27  0.35 -0.51  0.5  -1.41  1.39] b1: [ 0.26 -0.17  0.18  0.39 -0.04] b2: [0.1  0.08 0.27] b3: [0.02 0.13]\n",
            "epoch: 3501 loss: 0.0353 y_pred: [0.97 0.03 0.04 0.96] w1: [-0.33  0.   -0.22  0.53 -0.1   0.47 -0.08  0.29 -0.06  0.02 -0.63 -0.1\n",
            " -0.3   0.67  0.13  1.02 -0.01  0.29 -0.6   0.04] w2: [-0.29 -0.55 -1.18 -0.08  0.15 -0.1  -0.26 -0.15 -0.47  0.25  0.4   1.\n",
            "  0.11 -0.09  0.13] w3: [-0.28  0.36 -0.53  0.52 -1.44  1.42] b1: [ 0.27 -0.17  0.18  0.39 -0.04] b2: [0.1  0.09 0.27] b3: [0.02 0.13]\n",
            "epoch: 3601 loss: 0.0310 y_pred: [0.97 0.03 0.03 0.97] w1: [-0.34  0.   -0.22  0.54 -0.1   0.47 -0.08  0.3  -0.06  0.02 -0.64 -0.1\n",
            " -0.3   0.69  0.13  1.04 -0.01  0.3  -0.61  0.04] w2: [-0.31 -0.57 -1.19 -0.08  0.15 -0.1  -0.27 -0.15 -0.48  0.26  0.41  1.01\n",
            "  0.11 -0.09  0.13] w3: [-0.3   0.38 -0.55  0.54 -1.47  1.45] b1: [ 0.27 -0.17  0.19  0.4  -0.04] b2: [0.1  0.09 0.28] b3: [0.02 0.14]\n",
            "epoch: 3701 loss: 0.0276 y_pred: [0.97 0.03 0.03 0.97] w1: [-0.34  0.   -0.22  0.55 -0.1   0.47 -0.08  0.3  -0.06  0.02 -0.64 -0.1\n",
            " -0.3   0.69  0.13  1.05 -0.01  0.3  -0.61  0.04] w2: [-0.32 -0.58 -1.2  -0.08  0.15 -0.1  -0.27 -0.16 -0.48  0.27  0.43  1.02\n",
            "  0.11 -0.09  0.13] w3: [-0.31  0.39 -0.56  0.55 -1.49  1.48] b1: [ 0.27 -0.17  0.19  0.4  -0.04] b2: [0.1  0.09 0.28] b3: [0.01 0.14]\n",
            "epoch: 3801 loss: 0.0248 y_pred: [0.98 0.02 0.03 0.97] w1: [-0.35  0.   -0.22  0.56 -0.1   0.48 -0.08  0.3  -0.06  0.02 -0.65 -0.1\n",
            " -0.31  0.7   0.13  1.06 -0.01  0.31 -0.62  0.04] w2: [-0.33 -0.59 -1.21 -0.08  0.15 -0.1  -0.28 -0.16 -0.48  0.28  0.44  1.03\n",
            "  0.11 -0.09  0.13] w3: [-0.32  0.4  -0.58  0.57 -1.52  1.5 ] b1: [ 0.28 -0.17  0.19  0.41 -0.04] b2: [0.1  0.1  0.28] b3: [0.01 0.14]\n",
            "epoch: 3901 loss: 0.0224 y_pred: [0.98 0.02 0.02 0.98] w1: [-0.35  0.   -0.23  0.57 -0.1   0.48 -0.08  0.3  -0.06  0.02 -0.65 -0.1\n",
            " -0.31  0.71  0.13  1.07 -0.01  0.31 -0.63  0.04] w2: [-0.33 -0.6  -1.22 -0.08  0.15 -0.1  -0.28 -0.17 -0.49  0.28  0.45  1.04\n",
            "  0.11 -0.09  0.13] w3: [-0.33  0.41 -0.59  0.58 -1.54  1.52] b1: [ 0.28 -0.17  0.19  0.41 -0.04] b2: [0.1  0.1  0.29] b3: [0.01 0.14]\n",
            "epoch: 4001 loss: 0.0204 y_pred: [0.98 0.02 0.02 0.98] w1: [-0.36  0.   -0.23  0.58 -0.1   0.49 -0.08  0.3  -0.06  0.02 -0.66 -0.1\n",
            " -0.31  0.72  0.13  1.08 -0.01  0.32 -0.63  0.04] w2: [-0.34 -0.61 -1.22 -0.08  0.15 -0.1  -0.28 -0.17 -0.49  0.29  0.46  1.05\n",
            "  0.11 -0.09  0.13] w3: [-0.34  0.42 -0.6   0.59 -1.56  1.54] b1: [ 0.28 -0.17  0.19  0.42 -0.04] b2: [0.1  0.1  0.29] b3: [0.01 0.14]\n",
            "epoch: 4101 loss: 0.0188 y_pred: [0.98 0.02 0.02 0.98] w1: [-0.36  0.   -0.23  0.58 -0.1   0.49 -0.08  0.3  -0.06  0.02 -0.66 -0.1\n",
            " -0.31  0.72  0.13  1.09 -0.01  0.32 -0.64  0.04] w2: [-0.35 -0.62 -1.23 -0.08  0.15 -0.1  -0.29 -0.17 -0.49  0.3   0.47  1.05\n",
            "  0.11 -0.09  0.13] w3: [-0.34  0.43 -0.62  0.61 -1.57  1.56] b1: [ 0.29 -0.17  0.19  0.42 -0.04] b2: [0.1  0.1  0.29] b3: [0.01 0.14]\n",
            "epoch: 4201 loss: 0.0173 y_pred: [0.98 0.02 0.02 0.98] w1: [-0.36  0.   -0.23  0.59 -0.1   0.49 -0.08  0.31 -0.06  0.02 -0.66 -0.1\n",
            " -0.31  0.73  0.13  1.09 -0.01  0.32 -0.64  0.04] w2: [-0.36 -0.62 -1.23 -0.08  0.15 -0.1  -0.29 -0.18 -0.49  0.3   0.48  1.06\n",
            "  0.11 -0.09  0.13] w3: [-0.35  0.43 -0.63  0.62 -1.59  1.58] b1: [ 0.29 -0.17  0.19  0.42 -0.04] b2: [0.11 0.11 0.29] b3: [0.01 0.14]\n",
            "epoch: 4301 loss: 0.0160 y_pred: [0.98 0.02 0.02 0.98] w1: [-0.37  0.   -0.23  0.59 -0.1   0.49 -0.08  0.31 -0.06  0.02 -0.67 -0.1\n",
            " -0.31  0.74  0.13  1.1  -0.01  0.33 -0.65  0.04] w2: [-0.36 -0.63 -1.24 -0.08  0.15 -0.1  -0.29 -0.18 -0.49  0.31  0.49  1.07\n",
            "  0.11 -0.09  0.13] w3: [-0.36  0.44 -0.64  0.63 -1.61  1.59] b1: [ 0.29 -0.17  0.19  0.43 -0.04] b2: [0.11 0.11 0.29] b3: [0.01 0.14]\n",
            "epoch: 4401 loss: 0.0149 y_pred: [0.99 0.01 0.02 0.98] w1: [-0.37  0.   -0.23  0.6  -0.1   0.5  -0.08  0.31 -0.06  0.02 -0.67 -0.1\n",
            " -0.31  0.74  0.13  1.11 -0.01  0.33 -0.65  0.04] w2: [-0.37 -0.64 -1.24 -0.08  0.15 -0.1  -0.29 -0.18 -0.5   0.32  0.49  1.07\n",
            "  0.11 -0.09  0.13] w3: [-0.37  0.45 -0.65  0.64 -1.62  1.6 ] b1: [ 0.29 -0.17  0.19  0.43 -0.04] b2: [0.11 0.11 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 4501 loss: 0.0140 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.37  0.   -0.23  0.6  -0.1   0.5  -0.08  0.31 -0.07  0.02 -0.67 -0.1\n",
            " -0.32  0.75  0.13  1.11 -0.01  0.33 -0.66  0.04] w2: [-0.38 -0.64 -1.24 -0.08  0.15 -0.1  -0.3  -0.19 -0.5   0.32  0.5   1.08\n",
            "  0.11 -0.09  0.13] w3: [-0.37  0.46 -0.66  0.65 -1.63  1.62] b1: [ 0.29 -0.17  0.2   0.43 -0.04] b2: [0.11 0.11 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 4601 loss: 0.0131 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.37  0.   -0.24  0.61 -0.1   0.5  -0.08  0.31 -0.07  0.02 -0.68 -0.1\n",
            " -0.32  0.75  0.13  1.12 -0.01  0.33 -0.66  0.04] w2: [-0.38 -0.65 -1.25 -0.08  0.15 -0.1  -0.3  -0.19 -0.5   0.33  0.51  1.08\n",
            "  0.11 -0.09  0.13] w3: [-0.38  0.46 -0.66  0.65 -1.65  1.63] b1: [ 0.29 -0.17  0.2   0.43 -0.04] b2: [0.11 0.11 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 4701 loss: 0.0123 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.38  0.   -0.24  0.61 -0.1   0.5  -0.08  0.31 -0.07  0.02 -0.68 -0.1\n",
            " -0.32  0.75  0.13  1.12 -0.01  0.34 -0.67  0.04] w2: [-0.39 -0.66 -1.25 -0.08  0.15 -0.1  -0.3  -0.19 -0.5   0.33  0.51  1.08\n",
            "  0.11 -0.09  0.13] w3: [-0.39  0.47 -0.67  0.66 -1.66  1.64] b1: [ 0.3  -0.17  0.2   0.44 -0.04] b2: [0.11 0.12 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 4801 loss: 0.0117 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.38  0.   -0.24  0.62 -0.1   0.5  -0.08  0.31 -0.07  0.02 -0.68 -0.1\n",
            " -0.32  0.76  0.13  1.13 -0.01  0.34 -0.67  0.04] w2: [-0.39 -0.66 -1.25 -0.08  0.15 -0.1  -0.3  -0.19 -0.5   0.34  0.52  1.09\n",
            "  0.11 -0.09  0.13] w3: [-0.39  0.47 -0.68  0.67 -1.67  1.65] b1: [ 0.3  -0.17  0.2   0.44 -0.04] b2: [0.11 0.12 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 4901 loss: 0.0110 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.38  0.   -0.24  0.62 -0.1   0.5  -0.08  0.31 -0.07  0.02 -0.68 -0.1\n",
            " -0.32  0.76  0.13  1.13 -0.01  0.34 -0.67  0.04] w2: [-0.4  -0.67 -1.26 -0.08  0.15 -0.1  -0.31 -0.19 -0.5   0.34  0.52  1.09\n",
            "  0.11 -0.09  0.13] w3: [-0.4   0.48 -0.69  0.68 -1.68  1.66] b1: [ 0.3  -0.17  0.2   0.44 -0.04] b2: [0.11 0.12 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 5001 loss: 0.0105 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.38  0.   -0.24  0.63 -0.1   0.51 -0.08  0.31 -0.07  0.02 -0.69 -0.1\n",
            " -0.32  0.77  0.13  1.14 -0.01  0.34 -0.67  0.04] w2: [-0.4  -0.67 -1.26 -0.08  0.15 -0.1  -0.31 -0.2  -0.5   0.35  0.53  1.1\n",
            "  0.11 -0.09  0.13] w3: [-0.4   0.49 -0.7   0.69 -1.69  1.67] b1: [ 0.3  -0.17  0.2   0.44 -0.04] b2: [0.11 0.12 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 5101 loss: 0.0100 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.39  0.   -0.24  0.63 -0.1   0.51 -0.08  0.31 -0.07  0.02 -0.69 -0.1\n",
            " -0.32  0.77  0.13  1.14 -0.01  0.34 -0.68  0.04] w2: [-0.4  -0.68 -1.26 -0.08  0.15 -0.1  -0.31 -0.2  -0.5   0.35  0.54  1.1\n",
            "  0.11 -0.09  0.13] w3: [-0.41  0.49 -0.7   0.69 -1.7   1.68] b1: [ 0.3  -0.17  0.2   0.44 -0.04] b2: [0.11 0.12 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 5201 loss: 0.0095 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.39  0.   -0.24  0.63 -0.1   0.51 -0.08  0.31 -0.07  0.02 -0.69 -0.1\n",
            " -0.32  0.77  0.13  1.14 -0.01  0.34 -0.68  0.04] w2: [-0.41 -0.68 -1.26 -0.08  0.15 -0.1  -0.31 -0.2  -0.51  0.35  0.54  1.1\n",
            "  0.11 -0.09  0.13] w3: [-0.42  0.5  -0.71  0.7  -1.71  1.69] b1: [ 0.3  -0.17  0.2   0.45 -0.04] b2: [0.11 0.12 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 5301 loss: 0.0091 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.39  0.   -0.24  0.64 -0.1   0.51 -0.08  0.31 -0.07  0.02 -0.69 -0.1\n",
            " -0.32  0.77  0.13  1.15 -0.01  0.35 -0.68  0.04] w2: [-0.41 -0.68 -1.27 -0.08  0.15 -0.1  -0.31 -0.2  -0.51  0.36  0.54  1.1\n",
            "  0.11 -0.09  0.13] w3: [-0.42  0.5  -0.72  0.71 -1.72  1.7 ] b1: [ 0.3  -0.17  0.2   0.45 -0.04] b2: [0.11 0.12 0.3 ] b3: [0.01 0.14]\n",
            "epoch: 5401 loss: 0.0087 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.39  0.   -0.24  0.64 -0.1   0.51 -0.08  0.31 -0.07  0.02 -0.69 -0.1\n",
            " -0.32  0.78  0.13  1.15 -0.01  0.35 -0.69  0.04] w2: [-0.42 -0.69 -1.27 -0.08  0.15 -0.1  -0.31 -0.2  -0.51  0.36  0.55  1.11\n",
            "  0.11 -0.09  0.13] w3: [-0.42  0.51 -0.72  0.71 -1.72  1.71] b1: [ 0.31 -0.17  0.2   0.45 -0.04] b2: [0.11 0.12 0.31] b3: [0.01 0.14]\n",
            "epoch: 5501 loss: 0.0083 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.39  0.   -0.24  0.64 -0.1   0.51 -0.08  0.32 -0.07  0.02 -0.69 -0.1\n",
            " -0.33  0.78  0.13  1.15 -0.01  0.35 -0.69  0.04] w2: [-0.42 -0.69 -1.27 -0.08  0.15 -0.1  -0.32 -0.2  -0.51  0.37  0.55  1.11\n",
            "  0.11 -0.09  0.13] w3: [-0.43  0.51 -0.73  0.72 -1.73  1.72] b1: [ 0.31 -0.17  0.2   0.45 -0.04] b2: [0.11 0.12 0.31] b3: [0.01 0.14]\n",
            "epoch: 5601 loss: 0.0080 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.39  0.   -0.24  0.64 -0.1   0.51 -0.08  0.32 -0.07  0.02 -0.7  -0.1\n",
            " -0.33  0.78  0.13  1.16 -0.01  0.35 -0.69  0.04] w2: [-0.42 -0.69 -1.27 -0.08  0.15 -0.1  -0.32 -0.21 -0.51  0.37  0.56  1.11\n",
            "  0.11 -0.09  0.13] w3: [-0.43  0.51 -0.73  0.72 -1.74  1.72] b1: [ 0.31 -0.17  0.2   0.45 -0.04] b2: [0.11 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 5701 loss: 0.0077 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.39  0.   -0.24  0.65 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.7  -0.1\n",
            " -0.33  0.79  0.13  1.16 -0.01  0.35 -0.69  0.04] w2: [-0.43 -0.7  -1.27 -0.08  0.15 -0.1  -0.32 -0.21 -0.51  0.37  0.56  1.11\n",
            "  0.11 -0.09  0.13] w3: [-0.44  0.52 -0.74  0.73 -1.75  1.73] b1: [ 0.31 -0.17  0.2   0.45 -0.04] b2: [0.11 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 5801 loss: 0.0074 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.24  0.65 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.7  -0.1\n",
            " -0.33  0.79  0.13  1.16 -0.01  0.35 -0.69  0.04] w2: [-0.43 -0.7  -1.28 -0.08  0.15 -0.1  -0.32 -0.21 -0.51  0.38  0.57  1.12\n",
            "  0.11 -0.09  0.13] w3: [-0.44  0.52 -0.75  0.74 -1.75  1.74] b1: [ 0.31 -0.17  0.2   0.45 -0.04] b2: [0.11 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 5901 loss: 0.0071 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.25  0.65 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.7  -0.1\n",
            " -0.33  0.79  0.13  1.17 -0.01  0.36 -0.7   0.04] w2: [-0.43 -0.7  -1.28 -0.08  0.15 -0.1  -0.32 -0.21 -0.51  0.38  0.57  1.12\n",
            "  0.11 -0.09  0.13] w3: [-0.45  0.53 -0.75  0.74 -1.76  1.75] b1: [ 0.31 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6001 loss: 0.0069 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.25  0.66 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.7  -0.1\n",
            " -0.33  0.79  0.13  1.17 -0.01  0.36 -0.7   0.04] w2: [-0.44 -0.71 -1.28 -0.08  0.15 -0.1  -0.32 -0.21 -0.51  0.38  0.57  1.12\n",
            "  0.11 -0.09  0.13] w3: [-0.45  0.53 -0.76  0.75 -1.77  1.75] b1: [ 0.31 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6101 loss: 0.0066 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.25  0.66 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.7  -0.1\n",
            " -0.33  0.8   0.13  1.17 -0.01  0.36 -0.7   0.04] w2: [-0.44 -0.71 -1.28 -0.08  0.15 -0.1  -0.32 -0.21 -0.51  0.39  0.58  1.12\n",
            "  0.11 -0.09  0.13] w3: [-0.45  0.54 -0.76  0.75 -1.77  1.76] b1: [ 0.31 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6201 loss: 0.0064 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.25  0.66 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.7  -0.1\n",
            " -0.33  0.8   0.13  1.17 -0.01  0.36 -0.7   0.04] w2: [-0.44 -0.71 -1.28 -0.08  0.15 -0.1  -0.32 -0.21 -0.51  0.39  0.58  1.12\n",
            "  0.11 -0.09  0.13] w3: [-0.46  0.54 -0.77  0.76 -1.78  1.76] b1: [ 0.31 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6301 loss: 0.0062 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.25  0.66 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.8   0.13  1.18 -0.01  0.36 -0.7   0.04] w2: [-0.45 -0.72 -1.28 -0.08  0.15 -0.1  -0.33 -0.21 -0.51  0.39  0.58  1.13\n",
            "  0.11 -0.09  0.13] w3: [-0.46  0.54 -0.77  0.76 -1.79  1.77] b1: [ 0.31 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6401 loss: 0.0060 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.25  0.66 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.8   0.13  1.18 -0.01  0.36 -0.71  0.04] w2: [-0.45 -0.72 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.51  0.39  0.58  1.13\n",
            "  0.11 -0.09  0.13] w3: [-0.47  0.55 -0.77  0.76 -1.79  1.78] b1: [ 0.31 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6501 loss: 0.0058 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.4   0.   -0.25  0.67 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.8   0.13  1.18 -0.01  0.36 -0.71  0.04] w2: [-0.45 -0.72 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.51  0.4   0.59  1.13\n",
            "  0.11 -0.09  0.13] w3: [-0.47  0.55 -0.78  0.77 -1.8   1.78] b1: [ 0.31 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6601 loss: 0.0056 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.41  0.   -0.25  0.67 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.81  0.13  1.18 -0.01  0.36 -0.71  0.04] w2: [-0.45 -0.72 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.52  0.4   0.59  1.13\n",
            "  0.11 -0.09  0.13] w3: [-0.47  0.55 -0.78  0.77 -1.8   1.79] b1: [ 0.32 -0.17  0.2   0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6701 loss: 0.0055 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.41  0.   -0.25  0.67 -0.1   0.52 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.81  0.13  1.19 -0.01  0.36 -0.71  0.04] w2: [-0.46 -0.73 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.52  0.4   0.59  1.13\n",
            "  0.11 -0.09  0.13] w3: [-0.48  0.56 -0.79  0.78 -1.81  1.79] b1: [ 0.32 -0.17  0.21  0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6801 loss: 0.0053 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.41  0.   -0.25  0.67 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.81  0.13  1.19 -0.01  0.36 -0.71  0.04] w2: [-0.46 -0.73 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.52  0.4   0.6   1.13\n",
            "  0.11 -0.09  0.13] w3: [-0.48  0.56 -0.79  0.78 -1.81  1.8 ] b1: [ 0.32 -0.17  0.21  0.46 -0.04] b2: [0.12 0.13 0.31] b3: [0.01 0.14]\n",
            "epoch: 6901 loss: 0.0052 y_pred: [0.99 0.01 0.01 0.99] w1: [-0.41  0.   -0.25  0.67 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.81  0.13  1.19 -0.01  0.37 -0.71  0.04] w2: [-0.46 -0.73 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.52  0.41  0.6   1.13\n",
            "  0.11 -0.09  0.13] w3: [-0.48  0.56 -0.8   0.79 -1.82  1.8 ] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7001 loss: 0.0050 y_pred: [1.   0.   0.01 0.99] w1: [-0.41  0.   -0.25  0.68 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.81  0.13  1.19 -0.01  0.37 -0.72  0.04] w2: [-0.46 -0.73 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.52  0.41  0.6   1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.48  0.57 -0.8   0.79 -1.82  1.81] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7101 loss: 0.0049 y_pred: [1. 0. 0. 1.] w1: [-0.41  0.   -0.25  0.68 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.71 -0.1\n",
            " -0.33  0.81  0.13  1.19 -0.01  0.37 -0.72  0.04] w2: [-0.46 -0.73 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.52  0.41  0.6   1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.49  0.57 -0.8   0.79 -1.83  1.81] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7201 loss: 0.0048 y_pred: [1. 0. 0. 1.] w1: [-0.41  0.   -0.25  0.68 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.33  0.82  0.13  1.2  -0.01  0.37 -0.72  0.04] w2: [-0.47 -0.74 -1.29 -0.08  0.15 -0.1  -0.33 -0.22 -0.52  0.41  0.61  1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.49  0.57 -0.81  0.8  -1.83  1.82] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7301 loss: 0.0047 y_pred: [1. 0. 0. 1.] w1: [-0.41  0.   -0.25  0.68 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.33  0.82  0.13  1.2  -0.01  0.37 -0.72  0.04] w2: [-0.47 -0.74 -1.3  -0.08  0.15 -0.1  -0.34 -0.22 -0.52  0.42  0.61  1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.49  0.57 -0.81  0.8  -1.84  1.82] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7401 loss: 0.0045 y_pred: [1. 0. 0. 1.] w1: [-0.41  0.   -0.25  0.68 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.34  0.82  0.13  1.2  -0.01  0.37 -0.72  0.04] w2: [-0.47 -0.74 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.42  0.61  1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.5   0.58 -0.81  0.8  -1.84  1.83] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7501 loss: 0.0044 y_pred: [1. 0. 0. 1.] w1: [-0.41  0.   -0.25  0.68 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.34  0.82  0.13  1.2  -0.01  0.37 -0.72  0.04] w2: [-0.47 -0.74 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.42  0.61  1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.5   0.58 -0.82  0.81 -1.85  1.83] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7601 loss: 0.0043 y_pred: [1. 0. 0. 1.] w1: [-0.41  0.   -0.25  0.69 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.34  0.82  0.13  1.2  -0.01  0.37 -0.72  0.04] w2: [-0.48 -0.74 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.42  0.62  1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.5   0.58 -0.82  0.81 -1.85  1.83] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.31] b3: [0.01 0.14]\n",
            "epoch: 7701 loss: 0.0042 y_pred: [1. 0. 0. 1.] w1: [-0.41  0.   -0.25  0.69 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.34  0.82  0.13  1.21 -0.01  0.37 -0.72  0.04] w2: [-0.48 -0.75 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.42  0.62  1.14\n",
            "  0.11 -0.09  0.13] w3: [-0.5   0.59 -0.82  0.81 -1.85  1.84] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 7801 loss: 0.0041 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.25  0.69 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.34  0.82  0.13  1.21 -0.01  0.37 -0.73  0.04] w2: [-0.48 -0.75 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.43  0.62  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.51  0.59 -0.83  0.82 -1.86  1.84] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 7901 loss: 0.0040 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.25  0.69 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.34  0.83  0.13  1.21 -0.01  0.37 -0.73  0.04] w2: [-0.48 -0.75 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.43  0.62  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.51  0.59 -0.83  0.82 -1.86  1.85] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8001 loss: 0.0040 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.25  0.69 -0.1   0.53 -0.08  0.32 -0.07  0.02 -0.72 -0.1\n",
            " -0.34  0.83  0.13  1.21 -0.01  0.37 -0.73  0.04] w2: [-0.48 -0.75 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.43  0.62  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.51  0.59 -0.83  0.82 -1.87  1.85] b1: [ 0.32 -0.17  0.21  0.47 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8101 loss: 0.0039 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.25  0.69 -0.1   0.53 -0.08  0.32 -0.08  0.02 -0.72 -0.1\n",
            " -0.34  0.83  0.13  1.21 -0.01  0.38 -0.73  0.04] w2: [-0.48 -0.75 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.43  0.63  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.51  0.6  -0.84  0.83 -1.87  1.85] b1: [ 0.32 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8201 loss: 0.0038 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.69 -0.1   0.53 -0.08  0.32 -0.08  0.02 -0.72 -0.1\n",
            " -0.34  0.83  0.13  1.21 -0.01  0.38 -0.73  0.04] w2: [-0.49 -0.75 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.43  0.63  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.52  0.6  -0.84  0.83 -1.87  1.86] b1: [ 0.32 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8301 loss: 0.0037 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.69 -0.1   0.53 -0.08  0.33 -0.08  0.02 -0.72 -0.1\n",
            " -0.34  0.83  0.13  1.21 -0.01  0.38 -0.73  0.04] w2: [-0.49 -0.76 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.43  0.63  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.52  0.6  -0.84  0.83 -1.88  1.86] b1: [ 0.32 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8401 loss: 0.0036 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.72 -0.1\n",
            " -0.34  0.83  0.13  1.22 -0.01  0.38 -0.73  0.04] w2: [-0.49 -0.76 -1.3  -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.44  0.63  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.52  0.6  -0.84  0.83 -1.88  1.86] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8501 loss: 0.0036 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.83  0.13  1.22 -0.01  0.38 -0.73  0.04] w2: [-0.49 -0.76 -1.31 -0.08  0.15 -0.1  -0.34 -0.23 -0.52  0.44  0.63  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.52  0.61 -0.85  0.84 -1.88  1.87] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8601 loss: 0.0035 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.83  0.13  1.22 -0.01  0.38 -0.73  0.04] w2: [-0.49 -0.76 -1.31 -0.08  0.15 -0.1  -0.35 -0.23 -0.52  0.44  0.63  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.53  0.61 -0.85  0.84 -1.89  1.87] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8701 loss: 0.0034 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.22 -0.01  0.38 -0.74  0.04] w2: [-0.49 -0.76 -1.31 -0.08  0.15 -0.1  -0.35 -0.23 -0.52  0.44  0.64  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.53  0.61 -0.85  0.84 -1.89  1.87] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8801 loss: 0.0034 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.22 -0.01  0.38 -0.74  0.04] w2: [-0.5  -0.76 -1.31 -0.08  0.15 -0.1  -0.35 -0.23 -0.52  0.44  0.64  1.15\n",
            "  0.11 -0.09  0.13] w3: [-0.53  0.61 -0.86  0.85 -1.89  1.88] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 8901 loss: 0.0033 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.22 -0.01  0.38 -0.74  0.04] w2: [-0.5  -0.76 -1.31 -0.08  0.15 -0.1  -0.35 -0.23 -0.52  0.44  0.64  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.53  0.61 -0.86  0.85 -1.9   1.88] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 9001 loss: 0.0032 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.22 -0.01  0.38 -0.74  0.04] w2: [-0.5  -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.52  0.45  0.64  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.54  0.62 -0.86  0.85 -1.9   1.88] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 9101 loss: 0.0032 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.7  -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.22 -0.01  0.38 -0.74  0.04] w2: [-0.5  -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.52  0.45  0.64  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.54  0.62 -0.86  0.85 -1.9   1.89] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.12 0.14 0.32] b3: [0.01 0.14]\n",
            "epoch: 9201 loss: 0.0031 y_pred: [1. 0. 0. 1.] w1: [-0.42  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.23 -0.01  0.38 -0.74  0.04] w2: [-0.5  -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.52  0.45  0.64  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.54  0.62 -0.87  0.86 -1.91  1.89] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n",
            "epoch: 9301 loss: 0.0031 y_pred: [1. 0. 0. 1.] w1: [-0.43  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.23 -0.01  0.38 -0.74  0.04] w2: [-0.5  -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.52  0.45  0.65  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.54  0.62 -0.87  0.86 -1.91  1.89] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n",
            "epoch: 9401 loss: 0.0030 y_pred: [1. 0. 0. 1.] w1: [-0.43  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.23 -0.01  0.38 -0.74  0.04] w2: [-0.5  -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.52  0.45  0.65  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.54  0.62 -0.87  0.86 -1.91  1.9 ] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n",
            "epoch: 9501 loss: 0.0030 y_pred: [1. 0. 0. 1.] w1: [-0.43  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.23 -0.01  0.38 -0.74  0.04] w2: [-0.51 -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.52  0.45  0.65  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.55  0.63 -0.87  0.86 -1.91  1.9 ] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n",
            "epoch: 9601 loss: 0.0029 y_pred: [1. 0. 0. 1.] w1: [-0.43  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.84  0.13  1.23 -0.01  0.38 -0.74  0.04] w2: [-0.51 -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.53  0.45  0.65  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.55  0.63 -0.88  0.87 -1.92  1.9 ] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n",
            "epoch: 9701 loss: 0.0029 y_pred: [1. 0. 0. 1.] w1: [-0.43  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.85  0.13  1.23 -0.01  0.38 -0.74  0.04] w2: [-0.51 -0.77 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.53  0.46  0.65  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.55  0.63 -0.88  0.87 -1.92  1.9 ] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n",
            "epoch: 9801 loss: 0.0028 y_pred: [1. 0. 0. 1.] w1: [-0.43  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.85  0.13  1.23 -0.01  0.38 -0.74  0.04] w2: [-0.51 -0.78 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.53  0.46  0.65  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.55  0.63 -0.88  0.87 -1.92  1.91] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n",
            "epoch: 9901 loss: 0.0028 y_pred: [1. 0. 0. 1.] w1: [-0.43  0.   -0.26  0.71 -0.1   0.54 -0.08  0.33 -0.08  0.02 -0.73 -0.1\n",
            " -0.34  0.85  0.13  1.23 -0.01  0.39 -0.75  0.04] w2: [-0.51 -0.78 -1.31 -0.08  0.15 -0.1  -0.35 -0.24 -0.53  0.46  0.65  1.16\n",
            "  0.11 -0.09  0.13] w3: [-0.55  0.63 -0.88  0.87 -1.93  1.91] b1: [ 0.33 -0.17  0.21  0.48 -0.04] b2: [0.13 0.15 0.32] b3: [0.01 0.15]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}