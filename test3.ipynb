{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRt7ziibxApFpl+NHXE7RC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iREc7O9cKNBh"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#定义relu函数\n",
        "def relu(a):\n",
        "  a = np.maximum(0, a)\n",
        "  return a"
      ],
      "metadata": {
        "id": "z29tFET4N5If"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播，求y_pred\n",
        "def forward(W1, X, W2, B1, B2):\n",
        "  Z = np.dot(W1,X) + B1\n",
        "  H = relu(Z)\n",
        "\n",
        "  print(H.shape)\n",
        "\n",
        "  print(f\"隐藏节点值:{H}\")\n",
        "  y_pred = np.dot(H, W2.flatten()) + B2\n",
        "\n",
        "  return H, Z, y_pred"
      ],
      "metadata": {
        "id": "S-k0aYxnOOLA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#求损失函数loss值\n",
        "def compute_loss(y_pred, y_true):\n",
        "  loss = (y_pred - y_true) ** 2 /2\n",
        "  return loss"
      ],
      "metadata": {
        "id": "rqUbRhpkSVSP"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#求反向梯度值\n",
        "def backward(X, y_pred, y_true, H, Z):\n",
        "  B2_grad = y_pred - y_true\n",
        "  W2_grad = np.outer(B2_grad, H)\n",
        "\n",
        "  B1_grad = B2_grad * W2.flatten() * (Z>0)\n",
        "  W1_grad = np.outer(B1_grad, X)\n",
        "\n",
        "  return W1_grad, W2_grad, B1_grad, B2_grad"
      ],
      "metadata": {
        "id": "O4c9S7bZTKiK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#更新weight, bias的参数值\n",
        "def update_val(learning_rate, W1, W2, B1, B2, W1_grad, W2_grad, B1_grad, B2_grad):\n",
        "  W1 -= learning_rate * W1_grad\n",
        "  W2 -= learning_rate * W2_grad\n",
        "\n",
        "  B1 -= learning_rate * B1_grad\n",
        "  B2 -= learning_rate * B2_grad\n",
        "\n",
        "  return W1, W2, B1, B2"
      ],
      "metadata": {
        "id": "ZXj4g7xDjk6Y"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([1.0, -2.0, 3.0])     # 输入 (3,)\n",
        "W1 = np.array([[0.2, -0.5, 0.1],   # 权重 (2,3)\n",
        "        [-0.3, 0.8, -0.7]])\n",
        "\n",
        "B1 = np.array([0.0, 0.1])          # 偏置 (2,)\n",
        "\n",
        "W2 = np.array([[0.6, -1.2]])       # 输出层权重 (1,2)\n",
        "B2 = np.array([0.05])              # 输出层偏置 (1,)\n",
        "\n",
        "y_true = np.array([0.5])           # 真实标签\n",
        "learning_rate = 0.01\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "H, Z, y_pred = forward(W1, X, W2, B1, B2)\n",
        "print(f\"输出值:{y_pred}\")\n",
        "\n",
        "loss = compute_loss(y_pred, y_true)\n",
        "print(f\"损失值:{loss}\")\n",
        "\n",
        "W1_grad, W2_grad, B1_grad, B2_grad = backward(X, y_pred, y_true, H, Z)\n",
        "print(f\"W1的梯度:{W1_grad}, W2的梯度{W2_grad}, B1的梯度{B1_grad}, B2的梯度{B2_grad}\")\n",
        "\n",
        "W1, W2, B1, B2 = update_val(learning_rate, W1, W2, B1, B2, W1_grad, W2_grad, B1_grad, B2_grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhdYPiEiN3QO",
        "outputId": "68e636a7-26e6-45aa-85a2-7a46f4eb4b29"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,)\n",
            "隐藏节点值:[1.5 0. ]\n",
            "输出值:[0.95]\n",
            "损失值:[0.10125]\n",
            "W1的梯度:[[ 0.27 -0.54  0.81]\n",
            " [-0.    0.   -0.  ]], W2的梯度[[0.675 0.   ]], B1的梯度[ 0.27 -0.  ], B2的梯度[0.45]\n"
          ]
        }
      ]
    }
  ]
}