{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNopGVONoJmIKQJwnJk8XLE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "OcD2rA8ikL0D"
      },
      "outputs": [],
      "source": [
        "import numpy as py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "xvTcCjfA7K1Z"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = 2\n",
        "x2 = 3\n",
        "w1 = 0.5\n",
        "w2 = -0.4\n",
        "b = 0.1\n",
        "\n",
        "#前向传播\n",
        "y_pred= (w1*x1) + (w2*x2) + b\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5UnQM-wk2eF",
        "outputId": "c0da9496-54ec-476c-d9ff-90d6c5b417bd"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.10000000000000017"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#求loss值\n",
        "y_true = 1.5\n",
        "\n",
        "loss = pow((y_pred - y_true), 2)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmLxWNDHtr9E",
        "outputId": "ce740c5a-d781-4c41-e231-68bb8ec7a25e"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5600000000000005"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#计算参数的梯度\n",
        "w1_grad = (y_pred - y_true) * x1\n",
        "w2_grad = (y_pred - y_true) * x2\n",
        "b_grad = y_pred - y_true\n",
        "w1_grad, w2_grad, b_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TnNkdBZttnJ",
        "outputId": "7ba22385-7e72-4a89-e359-3c9d0a07fcb1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.2, -4.800000000000001, -1.6)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#更新weight, bias值\n",
        "lr = 0.01\n",
        "\n",
        "w1 -= lr * w1_grad\n",
        "w2 -= lr * w2_grad\n",
        "b -= lr * b_grad\n",
        "\n",
        "w1, w2, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cVJz7AmyqSV",
        "outputId": "08c52792-e2d8-4828-816e-96b02f1d5036"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.532, -0.35200000000000004, 0.116)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "NDT1Eg5XSKRZ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播\n",
        "def forward(W, X, b):\n",
        "  y_pred = np.dot(W, X) + b\n",
        "  print(\"Ypred输出的值:\", y_pred)\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "eTcHeKntSl8-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#求损失函数\n",
        "def computor_loss(y_pred, y_true):\n",
        "  loss = pow((y_pred - y_true), 2)\n",
        "  print(\"损失loss的值:\", loss)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "xe0kPxMTTLsu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算梯度\n",
        "def computor_grad(y_pred, y_true, x1, x2):\n",
        "  w1_grad = (y_pred - y_true) * x1\n",
        "  w2_grad = (y_pred - y_true) * x2\n",
        "  b_grad = y_pred - y_true\n",
        "  print(\"w1,w2,b的梯度分别是:\", w1_grad, w2_grad, b)\n",
        "  return w1_grad, w2_grad, b_grad"
      ],
      "metadata": {
        "id": "qFedtKj8TnbD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#更新weight,bias参数\n",
        "def backward(W, b, lr, w1_grad, w2_grad, b_grad):\n",
        "  w1 = W_temp[0] - lr * w1_grad\n",
        "  w2 = W_temp[1] - lr * w2_grad\n",
        "  b -= lr * b_grad\n",
        "\n",
        "  W_temp[0] = w1\n",
        "  W_temp[1] = w2\n",
        "  print(\"反向求得的w1,w2,b分别是\", w1, w2, b)\n",
        "  return w1, w2, b"
      ],
      "metadata": {
        "id": "G0qShvyyTpdv"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算并输出结果\n",
        "X = np.array([1.5, -2.0])\n",
        "W = np.array([0.7, -0.3])\n",
        "b = 0.2\n",
        "y_true = 0.5\n",
        "lr = 0.05\n",
        "\n",
        "W_temp = W\n",
        "wb_grad = []\n",
        "\n",
        "eporchs = 10\n",
        "\n",
        "for eporch in range(0, eporchs):\n",
        "  y_pred = forward(W, X, b)\n",
        "  loss = computor_loss(y_pred, y_true)\n",
        "  wb_grad = computor_grad(y_pred, y_true, X[0], X[1])\n",
        "\n",
        "  backward(W_temp, b, lr, wb_grad[0], wb_grad[1], wb_grad[2])\n",
        "  print(\"=======================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxoFJu31WL4j",
        "outputId": "70f4d413-056f-4ab6-bb36-3480e5eeb8cf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ypred输出的值: 1.8499999999999999\n",
            "损失loss的值: 1.8224999999999996\n",
            "w1,w2,b的梯度分别是: 2.025 -2.6999999999999997 0.2\n",
            "反向求得的w1,w2,b分别是 0.5987499999999999 -0.165 0.1325\n",
            "=======================\n",
            "Ypred输出的值: 1.4281249999999999\n",
            "损失loss的值: 0.8614160156249997\n",
            "w1,w2,b的梯度分别是: 1.3921875 -1.8562499999999997 0.2\n",
            "反向求得的w1,w2,b分别是 0.5291406249999999 -0.07218750000000002 0.15359375000000003\n",
            "=======================\n",
            "Ypred输出的值: 1.1380859374999999\n",
            "损失loss的值: 0.40715366363525374\n",
            "w1,w2,b的梯度分别是: 0.9571289062499998 -1.2761718749999997 0.2\n",
            "反向求得的w1,w2,b分别是 0.4812841796874999 -0.008378906250000026 0.16809570312500002\n",
            "=======================\n",
            "Ypred输出的值: 0.9386840820312499\n",
            "损失loss的值: 0.19244372382760036\n",
            "w1,w2,b的梯度分别是: 0.6580261230468748 -0.8773681640624997 0.2\n",
            "反向求得的w1,w2,b分别是 0.44838287353515616 0.03548950195312496 0.17806579589843752\n",
            "=======================\n",
            "Ypred输出的值: 0.8015953063964842\n",
            "损失loss的值: 0.0909597288403892\n",
            "w1,w2,b的梯度分别是: 0.45239295959472636 -0.6031906127929685 0.2\n",
            "反向求得的w1,w2,b分别是 0.42576322555541984 0.06564903259277338 0.1849202346801758\n",
            "=======================\n",
            "Ypred输出的值: 0.7073467731475831\n",
            "损失loss的值: 0.042992684334715286\n",
            "w1,w2,b的梯度分别是: 0.31102015972137464 -0.4146935462951662 0.2\n",
            "反向求得的w1,w2,b分别是 0.4102122175693511 0.08638370990753169 0.18963266134262086\n",
            "=======================\n",
            "Ypred输出的值: 0.6425509065389634\n",
            "损失loss的值: 0.02032076095508028\n",
            "w1,w2,b的梯度分别是: 0.2138263598084451 -0.2851018130779268 0.2\n",
            "反向求得的w1,w2,b分别是 0.39952089957892883 0.10063880056142803 0.19287245467305184\n",
            "=======================\n",
            "Ypred输出的值: 0.5980037482455371\n",
            "损失loss的值: 0.009604734670174626\n",
            "w1,w2,b的梯度分别是: 0.14700562236830572 -0.1960074964910743 0.2\n",
            "反向求得的w1,w2,b分别是 0.39217061846051354 0.11043917538598175 0.19509981258772316\n",
            "=======================\n",
            "Ypred输出的值: 0.5673775769188067\n",
            "损失loss的值: 0.00453973787144972\n",
            "w1,w2,b的梯度分别是: 0.10106636537821012 -0.1347551538376135 0.2\n",
            "反向求得的w1,w2,b分别是 0.38711730019160306 0.11717693307786242 0.19663112115405967\n",
            "=======================\n",
            "Ypred输出的值: 0.5463220841316798\n",
            "损失loss的值: 0.0021457354783024235\n",
            "w1,w2,b的梯度分别是: 0.06948312619751973 -0.09264416826335964 0.2\n",
            "反向求得的w1,w2,b分别是 0.3836431438817271 0.1218091414910304 0.19768389579341603\n",
            "=======================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yvAzGORsnemU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
      ],
      "metadata": {
        "id": "HYZflypwnt1z"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播\n",
        "def forward(X,W,b):\n",
        "  y_pred = np.dot(X,W) + b\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "W1n6pfLpoMGz"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算损失函数\n",
        "def computer_loss(y_pred, y_true):\n",
        "  loss = pow((y_pred - y_true), 2) / 2\n",
        "  return loss"
      ],
      "metadata": {
        "id": "f4utNJv5pCkM"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#计算w,b的梯度\n",
        "def computer_grad(X, y_pred, y_true):\n",
        "  y_diff = y_pred - y_true\n",
        "  return y_diff*X, y_diff"
      ],
      "metadata": {
        "id": "cq4PGEi3phm-"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#反向传播更新w,b的值\n",
        "def backward(W, b, lr, wg, bg):\n",
        "  W -= lr * wg\n",
        "  b -= lr * bg\n",
        "  return W, b"
      ],
      "metadata": {
        "id": "3XG_NYKXrbIg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#初始化\n",
        "X = np.array([2.0, -1.5, 3.0])\n",
        "W = np.array([0.6, -0.2, 0.8])\n",
        "b = 0.1\n",
        "y_true = 2.5\n",
        "lr = 0.01\n",
        "\n",
        "eporchs = 10\n",
        "\n",
        "for eporch in range(0, eporchs):\n",
        "  y_pred = forward(X,W,b)\n",
        "  loss = computer_loss(y_pred, y_true)\n",
        "  wg, bg = computer_grad(X, y_pred, y_true)\n",
        "  W, b = backward(W, b, lr, wg, bg)\n",
        "  print(f\"y_pred:{y_pred}, loss:{loss}, weight gradian:(w,{wg}),bias grandian:(b,{bg}),new_w({W}),new_b({b})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHw29nkxwVys",
        "outputId": "d641e40e-74f9-473b-aed8-74c499baa118"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred:4.0, loss:1.125, weight gradian:(w,[ 3.   -2.25  4.5 ]),bias grandian:(b,1.5),new_w([ 0.57   -0.1775  0.755 ]),new_b(0.085)\n",
            "y_pred:3.75625, loss:0.7890820312500001, weight gradian:(w,[ 2.5125   -1.884375  3.76875 ]),bias grandian:(b,1.25625),new_w([ 0.544875   -0.15865625  0.7173125 ]),new_b(0.0724375)\n",
            "y_pred:3.5521093749999997, loss:0.553467068481445, weight gradian:(w,[ 2.10421875 -1.57816406  3.15632812]),bias grandian:(b,1.0521093749999997),new_w([ 0.52383281 -0.14287461  0.68574922]),new_b(0.06191640625000001)\n",
            "y_pred:3.3811416015625007, loss:0.3882052610020643, weight gradian:(w,[ 1.7622832 -1.3217124  2.6434248]),bias grandian:(b,0.8811416015625007),new_w([ 0.50620998 -0.12965749  0.65931497]),new_b(0.053104990234374996)\n",
            "y_pred:3.237956091308594, loss:0.272289596349729, weight gradian:(w,[ 1.47591218 -1.10693414  2.21386827]),bias grandian:(b,0.7379560913085941),new_w([ 0.49145086 -0.11858814  0.63717629]),new_b(0.045725429321289056)\n",
            "y_pred:3.1180382264709476, loss:0.19098562468967717, weight gradian:(w,[ 1.23607645 -0.92705734  1.85411468]),bias grandian:(b,0.6180382264709476),new_w([ 0.47909009 -0.10931757  0.61863514]),new_b(0.03954504705657958)\n",
            "y_pred:3.0176070146694185, loss:0.1339585108174938, weight gradian:(w,[ 1.03521403 -0.77641052  1.55282104]),bias grandian:(b,0.5176070146694185),new_w([ 0.46873795 -0.10155347  0.60310693]),new_b(0.0343689769098854)\n",
            "y_pred:2.933495874785638, loss:0.09395933672808272, weight gradian:(w,[ 0.86699175 -0.65024381  1.30048762]),bias grandian:(b,0.4334958747856379),new_w([ 0.46006804 -0.09505103  0.59010205]),new_b(0.030034018162029018)\n",
            "y_pred:2.8630527951329716, loss:0.06590366602693173, weight gradian:(w,[ 0.72610559 -0.54457919  1.08915839]),bias grandian:(b,0.3630527951329716),new_w([ 0.45280698 -0.08960524  0.57921047]),new_b(0.0264034902106993)\n",
            "y_pred:2.804056715923864, loss:0.04622524324920262, weight gradian:(w,[ 0.60811343 -0.45608507  0.91217015]),bias grandian:(b,0.30405671592386385),new_w([ 0.44672585 -0.08504438  0.57008877]),new_b(0.023362923051460663)\n"
          ]
        }
      ]
    }
  ]
}