{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtNV6jZCPTgiYy5JrC2tr+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sUwhofr3-wVu"
      },
      "outputs": [],
      "source": [
        "#考虑一个具有两个隐藏层的神经网络，结构如下：\n",
        "\n",
        "#一个输入节点 (x) (但我们会输入一个批次的 (X))\n",
        "#第一个隐藏层，包含 2 个 神经元 (h^{(1)}_1, h^{(1)}_2)，均使用 ReLU 激活函数。\n",
        "#第二个隐藏层，包含 2 个 神经元 (h^{(2)}_1, h^{(2)}_2)，均使用 ReLU 激活函数。\n",
        "#一个输出节点 (y_{pred})，使用 Sigmoid 激活函数。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "MycsVmes-3F1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#添加relu函数\n",
        "def relu(a):\n",
        "  return np.maximum(0, a)"
      ],
      "metadata": {
        "id": "yHObA6ii_FKU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#添加sigmoid激活函数\n",
        "def sigmoid(a):\n",
        "  return 1 / (1 + np.exp(-a))"
      ],
      "metadata": {
        "id": "T0k5tMBy_Tx8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播，计算y_pred输出\n",
        "def forward(w1, w2, w3, b1, b2, b3, x):\n",
        "  z1 = np.dot(x, w1) + b1 #shape (2,2)\n",
        "  h1 = relu(z1) #shape (2,2)\n",
        "\n",
        "  z2 = np.dot(h1, w2) + b2 #shape (2,2)\n",
        "  h2 = relu(z2)\n",
        "\n",
        "  zout = np.dot(h2, w3) + b3 #shape (2,1)\n",
        "  y_pred = sigmoid(zout) #shape (2,1)\n",
        "  return y_pred, z1, z2, h1, h2"
      ],
      "metadata": {
        "id": "LaOlLrlABzV1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#求损失函数loss\n",
        "def compute_loss(y_pred, y_true):\n",
        "  loss = (y_pred - y_true)**2 /2\n",
        "  return loss"
      ],
      "metadata": {
        "id": "LXPQMPybDyaI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#反向传播，求梯度计算\n",
        "def forward(w1, w2, w3, b1, b2, b3, x):\n",
        "  z1 = torch.matmul(x, w1) + b1 #shape (2,2)\n",
        "  h1 = torch.relu(z1) #shape (2,2)\n",
        "\n",
        "  z2 = torch.matmul(h1, w2) + b2 #shape (2,2)\n",
        "  h2 = torch.relu(z2)\n",
        "\n",
        "  zout = torch.matmul(h2, w3) + b3 #shape (2,1)\n",
        "  y_pred = torch.sigmoid(zout) #shape (2,1)\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "6B6nTuq6Eean"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#更新参数,weight, bias\n",
        "def update_params(w1, w2, w3, b1, b2, b3, w1_grad, w2_grad, w3_grad, b1_grad, b2_grad, b3_grad, learning_rate):\n",
        "  w1 -= learning_rate * w1_grad\n",
        "  w2 -= learning_rate * w2_grad\n",
        "  w3 -= learning_rate * w3_grad\n",
        "  b1 -= learning_rate * b1_grad\n",
        "  b2 -= learning_rate * b2_grad\n",
        "  b3 -= learning_rate * b3_grad\n",
        "  return w1, w2, w3, b1, b2, b3\n"
      ],
      "metadata": {
        "id": "iqQrok4eMHuZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = np.array([[0.2, 0.3]])\n",
        "\n",
        "b1 = np.array([[0.1, -0.1]])\n",
        "\n",
        "w2 = np.array([[0.4, -0.1],\n",
        "        [0.2, 0.5]])\n",
        "\n",
        "b2 = np.array([[-0.2, 0.3]])\n",
        "\n",
        "w3 = np.array([[-0.6],\n",
        "        [0.7]])\n",
        "\n",
        "b3 = np.array([0.1])\n",
        "\n",
        "x = np.array([[1.5],\n",
        "        [0.5]])\n",
        "\n",
        "y_true = np.array([[0.6],\n",
        "          [0.9]])\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 10000\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  y_pred, z1, z2, h1, h2 = forward(w1, w2, w3, b1, b2, b3, x)\n",
        "  loss = compute_loss(y_pred, y_true)\n",
        "  losses.append(loss.flatten().mean())\n",
        "\n",
        "  y_pred = forward(w1, w2, w3, b1, b2, b3, x)\n",
        "  w1, w2, w3, b1, b2, b3 = update_params(w1, w2, w3, b1, b2, b3, w1_grad, w2_grad, w3_grad, b1_grad, b2_grad, b3_grad, learning_rate)\n",
        "\n",
        "  if epoch%100 == 0:\n",
        "    print(\"Epoch:\", epoch + 1,\n",
        "      \"loss:\", np.round(loss.flatten().mean(axis=0, keepdims=True), 4),\n",
        "      \"y_pred:\", np.round(y_pred, 4),\n",
        "      \"w1:\", np.round(w1.flatten(), 1),\n",
        "      \"w2:\", np.round(w2.flatten(), 1),\n",
        "      \"w3:\", np.round(w3.flatten(), 1),\n",
        "      \"b1:\", np.round(b1.flatten(), 1),\n",
        "      \"b2:\", np.round(b2.flatten(), 1),\n",
        "      \"b3:\", np.round(b3.flatten(), 1)\n",
        "      )\n",
        "\n",
        "plt.plot(range(epochs), losses, \"blue\")\n",
        "plt.xlabel(\"epoch axis\")\n",
        "plt.ylabel(\"loss axis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "FqrTR0Sz_gx2",
        "outputId": "0a659639-fee7-4c0a-c4df-61e3aa185040"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1b8ee72f2880>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     print(\"Epoch:\", epoch + 1,\n\u001b[1;32m     35\u001b[0m       \u001b[0;34m\"loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m       \u001b[0;34m\"y_pred:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0;34m\"w1:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0;34m\"w2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36mround\u001b[0;34m(a, decimals, out)\u001b[0m\n\u001b[1;32m   3449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3450\u001b[0m     \"\"\"\n\u001b[0;32m-> 3451\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'round'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# functions that are now methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_array_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m# As this already tried the method, subok is maybe quite reasonable here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# but this follows what was done before. TODO: revisit this.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 2) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Afp6wdH0Qa2Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#前向传播，求输出y_pred\n",
        "def forward(w1, w2, w3, b1, b2, b3, x):\n",
        "  z1 = torch.matmul(x, w1) + b1 #shape (2,2)\n",
        "  h1 = torch.relu(z1) #shape (2,2)\n",
        "\n",
        "  z2 = torch.matmul(h1, w2) + b2 #shape (2,2)\n",
        "  h2 = torch.relu(z2)\n",
        "\n",
        "  zout = torch.matmul(h2, w3) + b3 #shape (2,1)\n",
        "  y_pred = torch.sigmoid(zout) #shape (2,1)\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "HJRZA99ARNQw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#求损失函数loss\n",
        "def compute_loss(y_pred, y_true):\n",
        "  loss = (y_pred - y_true)**2 /2\n",
        "  return loss"
      ],
      "metadata": {
        "id": "e4Ii8o5fSr_6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = torch.tensor([[0.2, 0.3]],requires_grad=True)\n",
        "\n",
        "b1 = torch.tensor([[0.1, -0.1]],requires_grad=True)\n",
        "\n",
        "w2 = torch.tensor([[0.4, -0.1],\n",
        "          [0.2, 0.5]],requires_grad=True)\n",
        "\n",
        "b2 = torch.tensor([[-0.2, 0.3]],requires_grad=True)\n",
        "\n",
        "w3 = torch.tensor([[-0.6],\n",
        "          [0.7]],requires_grad=True)\n",
        "\n",
        "b3 = torch.tensor([0.1],requires_grad=True)\n",
        "\n",
        "x = torch.tensor([[1.5],\n",
        "          [0.5]])\n",
        "\n",
        "y_true = torch.tensor([[0.6],\n",
        "            [0.9]])\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 10000\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  y_pred = forward(w1, w2, w3, b1, b2, b3, x)\n",
        "  loss = compute_loss(y_pred, y_true)\n",
        "  #loss = torch.mean(compute_loss(y_pred, y_true), axis=0, keepdims=True).flatten()\n",
        "  losses.append(torch.mean(loss, axis=0, keepdims=True).flatten().item())\n",
        "\n",
        "  if w1.grad is not None:\n",
        "    w1.grad.zero_()\n",
        "    w2.grad.zero_()\n",
        "    w3.grad.zero_()\n",
        "    b1.grad.zero_()\n",
        "    b2.grad.zero_()\n",
        "    b3.grad.zero_()\n",
        "\n",
        "  loss.mean().backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w1 -= learning_rate * w1.grad\n",
        "    w2 -= learning_rate * w2.grad\n",
        "    w3 -= learning_rate * w3.grad\n",
        "    b1 -= learning_rate * b1.grad\n",
        "    b2 -= learning_rate * b2.grad\n",
        "    b3 -= learning_rate * b3.grad\n",
        "\n",
        "  if epoch%100 == 0:\n",
        "    print(\"Epoch:\", epoch + 1,\n",
        "      f\"loss: {loss.mean().item():.4f}\",\n",
        "      f\"y_pred: {y_pred.mean():.4f}\",\n",
        "      f\"w1: {w1.flatten().detach().numpy().round(2)}\",\n",
        "      f\"w2: {w2.flatten().detach().numpy().round(2)}\",\n",
        "      f\"w3: {w3.flatten().detach().numpy().round(2)}\",\n",
        "      f\"b1: {b1.flatten().detach().numpy().round(2)}\",\n",
        "      f\"b2: {b2.flatten().detach().numpy().round(2)}\",\n",
        "      f\"b3: {b3.flatten().detach().numpy().round(2)}\"\n",
        "      )\n",
        "\n",
        "plt.plot(range(epochs), losses, \"blue\")\n",
        "plt.xlabel(\"epoch axis\")\n",
        "plt.ylabel(\"loss axis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1EFj7m2uQ1HQ",
        "outputId": "abe378d1-16bb-45ca-d522-1b67b7e52d5b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 loss: 0.0260 y_pred: 0.5866 w1: [0.2 0.3] w2: [ 0.4 -0.1  0.2  0.5] w3: [-0.6  0.7] b1: [ 0.1 -0.1] b2: [-0.2  0.3] b3: [0.1]\n",
            "Epoch: 101 loss: 0.0234 y_pred: 0.6031 w1: [0.2  0.31] w2: [ 0.4  -0.09  0.2   0.5 ] w3: [-0.6   0.71] b1: [ 0.1  -0.09] b2: [-0.2   0.33] b3: [0.14]\n",
            "Epoch: 201 loss: 0.0214 y_pred: 0.6178 w1: [0.2  0.31] w2: [ 0.4  -0.09  0.2   0.5 ] w3: [-0.6   0.72] b1: [ 0.1  -0.07] b2: [-0.2   0.35] b3: [0.17]\n",
            "Epoch: 301 loss: 0.0197 y_pred: 0.6309 w1: [0.2  0.32] w2: [ 0.4  -0.09  0.2   0.5 ] w3: [-0.6   0.73] b1: [ 0.09 -0.06] b2: [-0.2   0.37] b3: [0.2]\n",
            "Epoch: 401 loss: 0.0184 y_pred: 0.6424 w1: [0.2  0.32] w2: [ 0.4  -0.08  0.2   0.5 ] w3: [-0.6   0.75] b1: [ 0.09 -0.05] b2: [-0.19  0.39] b3: [0.23]\n",
            "Epoch: 501 loss: 0.0173 y_pred: 0.6526 w1: [0.2  0.32] w2: [ 0.4  -0.08  0.2   0.51] w3: [-0.6   0.75] b1: [ 0.09 -0.04] b2: [-0.19  0.41] b3: [0.25]\n",
            "Epoch: 601 loss: 0.0164 y_pred: 0.6616 w1: [0.21 0.33] w2: [ 0.41 -0.08  0.21  0.51] w3: [-0.6   0.76] b1: [ 0.09 -0.03] b2: [-0.18  0.43] b3: [0.27]\n",
            "Epoch: 701 loss: 0.0156 y_pred: 0.6696 w1: [0.21 0.33] w2: [ 0.41 -0.08  0.21  0.51] w3: [-0.6   0.77] b1: [ 0.1  -0.02] b2: [-0.18  0.44] b3: [0.29]\n",
            "Epoch: 801 loss: 0.0149 y_pred: 0.6767 w1: [0.21 0.33] w2: [ 0.41 -0.08  0.21  0.5 ] w3: [-0.6   0.78] b1: [ 0.1  -0.02] b2: [-0.17  0.45] b3: [0.31]\n",
            "Epoch: 901 loss: 0.0144 y_pred: 0.6829 w1: [0.21 0.33] w2: [ 0.41 -0.08  0.21  0.5 ] w3: [-0.6   0.79] b1: [ 0.1  -0.01] b2: [-0.17  0.47] b3: [0.32]\n",
            "Epoch: 1001 loss: 0.0139 y_pred: 0.6884 w1: [0.22 0.33] w2: [ 0.42 -0.07  0.22  0.5 ] w3: [-0.6   0.79] b1: [ 0.1 -0. ] b2: [-0.16  0.48] b3: [0.34]\n",
            "Epoch: 1101 loss: 0.0135 y_pred: 0.6932 w1: [0.22 0.33] w2: [ 0.42 -0.07  0.22  0.5 ] w3: [-0.61  0.8 ] b1: [0.1 0. ] b2: [-0.16  0.49] b3: [0.35]\n",
            "Epoch: 1201 loss: 0.0131 y_pred: 0.6975 w1: [0.23 0.33] w2: [ 0.42 -0.07  0.22  0.5 ] w3: [-0.61  0.8 ] b1: [0.1  0.01] b2: [-0.15  0.5 ] b3: [0.36]\n",
            "Epoch: 1301 loss: 0.0128 y_pred: 0.7013 w1: [0.23 0.33] w2: [ 0.42 -0.07  0.23  0.5 ] w3: [-0.61  0.81] b1: [0.11 0.02] b2: [-0.14  0.51] b3: [0.37]\n",
            "Epoch: 1401 loss: 0.0125 y_pred: 0.7047 w1: [0.24 0.33] w2: [ 0.43 -0.07  0.23  0.5 ] w3: [-0.61  0.81] b1: [0.11 0.02] b2: [-0.14  0.51] b3: [0.38]\n",
            "Epoch: 1501 loss: 0.0123 y_pred: 0.7082 w1: [0.24 0.33] w2: [ 0.43 -0.07  0.23  0.5 ] w3: [-0.61  0.82] b1: [0.11 0.02] b2: [-0.14  0.52] b3: [0.39]\n",
            "Epoch: 1601 loss: 0.0121 y_pred: 0.7113 w1: [0.24 0.33] w2: [ 0.43 -0.08  0.23  0.5 ] w3: [-0.62  0.82] b1: [0.11 0.03] b2: [-0.14  0.53] b3: [0.4]\n",
            "Epoch: 1701 loss: 0.0120 y_pred: 0.7141 w1: [0.25 0.33] w2: [ 0.43 -0.08  0.24  0.49] w3: [-0.62  0.82] b1: [0.1  0.03] b2: [-0.14  0.53] b3: [0.41]\n",
            "Epoch: 1801 loss: 0.0118 y_pred: 0.7166 w1: [0.25 0.33] w2: [ 0.43 -0.08  0.24  0.49] w3: [-0.62  0.82] b1: [0.1  0.03] b2: [-0.14  0.54] b3: [0.42]\n",
            "Epoch: 1901 loss: 0.0117 y_pred: 0.7188 w1: [0.25 0.33] w2: [ 0.43 -0.08  0.24  0.49] w3: [-0.62  0.83] b1: [0.1  0.03] b2: [-0.15  0.55] b3: [0.42]\n",
            "Epoch: 2001 loss: 0.0116 y_pred: 0.7207 w1: [0.26 0.32] w2: [ 0.43 -0.08  0.24  0.49] w3: [-0.62  0.83] b1: [0.1  0.04] b2: [-0.15  0.55] b3: [0.43]\n",
            "Epoch: 2101 loss: 0.0115 y_pred: 0.7224 w1: [0.26 0.32] w2: [ 0.44 -0.08  0.24  0.48] w3: [-0.63  0.83] b1: [0.1  0.04] b2: [-0.15  0.56] b3: [0.43]\n",
            "Epoch: 2201 loss: 0.0114 y_pred: 0.7240 w1: [0.26 0.32] w2: [ 0.44 -0.08  0.25  0.48] w3: [-0.63  0.83] b1: [0.1  0.04] b2: [-0.15  0.56] b3: [0.44]\n",
            "Epoch: 2301 loss: 0.0113 y_pred: 0.7254 w1: [0.27 0.32] w2: [ 0.44 -0.09  0.25  0.48] w3: [-0.63  0.83] b1: [0.1  0.04] b2: [-0.15  0.56] b3: [0.45]\n",
            "Epoch: 2401 loss: 0.0112 y_pred: 0.7266 w1: [0.27 0.31] w2: [ 0.44 -0.09  0.25  0.48] w3: [-0.63  0.84] b1: [0.1  0.04] b2: [-0.15  0.57] b3: [0.45]\n",
            "Epoch: 2501 loss: 0.0111 y_pred: 0.7276 w1: [0.27 0.31] w2: [ 0.44 -0.09  0.25  0.47] w3: [-0.64  0.84] b1: [0.1  0.05] b2: [-0.15  0.57] b3: [0.45]\n",
            "Epoch: 2601 loss: 0.0111 y_pred: 0.7286 w1: [0.28 0.31] w2: [ 0.45 -0.09  0.26  0.47] w3: [-0.64  0.84] b1: [0.1  0.05] b2: [-0.16  0.57] b3: [0.46]\n",
            "Epoch: 2701 loss: 0.0110 y_pred: 0.7294 w1: [0.28 0.31] w2: [ 0.45 -0.09  0.26  0.47] w3: [-0.64  0.84] b1: [0.09 0.05] b2: [-0.16  0.58] b3: [0.46]\n",
            "Epoch: 2801 loss: 0.0109 y_pred: 0.7302 w1: [0.29 0.31] w2: [ 0.45 -0.1   0.26  0.47] w3: [-0.64  0.84] b1: [0.09 0.05] b2: [-0.16  0.58] b3: [0.47]\n",
            "Epoch: 2901 loss: 0.0108 y_pred: 0.7308 w1: [0.29 0.3 ] w2: [ 0.45 -0.1   0.26  0.46] w3: [-0.65  0.84] b1: [0.09 0.05] b2: [-0.16  0.58] b3: [0.47]\n",
            "Epoch: 3001 loss: 0.0108 y_pred: 0.7314 w1: [0.3 0.3] w2: [ 0.45 -0.1   0.26  0.46] w3: [-0.65  0.84] b1: [0.09 0.05] b2: [-0.16  0.59] b3: [0.47]\n",
            "Epoch: 3101 loss: 0.0107 y_pred: 0.7319 w1: [0.3 0.3] w2: [ 0.46 -0.1   0.27  0.46] w3: [-0.65  0.84] b1: [0.09 0.05] b2: [-0.16  0.59] b3: [0.48]\n",
            "Epoch: 3201 loss: 0.0106 y_pred: 0.7324 w1: [0.3 0.3] w2: [ 0.46 -0.11  0.27  0.46] w3: [-0.65  0.84] b1: [0.09 0.05] b2: [-0.16  0.59] b3: [0.48]\n",
            "Epoch: 3301 loss: 0.0105 y_pred: 0.7327 w1: [0.31 0.29] w2: [ 0.46 -0.11  0.27  0.45] w3: [-0.66  0.84] b1: [0.09 0.05] b2: [-0.17  0.6 ] b3: [0.48]\n",
            "Epoch: 3401 loss: 0.0104 y_pred: 0.7331 w1: [0.31 0.29] w2: [ 0.46 -0.11  0.27  0.45] w3: [-0.66  0.84] b1: [0.09 0.05] b2: [-0.17  0.6 ] b3: [0.49]\n",
            "Epoch: 3501 loss: 0.0104 y_pred: 0.7334 w1: [0.32 0.29] w2: [ 0.46 -0.11  0.27  0.45] w3: [-0.66  0.85] b1: [0.09 0.05] b2: [-0.17  0.6 ] b3: [0.49]\n",
            "Epoch: 3601 loss: 0.0103 y_pred: 0.7336 w1: [0.32 0.29] w2: [ 0.47 -0.12  0.28  0.45] w3: [-0.67  0.85] b1: [0.09 0.06] b2: [-0.17  0.6 ] b3: [0.49]\n",
            "Epoch: 3701 loss: 0.0102 y_pred: 0.7338 w1: [0.33 0.29] w2: [ 0.47 -0.12  0.28  0.44] w3: [-0.67  0.85] b1: [0.08 0.06] b2: [-0.17  0.6 ] b3: [0.49]\n",
            "Epoch: 3801 loss: 0.0101 y_pred: 0.7340 w1: [0.33 0.28] w2: [ 0.47 -0.12  0.28  0.44] w3: [-0.67  0.85] b1: [0.08 0.06] b2: [-0.17  0.61] b3: [0.5]\n",
            "Epoch: 3901 loss: 0.0101 y_pred: 0.7341 w1: [0.34 0.28] w2: [ 0.47 -0.12  0.28  0.44] w3: [-0.67  0.85] b1: [0.08 0.06] b2: [-0.17  0.61] b3: [0.5]\n",
            "Epoch: 4001 loss: 0.0100 y_pred: 0.7342 w1: [0.34 0.28] w2: [ 0.48 -0.13  0.29  0.44] w3: [-0.68  0.85] b1: [0.08 0.06] b2: [-0.18  0.61] b3: [0.5]\n",
            "Epoch: 4101 loss: 0.0099 y_pred: 0.7342 w1: [0.35 0.28] w2: [ 0.48 -0.13  0.29  0.43] w3: [-0.68  0.85] b1: [0.08 0.06] b2: [-0.18  0.61] b3: [0.5]\n",
            "Epoch: 4201 loss: 0.0098 y_pred: 0.7343 w1: [0.35 0.28] w2: [ 0.48 -0.13  0.29  0.43] w3: [-0.68  0.85] b1: [0.08 0.06] b2: [-0.18  0.62] b3: [0.51]\n",
            "Epoch: 4301 loss: 0.0098 y_pred: 0.7343 w1: [0.36 0.27] w2: [ 0.48 -0.14  0.29  0.43] w3: [-0.69  0.85] b1: [0.08 0.06] b2: [-0.18  0.62] b3: [0.51]\n",
            "Epoch: 4401 loss: 0.0097 y_pred: 0.7343 w1: [0.36 0.27] w2: [ 0.49 -0.14  0.29  0.43] w3: [-0.69  0.85] b1: [0.08 0.06] b2: [-0.18  0.62] b3: [0.51]\n",
            "Epoch: 4501 loss: 0.0096 y_pred: 0.7342 w1: [0.37 0.27] w2: [ 0.49 -0.14  0.3   0.42] w3: [-0.69  0.85] b1: [0.08 0.06] b2: [-0.18  0.62] b3: [0.51]\n",
            "Epoch: 4601 loss: 0.0095 y_pred: 0.7342 w1: [0.37 0.27] w2: [ 0.49 -0.15  0.3   0.42] w3: [-0.7   0.85] b1: [0.08 0.06] b2: [-0.19  0.62] b3: [0.52]\n",
            "Epoch: 4701 loss: 0.0094 y_pred: 0.7341 w1: [0.38 0.27] w2: [ 0.49 -0.15  0.3   0.42] w3: [-0.7   0.85] b1: [0.07 0.06] b2: [-0.19  0.63] b3: [0.52]\n",
            "Epoch: 4801 loss: 0.0094 y_pred: 0.7340 w1: [0.38 0.27] w2: [ 0.5  -0.15  0.3   0.42] w3: [-0.7   0.85] b1: [0.07 0.06] b2: [-0.19  0.63] b3: [0.52]\n",
            "Epoch: 4901 loss: 0.0093 y_pred: 0.7339 w1: [0.39 0.26] w2: [ 0.5  -0.16  0.3   0.41] w3: [-0.71  0.86] b1: [0.07 0.06] b2: [-0.19  0.63] b3: [0.52]\n",
            "Epoch: 5001 loss: 0.0092 y_pred: 0.7337 w1: [0.39 0.26] w2: [ 0.5  -0.16  0.31  0.41] w3: [-0.71  0.86] b1: [0.07 0.06] b2: [-0.19  0.63] b3: [0.52]\n",
            "Epoch: 5101 loss: 0.0091 y_pred: 0.7336 w1: [0.4  0.26] w2: [ 0.51 -0.16  0.31  0.41] w3: [-0.71  0.86] b1: [0.07 0.06] b2: [-0.19  0.63] b3: [0.53]\n",
            "Epoch: 5201 loss: 0.0090 y_pred: 0.7334 w1: [0.4  0.26] w2: [ 0.51 -0.17  0.31  0.41] w3: [-0.72  0.86] b1: [0.07 0.06] b2: [-0.2   0.63] b3: [0.53]\n",
            "Epoch: 5301 loss: 0.0089 y_pred: 0.7332 w1: [0.41 0.26] w2: [ 0.51 -0.17  0.31  0.4 ] w3: [-0.72  0.86] b1: [0.07 0.06] b2: [-0.2   0.64] b3: [0.53]\n",
            "Epoch: 5401 loss: 0.0088 y_pred: 0.7331 w1: [0.41 0.26] w2: [ 0.51 -0.18  0.31  0.4 ] w3: [-0.72  0.86] b1: [0.07 0.06] b2: [-0.2   0.64] b3: [0.53]\n",
            "Epoch: 5501 loss: 0.0087 y_pred: 0.7329 w1: [0.42 0.26] w2: [ 0.52 -0.18  0.31  0.4 ] w3: [-0.73  0.86] b1: [0.07 0.06] b2: [-0.2   0.64] b3: [0.54]\n",
            "Epoch: 5601 loss: 0.0087 y_pred: 0.7327 w1: [0.43 0.25] w2: [ 0.52 -0.18  0.32  0.4 ] w3: [-0.73  0.86] b1: [0.06 0.06] b2: [-0.2   0.64] b3: [0.54]\n",
            "Epoch: 5701 loss: 0.0086 y_pred: 0.7324 w1: [0.43 0.25] w2: [ 0.52 -0.19  0.32  0.4 ] w3: [-0.73  0.86] b1: [0.06 0.06] b2: [-0.2   0.64] b3: [0.54]\n",
            "Epoch: 5801 loss: 0.0085 y_pred: 0.7322 w1: [0.44 0.25] w2: [ 0.53 -0.19  0.32  0.39] w3: [-0.74  0.87] b1: [0.06 0.06] b2: [-0.2   0.65] b3: [0.54]\n",
            "Epoch: 5901 loss: 0.0084 y_pred: 0.7320 w1: [0.44 0.25] w2: [ 0.53 -0.19  0.32  0.39] w3: [-0.74  0.87] b1: [0.06 0.06] b2: [-0.21  0.65] b3: [0.54]\n",
            "Epoch: 6001 loss: 0.0083 y_pred: 0.7317 w1: [0.45 0.25] w2: [ 0.53 -0.2   0.32  0.39] w3: [-0.74  0.87] b1: [0.06 0.06] b2: [-0.21  0.65] b3: [0.55]\n",
            "Epoch: 6101 loss: 0.0082 y_pred: 0.7315 w1: [0.45 0.25] w2: [ 0.54 -0.2   0.33  0.39] w3: [-0.75  0.87] b1: [0.06 0.06] b2: [-0.21  0.65] b3: [0.55]\n",
            "Epoch: 6201 loss: 0.0081 y_pred: 0.7313 w1: [0.46 0.25] w2: [ 0.54 -0.21  0.33  0.39] w3: [-0.75  0.87] b1: [0.06 0.06] b2: [-0.21  0.65] b3: [0.55]\n",
            "Epoch: 6301 loss: 0.0080 y_pred: 0.7310 w1: [0.47 0.25] w2: [ 0.54 -0.21  0.33  0.38] w3: [-0.75  0.87] b1: [0.06 0.06] b2: [-0.21  0.66] b3: [0.55]\n",
            "Epoch: 6401 loss: 0.0079 y_pred: 0.7307 w1: [0.47 0.25] w2: [ 0.55 -0.21  0.33  0.38] w3: [-0.76  0.87] b1: [0.05 0.06] b2: [-0.21  0.66] b3: [0.56]\n",
            "Epoch: 6501 loss: 0.0078 y_pred: 0.7305 w1: [0.48 0.25] w2: [ 0.55 -0.22  0.33  0.38] w3: [-0.76  0.88] b1: [0.05 0.06] b2: [-0.22  0.66] b3: [0.56]\n",
            "Epoch: 6601 loss: 0.0077 y_pred: 0.7302 w1: [0.48 0.24] w2: [ 0.55 -0.22  0.33  0.38] w3: [-0.77  0.88] b1: [0.05 0.06] b2: [-0.22  0.66] b3: [0.56]\n",
            "Epoch: 6701 loss: 0.0076 y_pred: 0.7300 w1: [0.49 0.24] w2: [ 0.56 -0.23  0.34  0.38] w3: [-0.77  0.88] b1: [0.05 0.06] b2: [-0.22  0.66] b3: [0.56]\n",
            "Epoch: 6801 loss: 0.0075 y_pred: 0.7297 w1: [0.49 0.24] w2: [ 0.56 -0.23  0.34  0.37] w3: [-0.77  0.88] b1: [0.05 0.07] b2: [-0.22  0.67] b3: [0.56]\n",
            "Epoch: 6901 loss: 0.0074 y_pred: 0.7294 w1: [0.5  0.24] w2: [ 0.56 -0.23  0.34  0.37] w3: [-0.78  0.88] b1: [0.05 0.07] b2: [-0.22  0.67] b3: [0.57]\n",
            "Epoch: 7001 loss: 0.0073 y_pred: 0.7292 w1: [0.51 0.24] w2: [ 0.57 -0.24  0.34  0.37] w3: [-0.78  0.88] b1: [0.05 0.07] b2: [-0.23  0.67] b3: [0.57]\n",
            "Epoch: 7101 loss: 0.0072 y_pred: 0.7289 w1: [0.51 0.24] w2: [ 0.57 -0.24  0.34  0.37] w3: [-0.78  0.89] b1: [0.04 0.07] b2: [-0.23  0.67] b3: [0.57]\n",
            "Epoch: 7201 loss: 0.0071 y_pred: 0.7287 w1: [0.52 0.24] w2: [ 0.58 -0.25  0.34  0.37] w3: [-0.79  0.89] b1: [0.04 0.07] b2: [-0.23  0.67] b3: [0.57]\n",
            "Epoch: 7301 loss: 0.0070 y_pred: 0.7284 w1: [0.52 0.24] w2: [ 0.58 -0.25  0.35  0.36] w3: [-0.79  0.89] b1: [0.04 0.07] b2: [-0.23  0.68] b3: [0.58]\n",
            "Epoch: 7401 loss: 0.0069 y_pred: 0.7281 w1: [0.53 0.24] w2: [ 0.58 -0.25  0.35  0.36] w3: [-0.8   0.89] b1: [0.04 0.07] b2: [-0.23  0.68] b3: [0.58]\n",
            "Epoch: 7501 loss: 0.0068 y_pred: 0.7279 w1: [0.54 0.24] w2: [ 0.59 -0.26  0.35  0.36] w3: [-0.8   0.89] b1: [0.04 0.07] b2: [-0.24  0.68] b3: [0.58]\n",
            "Epoch: 7601 loss: 0.0066 y_pred: 0.7276 w1: [0.54 0.24] w2: [ 0.59 -0.26  0.35  0.36] w3: [-0.8  0.9] b1: [0.04 0.07] b2: [-0.24  0.68] b3: [0.58]\n",
            "Epoch: 7701 loss: 0.0065 y_pred: 0.7274 w1: [0.55 0.24] w2: [ 0.59 -0.27  0.35  0.36] w3: [-0.81  0.9 ] b1: [0.03 0.07] b2: [-0.24  0.69] b3: [0.59]\n",
            "Epoch: 7801 loss: 0.0064 y_pred: 0.7271 w1: [0.55 0.24] w2: [ 0.6  -0.27  0.35  0.36] w3: [-0.81  0.9 ] b1: [0.03 0.07] b2: [-0.24  0.69] b3: [0.59]\n",
            "Epoch: 7901 loss: 0.0063 y_pred: 0.7269 w1: [0.56 0.24] w2: [ 0.6  -0.27  0.35  0.35] w3: [-0.82  0.9 ] b1: [0.03 0.07] b2: [-0.24  0.69] b3: [0.59]\n",
            "Epoch: 8001 loss: 0.0062 y_pred: 0.7267 w1: [0.57 0.24] w2: [ 0.6  -0.28  0.36  0.35] w3: [-0.82  0.91] b1: [0.03 0.07] b2: [-0.25  0.69] b3: [0.59]\n",
            "Epoch: 8101 loss: 0.0061 y_pred: 0.7264 w1: [0.57 0.24] w2: [ 0.61 -0.28  0.36  0.35] w3: [-0.82  0.91] b1: [0.03 0.07] b2: [-0.25  0.69] b3: [0.6]\n",
            "Epoch: 8201 loss: 0.0060 y_pred: 0.7262 w1: [0.58 0.24] w2: [ 0.61 -0.29  0.36  0.35] w3: [-0.83  0.91] b1: [0.02 0.07] b2: [-0.25  0.7 ] b3: [0.6]\n",
            "Epoch: 8301 loss: 0.0059 y_pred: 0.7260 w1: [0.58 0.24] w2: [ 0.61 -0.29  0.36  0.35] w3: [-0.83  0.91] b1: [0.02 0.07] b2: [-0.25  0.7 ] b3: [0.6]\n",
            "Epoch: 8401 loss: 0.0058 y_pred: 0.7258 w1: [0.59 0.24] w2: [ 0.62 -0.29  0.36  0.35] w3: [-0.84  0.92] b1: [0.02 0.07] b2: [-0.25  0.7 ] b3: [0.6]\n",
            "Epoch: 8501 loss: 0.0057 y_pred: 0.7256 w1: [0.6  0.24] w2: [ 0.62 -0.3   0.36  0.35] w3: [-0.84  0.92] b1: [0.02 0.07] b2: [-0.26  0.7 ] b3: [0.61]\n",
            "Epoch: 8601 loss: 0.0055 y_pred: 0.7254 w1: [0.6  0.24] w2: [ 0.63 -0.3   0.36  0.34] w3: [-0.84  0.92] b1: [0.02 0.07] b2: [-0.26  0.71] b3: [0.61]\n",
            "Epoch: 8701 loss: 0.0054 y_pred: 0.7252 w1: [0.61 0.24] w2: [ 0.63 -0.31  0.36  0.34] w3: [-0.85  0.92] b1: [0.01 0.07] b2: [-0.26  0.71] b3: [0.61]\n",
            "Epoch: 8801 loss: 0.0053 y_pred: 0.7251 w1: [0.61 0.24] w2: [ 0.63 -0.31  0.37  0.34] w3: [-0.85  0.93] b1: [0.01 0.07] b2: [-0.26  0.71] b3: [0.62]\n",
            "Epoch: 8901 loss: 0.0052 y_pred: 0.7249 w1: [0.62 0.24] w2: [ 0.64 -0.31  0.37  0.34] w3: [-0.85  0.93] b1: [0.01 0.07] b2: [-0.27  0.71] b3: [0.62]\n",
            "Epoch: 9001 loss: 0.0051 y_pred: 0.7248 w1: [0.62 0.24] w2: [ 0.64 -0.32  0.37  0.34] w3: [-0.86  0.93] b1: [0.01 0.07] b2: [-0.27  0.72] b3: [0.62]\n",
            "Epoch: 9101 loss: 0.0050 y_pred: 0.7246 w1: [0.63 0.24] w2: [ 0.64 -0.32  0.37  0.34] w3: [-0.86  0.93] b1: [0.   0.07] b2: [-0.27  0.72] b3: [0.62]\n",
            "Epoch: 9201 loss: 0.0049 y_pred: 0.7245 w1: [0.64 0.24] w2: [ 0.65 -0.32  0.37  0.34] w3: [-0.87  0.94] b1: [0.   0.07] b2: [-0.27  0.72] b3: [0.63]\n",
            "Epoch: 9301 loss: 0.0048 y_pred: 0.7244 w1: [0.64 0.24] w2: [ 0.65 -0.33  0.37  0.34] w3: [-0.87  0.94] b1: [0.   0.07] b2: [-0.27  0.72] b3: [0.63]\n",
            "Epoch: 9401 loss: 0.0047 y_pred: 0.7243 w1: [0.65 0.24] w2: [ 0.65 -0.33  0.37  0.33] w3: [-0.87  0.94] b1: [-0.    0.07] b2: [-0.28  0.73] b3: [0.63]\n",
            "Epoch: 9501 loss: 0.0046 y_pred: 0.7242 w1: [0.65 0.24] w2: [ 0.66 -0.34  0.37  0.33] w3: [-0.88  0.95] b1: [-0.    0.07] b2: [-0.28  0.73] b3: [0.63]\n",
            "Epoch: 9601 loss: 0.0045 y_pred: 0.7241 w1: [0.66 0.24] w2: [ 0.66 -0.34  0.38  0.33] w3: [-0.88  0.95] b1: [-0.01  0.07] b2: [-0.28  0.73] b3: [0.64]\n",
            "Epoch: 9701 loss: 0.0044 y_pred: 0.7240 w1: [0.66 0.24] w2: [ 0.66 -0.34  0.38  0.33] w3: [-0.89  0.95] b1: [-0.01  0.07] b2: [-0.28  0.73] b3: [0.64]\n",
            "Epoch: 9801 loss: 0.0043 y_pred: 0.7237 w1: [0.67 0.24] w2: [ 0.67 -0.35  0.38  0.33] w3: [-0.89  0.95] b1: [-0.01  0.07] b2: [-0.29  0.74] b3: [0.64]\n",
            "Epoch: 9901 loss: 0.0042 y_pred: 0.7235 w1: [0.67 0.24] w2: [ 0.67 -0.35  0.38  0.33] w3: [-0.89  0.96] b1: [-0.01  0.07] b2: [-0.29  0.74] b3: [0.64]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}